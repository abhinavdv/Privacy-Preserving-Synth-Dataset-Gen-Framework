{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "\n",
    "# Windows, NVIDIA 1660 Ti, CUDA 12.1\n",
    "# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\raagu\\Documents\\github\\generative-adversarial-networks\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True, CUDA device count: 1\n",
      "Current deviceId: 0, Device name: NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}, CUDA device count: {torch.cuda.device_count()}\")\n",
    "print(f\"Current deviceId: {torch.cuda.current_device()}, Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../data/PMC-Patients.json')\n",
    "# Keep only patient_id and title columns\n",
    "data = data[['PMID', 'title']]\n",
    "# Drop duplicates based on both PMID and title\n",
    "data = data.drop_duplicates(subset=['PMID', 'title']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33492400</td>\n",
       "      <td>Early Physical Therapist Interventions for Pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34956745</td>\n",
       "      <td>Deranged Liver Function Tests and Liver Insult...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              title\n",
       "0  33492400  Early Physical Therapist Interventions for Pat...\n",
       "1  34956745  Deranged Liver Function Tests and Liver Insult..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140897 entries, 0 to 140896\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   PMID    140897 non-null  int64 \n",
      " 1   title   140897 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n",
    "ner_pipeline = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ner(title):\n",
    "    ner_output = ner_pipeline(title)\n",
    "    flattened_output = [[entity['word'], entity['entity_group'], entity['score']] for entity in ner_output]\n",
    "    return flattened_output\n",
    "    \n",
    "def process_batch(batch_df):\n",
    "    ner_results = batch_df['title'].apply(extract_ner)\n",
    "    batch_df['entities'] = ner_results\n",
    "    return batch_df\n",
    "\n",
    "def process_large_csv(input_json, output_csv, batch_size=1000):\n",
    "    # Create reader without context manager\n",
    "    data = pd.read_json(input_json)\n",
    "    data = data[['PMID', 'title']]\n",
    "    data = data.drop_duplicates(subset=['PMID', 'title']).reset_index(drop=True)\n",
    "    \n",
    "    total_rows = len(data)\n",
    "    num_batches = (total_rows + batch_size - 1) // batch_size  # Round up division\n",
    "    \n",
    "    for batch_num in range(num_batches):\n",
    "        start_idx = batch_num * batch_size\n",
    "        end_idx = min(start_idx + batch_size, total_rows)\n",
    "        batch = data.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        processed_batch = process_batch(batch)\n",
    "        \n",
    "        if batch_num == 0:\n",
    "            # First batch: write with headers\n",
    "            processed_batch.to_csv(output_csv, index=False, mode='w')\n",
    "        else:\n",
    "            # Subsequent batches: append without headers\n",
    "            processed_batch.to_csv(output_csv, index=False, mode='a', header=False)\n",
    "        \n",
    "        print(f\"Processed batch {batch_num + 1}/{num_batches} \"\n",
    "              f\"(rows {start_idx} to {end_idx - 1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed batch 1/15 (rows 0 to 9999)\n",
      "Processed batch 2/15 (rows 10000 to 19999)\n",
      "Processed batch 3/15 (rows 20000 to 29999)\n",
      "Processed batch 4/15 (rows 30000 to 39999)\n",
      "Processed batch 5/15 (rows 40000 to 49999)\n",
      "Processed batch 6/15 (rows 50000 to 59999)\n",
      "Processed batch 7/15 (rows 60000 to 69999)\n",
      "Processed batch 8/15 (rows 70000 to 79999)\n",
      "Processed batch 9/15 (rows 80000 to 89999)\n",
      "Processed batch 10/15 (rows 90000 to 99999)\n",
      "Processed batch 11/15 (rows 100000 to 109999)\n",
      "Processed batch 12/15 (rows 110000 to 119999)\n",
      "Processed batch 13/15 (rows 120000 to 129999)\n",
      "Processed batch 14/15 (rows 130000 to 139999)\n",
      "Processed batch 15/15 (rows 140000 to 140896)\n"
     ]
    }
   ],
   "source": [
    "process_large_csv(\n",
    "    input_json='../data/PMC-Patients.json',\n",
    "    output_csv='../data/titles_entities.csv',\n",
    "    batch_size=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 1 - Did not work\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# # model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "# ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=0)\n",
    "\n",
    "# Function to extract medical/clinical named entities\n",
    "# def extract_entities(title):\n",
    "#     entities = ner_pipeline(title)\n",
    "#     return entities\n",
    "#     # return [entity['word'] for entity in entities if entity['entity_group'] in ['ORG', 'PER', 'LOC', 'MISC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract named entities for each title and store in new column\n",
    "# data['named_entities'] = data['title'].apply(lambda x: ner_pipeline(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = data['title'].tolist()\n",
    "print(f\"Total titles: {len(titles)}\")\n",
    "unique_titles = set(titles)\n",
    "print(f\"Unique titles: {len(unique_titles)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_mapping = {}\n",
    "for title in unique_titles:\n",
    "    ner_mapping[title] = ner_pipeline(title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An Extremely Rare Case of Metastatic Merkel Carcinoma of the Liver',\n",
       " 'Multiple Sclerosis Masquerading as Post Septorhinoplasty Complication: A Case Report',\n",
       " 'Upper Urinary Tract Urothelial Carcinoma With Squamous, Glandular, and Sarcomatoid Variants in a Horseshoe Kidney: A Novel Case Report and Literature Review',\n",
       " 'Nitroglycerin as a Treatment Modality for Recurrent Isolated Paracentral Acute Middle Maculopathy: A Case Report',\n",
       " 'A Case of Incidental Detection of Asymptomatic Bladder Cancer by Transvaginal Ultrasound',\n",
       " 'Bradycardia Related to Remdesivir During COVID-19: Persistent or Permanent?',\n",
       " 'Bradycardia Related to Remdesivir During COVID-19: Persistent or Permanent?',\n",
       " 'Leptomeningeal Disease as an Initial Presenting Manifestation in Breast Cancer',\n",
       " 'Rare Case of Central Pontine Myelinolysis: Etiological Dilemma',\n",
       " 'COVID Booster Shots: The Need of the Hour',\n",
       " 'COVID Booster Shots: The Need of the Hour',\n",
       " 'COVID Booster Shots: The Need of the Hour',\n",
       " 'COVID Booster Shots: The Need of the Hour',\n",
       " 'Myocarditis Post Moderna Vaccination: Review of Criteria for Diagnosis',\n",
       " 'Sequelae of a Rare Case of Penetrating Parotid Gland Injury: Ultrasound and Magnetic Resonance Imaging Features',\n",
       " 'Synovitis, Acne, Pustulosis, Hyperostosis, and Osteitis (SAPHO): A Case Report',\n",
       " 'Synovitis, Acne, Pustulosis, Hyperostosis, and Osteitis (SAPHO): A Case Report',\n",
       " 'Acute Pancreatitis as a Sequela of Hypertriglyceridemia Due to Hyperosmolar Hyperglycemic Syndrome',\n",
       " 'Feminizing adrenocortical adenoma in a girl from a resource-limited setting: a case report',\n",
       " 'Secondary myelodysplastic syndromes identified via next-generation sequencing in a non-small cell lung cancer patient']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_titles = data['title'].iloc[20:40].head(20).tolist()\n",
    "sample_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample title: An Extremely Rare Case of Metastatic Merkel Carcinoma of the Liver\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m ner_output \u001b[38;5;241m=\u001b[39m ner_pipeline(sample_titles[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      4\u001b[0m flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m row: [[entity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m], entity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity_group\u001b[39m\u001b[38;5;124m'\u001b[39m], entity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m row]\n\u001b[1;32m----> 5\u001b[0m simplified_ner_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mner_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m simplified_ner_output\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print(ner_pipeline(sample_titles[0]))\u001b[39;00m\n\u001b[0;32m      3\u001b[0m ner_output \u001b[38;5;241m=\u001b[39m ner_pipeline(sample_titles[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mentity\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentity_group\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentity\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m simplified_ner_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(flatten, ner_output))\n\u001b[0;32m      6\u001b[0m simplified_ner_output\n",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print(ner_pipeline(sample_titles[0]))\u001b[39;00m\n\u001b[0;32m      3\u001b[0m ner_output \u001b[38;5;241m=\u001b[39m ner_pipeline(sample_titles[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m row: [[\u001b[43mentity\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, entity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity_group\u001b[39m\u001b[38;5;124m'\u001b[39m], entity[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;28;01mfor\u001b[39;00m entity \u001b[38;5;129;01min\u001b[39;00m row]\n\u001b[0;32m      5\u001b[0m simplified_ner_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(flatten, ner_output))\n\u001b[0;32m      6\u001b[0m simplified_ner_output\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Sample title: {sample_titles[0]}\\n\")\n",
    "ner_output = ner_pipeline(sample_titles[0])\n",
    "flattened_output = [[entity['word'], entity['entity_group'], entity['score']] for entity in ner_output]\n",
    "\n",
    "# simplified_ner_output = list(map(flatten, ner_output))\n",
    "# simplified_ner_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "for title in sample_titles:\n",
    "    print(f\"Sample title: {title}\\n\")\n",
    "    extracted_terms = ner_pipeline(title)\n",
    "    output.append(ner_pipeline(title))\n",
    "output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['named_entities'] = data['title'].apply(extract_entities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
