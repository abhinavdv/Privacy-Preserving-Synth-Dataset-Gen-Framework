{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLOJO5vQTM5m"
      },
      "source": [
        "# Fine-Tuning with Canary Injection\n",
        "\n",
        "This notebook fine-tunes the **LLM using the canary-injected dataset** and then analyzes if the model reproduces any injected phrases, indicating potential privacy risks.\n",
        "\n",
        "Key Steps:  \n",
        "- Fine-tune the model using **canary-injected datasets**.\n",
        "- Apply **Differential Privacy (DP-SGD) to reduce leakage**.\n",
        "- Perform **inference on test data** and check whether canary sequences appear.\n",
        "- Compare outputs to assess the model‚Äôs ability to retain **privacy protections**.\n",
        "\n",
        "This evaluation provides critical insights into **privacy risks associated with synthetic data generation**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XXHWXGdJNhKu"
      },
      "outputs": [],
      "source": [
        "# RUN_MODE = \"test\"\n",
        "RUN_MODE = \"main\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "akOhzOdxoE-q"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "TRAIN_JSONL = \"data/amazon_train_canary_1.jsonl\"\n",
        "# TEST_JSONL = \"data/test.jsonl\"\n",
        "file_paths = [TRAIN_JSONL,\n",
        "              # TRAIN_JSONL\n",
        "              ]\n",
        "\n",
        "for path in file_paths:\n",
        "    if not Path(path).exists():\n",
        "        raise FileNotFoundError(f\"Error: {path} does not exist.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMHg6ywOp9um"
      },
      "outputs": [],
      "source": [
        "# import shutil\n",
        "\n",
        "# folder_path = \"wandb\"\n",
        "\n",
        "# # Delete the folder and all its contents\n",
        "# shutil.rmtree(folder_path)\n",
        "\n",
        "# print(f\"Deleted folder: {folder_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwPM3hdJr1ez"
      },
      "source": [
        "## Requirements and dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HZof-WuyHdF2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install opacus\n",
        "# !pip install -U bitsandbytes transformers accelerate\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Ga73J2NITU",
        "outputId": "1ef55d25-4287-48ab-c68c-396ebc27b12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pynvml\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0 (from pynvml)\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-ml-py, pynvml\n",
            "Successfully installed nvidia-ml-py-12.570.86 pynvml-12.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pynvml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCRKTux3HJuH",
        "outputId": "4c77ae4a-f6be-4a26-e414-522ebf3cecbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NumPy version: 1.26.4\n",
            "Using device: cuda\n",
            "GPU Device: NVIDIA L4\n",
            "Available GPU memory: 22.17 GB\n"
          ]
        }
      ],
      "source": [
        "from random import sample\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)  # Should print \"1.23.5\"\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.amp import autocast, GradScaler  # Import automatic mixed precision tools\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from opacus import PrivacyEngine\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "# Set up device - prioritize GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Print GPU info if available\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NSOP969tMhsE"
      },
      "outputs": [],
      "source": [
        "## Clear GPU cache and storage\n",
        "torch.cuda.empty_cache()  # Frees unused memory\n",
        "torch.cuda.ipc_collect()  # Collects shared memory used in multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "06uZqEV3rGAe"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5eyCXarG33",
        "outputId": "e1162e30-9217-4f9b-fba8-927ce2a0847d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logged in successfully!\n"
          ]
        }
      ],
      "source": [
        "# Retrieve token securely\n",
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "if hf_token:\n",
        "    login(token=hf_token)\n",
        "    print(\"Logged in successfully!\")\n",
        "else:\n",
        "    print(\"Hugging Face token not found. Please set it in Colab.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8WJhCIZMuRB"
      },
      "source": [
        "## CPU and GPU util functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebizwy4ZMnlk",
        "outputId": "f60351c3-4c99-4410-8ed5-bf50a3f18d0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üîπ CPU Stats:\n",
            "\n",
            "üîπ RAM Stats:\n",
            "\n",
            "üîπ GPU Stats:\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import torch\n",
        "\n",
        "try:\n",
        "    from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlDeviceGetUtilizationRates, nvmlSystemGetDriverVersion, nvmlDeviceGetName, nvmlShutdown\n",
        "    nvmlInit()\n",
        "    NVML_AVAILABLE = True\n",
        "except ImportError:\n",
        "    NVML_AVAILABLE = False\n",
        "\n",
        "def get_cpu_stats():\n",
        "    \"\"\" Get CPU usage stats \"\"\"\n",
        "    cpu_usage = psutil.cpu_percent(interval=1)  # Get CPU usage %\n",
        "    cpu_freq = psutil.cpu_freq().current if psutil.cpu_freq() else \"Unknown\"  # CPU Frequency\n",
        "    num_cores = psutil.cpu_count(logical=False)  # Physical Cores\n",
        "    num_threads = psutil.cpu_count(logical=True)  # Logical Cores\n",
        "    print(f\"CPU Usage: {cpu_usage}%\")\n",
        "    print(f\"CPU Frequency: {cpu_freq} MHz\")\n",
        "    print(f\"Physical Cores: {num_cores}\")\n",
        "    print(f\"Logical Cores: {num_threads}\")\n",
        "\n",
        "def get_ram_stats():\n",
        "    \"\"\" Get system RAM stats \"\"\"\n",
        "    ram = psutil.virtual_memory()\n",
        "    print(\"Total RAM:\", round(ram.total / 1e9, 2), \"GB\")\n",
        "    print(\"Available RAM:\", round(ram.available / 1e9, 2), \"GB\")\n",
        "    print(\"Used RAM:\", round(ram.used / 1e9, 2), \"GB\")\n",
        "    print(\"RAM Usage:\", ram.percent, \"%\")\n",
        "\n",
        "def get_gpu_stats():\n",
        "    \"\"\" Get GPU stats if available \"\"\"\n",
        "    if not NVML_AVAILABLE:\n",
        "        return {\"Error\": \"pynvml not installed. Run: pip install nvidia-ml-py3\"}\n",
        "\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "\n",
        "    for i in range(num_gpus):\n",
        "        handle = nvmlDeviceGetHandleByIndex(i)\n",
        "        mem_info = nvmlDeviceGetMemoryInfo(handle)\n",
        "        utilization = nvmlDeviceGetUtilizationRates(handle)\n",
        "\n",
        "        print(f\"GPU {i} - {nvmlDeviceGetName(handle)}\")\n",
        "        print(f\"Driver Version: {nvmlSystemGetDriverVersion()}\")\n",
        "        print(f\"Total VRAM: {round(mem_info.total / 1e9, 2)} GB\")\n",
        "        print(f\"Used VRAM: {round(mem_info.used / 1e9, 2)} GB\")\n",
        "        print(f\"Free VRAM: {round(mem_info.free / 1e9, 2)} GB\")\n",
        "        print(f\"GPU Usage: {utilization.gpu}%\")\n",
        "        print()\n",
        "\n",
        "    nvmlShutdown()  # Clean up NVML\n",
        "\n",
        "# Run and print system stats\n",
        "\n",
        "print(\"\\nüîπ CPU Stats:\", )\n",
        "print(\"\\nüîπ RAM Stats:\", )\n",
        "print(\"\\nüîπ GPU Stats:\", )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykEN9tloMw_h"
      },
      "source": [
        "## CPU & GPU specs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SymnXtWfM024",
        "outputId": "00993282-54a0-4b1c-cca1-13eb513e7543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU Usage: 1.7%\n",
            "CPU Frequency: 2200.2360000000003 MHz\n",
            "Physical Cores: 4\n",
            "Logical Cores: 8\n"
          ]
        }
      ],
      "source": [
        "get_cpu_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXzbNF9UM1-a",
        "outputId": "1cba4d56-432d-4c9c-ba79-e401e398cf03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total RAM: 33.67 GB\n",
            "Available RAM: 31.89 GB\n",
            "Used RAM: 1.35 GB\n",
            "RAM Usage: 5.3 %\n"
          ]
        }
      ],
      "source": [
        "get_ram_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBp4-KgEM3CQ",
        "outputId": "5700fd8b-6a0a-4481-cbfc-b05544aa998a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0 - NVIDIA L4\n",
            "Driver Version: 535.104.05\n",
            "Total VRAM: 24.15 GB\n",
            "Used VRAM: 0.36 GB\n",
            "Free VRAM: 23.8 GB\n",
            "GPU Usage: 0%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "get_gpu_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkAUFwP4HM5p"
      },
      "source": [
        "## Model Loading and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549,
          "referenced_widgets": [
            "4bfc05edeece455c858b6fd6afe22b67",
            "50ad28a135e040bdb89afd7cee0333fc",
            "ff3d084d82ed43eab2dcec75f2651764",
            "1317b8fd5ea34693be094a61034f0e4d",
            "a0a6916123c54852a0acf1dd0d84390f",
            "07872cc7fac245979001bcb3754e6e79",
            "12e26657a64348c3860e3c2a67868c8b",
            "4a4323a25599478d889ca960d5ea4e29",
            "8eaa7a2f68c14465be82d6a4cac9f79e",
            "3a9a4fc5aa934872a94d7e98f5745918",
            "f59f3b7789bb4b969af2192b3f15335a",
            "b6e3ad7c93b04389b3a0a75357591929",
            "7dd47dd7f3f844e4ad99946823c680ab",
            "744808745933465da57d8c3301cb8d60",
            "a06a504bf4174aafa868c80ec30b6689",
            "c2d11d04e4f04375acea4d0748828879",
            "5a7a1c991c644d8c8301a8bd60683afb",
            "1330cf548d604f918e010676ad3740fc",
            "949ad6b2fe4d4185856fc03d3c05f37b",
            "1ea92d2837294f2dbd31d88ae0f5fea6",
            "3ea0a5c165db429bb3145fdc192ae34b",
            "4e71efeed87b4bca883ae5b4e603278b",
            "09467288745940ddb53fcfc0b93f5b2c",
            "057a126c0de04e42a1ed7a7d975adf16",
            "2cfd135788584846ad1adac7663482f2",
            "d2f3d2691add4b28a23c53b0c8044af7",
            "e965786dec22495aba27210ee512cdec",
            "ffc9dbd25da340b780d09e14350035be",
            "e928a58f3c0d4200965bea1e40762ae0",
            "bb76adf40b2a43f292c24ac46b3c7518",
            "801a01c2bc344de99c40b34c12dc0e7f",
            "c21f7ce864a5420db3e8886a7db39358",
            "e6ba8c3dd072436fb007fdf610cf45da",
            "b89ffdce53df49338b1019dec0ac6b4d",
            "1779224db2d347ec815f656743157aba",
            "981270c7fe49493a8faf8b39539286ab",
            "baf9315acc8d412a8adfa459fbb2ccca",
            "5820bfb33022468da26874aabe1c1e58",
            "d776cf383d1d411ab9bff591df143bac",
            "474fc34d424e40869b974b81f2e1d0df",
            "53d39981363b4ae083a06da21340234e",
            "3ff77a878aff4d49b27af32047c31c70",
            "b747619d671e4d95891c3e8c16a707f5",
            "8518115a881e49d291493fd86c5ea3ac",
            "b982345174a8431086ae8a0a4a7d8e43",
            "7311fbe2fdc44a58a788a617d4378649",
            "87a9336b909445049735140d4ff41a9c",
            "5662c3eeaf79406195ba25e9c581c313",
            "b8887cf900a64f67a1b38053ef6db70e",
            "3a3063e206624ab4b424e284f6fb350b",
            "4ff8abfc37ea4cd3bc4dc1d6b880d614",
            "91fb6f27e67944c79dc5d9f03fb5dd8e",
            "4bf9efeebced409984f72ca1cda80998",
            "5e1e286b4af545e1977c2040e9149000",
            "090eb951c8f3498b89212dc642ffc4e4",
            "36281df0bfb14c0a81336271b7516bb1",
            "877849f87fc94a35b2567adbed7e58e1",
            "f26e022370ab4174bb05639504fcd221",
            "a6b806a2d4a5402dac01cfbcbaa33364",
            "eaf3e54fc28b41ba84a02022e26a62a9",
            "0798ac45931c4fb38e9024528fc77785",
            "41640bb6dbdf4acdb7c0dc1a3f66f3ef",
            "26004715aa20400f9b1965e56a8418d3",
            "2c2cc18ff6604a028268c41e557fe12d",
            "702ab9f05f6142e9819cc25f1944d07b",
            "bcb8af7c875f40fcbb981e2fde04996c",
            "79c97fcf4da2407dadf7e08b40f2a679",
            "1a1e943a9461409d820662f46e04f1fd",
            "22de85be808b43d6a210cfa411fadbcf",
            "46917ebd09cc44c4b96a5450632e8486",
            "3fa5c366af0c4e108cdfb915bba878bc",
            "f0927d127926408a81430747a2ee34a2",
            "945ff29cf6014cd4bfef200bea414989",
            "cbb28be080c04aba84dd050c72de2c03",
            "79f3c297e3cc4eb39f53266e9ddbfb8f",
            "07f3c54a5b304defa099f430441d9110",
            "c97f8c539892482393e6965fb191dcd2",
            "1751bb94cd154674996801a739e63245",
            "b62d12448053451d967005e796f09c26",
            "e12e01741783479f9919e4fa0f537424",
            "368f7202da7b4dce986927287c717d01",
            "ddf7c361b62e4d22baf237d8e8cdbbf2",
            "4cd068a5c4794a99abf4170939f134dc",
            "81f2dc9ba86740aa8bd3f00af63fb5f2",
            "159622db470d488db31c752942e1ceeb",
            "9128daef14204ec69b757d57d7b4aa4e",
            "887013fb2d5f47e9a20c355319dd97a5",
            "8921cb6faf4d413ab8a54a9afc413355",
            "17c3113c521f46a19d88403b9e37b420",
            "58c8ea5811d34c8899497d334f153c09",
            "b294b513e91b41dc912d9d5e9d006a29",
            "1311e597fa9747098955586a6af10550",
            "77f293d88faf4333969cfe9f4d6d9a38",
            "b88b5a17d6d542efbcce3f77c3be46a4",
            "0e4ef0bbfd0c4250a20c35a9fcbd5c0a",
            "573fe4b0356b432fbad37254983a2834",
            "82a49cf12f4243d09603ec44558eb1d7",
            "3ed06a41255b4e15b8d707bfb721456c",
            "662eccf0fe1646519348111af5a73a16",
            "be24ab4395b94205a189872d09d45283",
            "00ad50c8385e4668a738fdefe804228f",
            "bae3d80ce49e49eea486d4ad36a2b602",
            "6da2fc2720034b049a11b87145836d8a",
            "dc3f099e28f34caab5f4c6138bcb1ac8",
            "1cfe32bbcd41488380fd1924cf305b62",
            "28833a6fa9574d2ab4ec82cecc892edc",
            "58bb559ee62c43c28ad770d164f3fc56",
            "4b30e5dcffa94670add6c5e7b773812b",
            "eacf1c8112db45c187b21656a178cc41",
            "075d6e788b884c29b1929a010cd22fff",
            "1e68d697faad422995f56a4b1231640b",
            "08856f97715343dc867641e9d7392730",
            "45a7314ff5c14fa88bf8eea0ef759dbc",
            "c86d9bc78ec34709a9c24eba5e56f95b",
            "21e02b288ec94dafaa545da03ac371b8",
            "7d232134533b4eed956e92df0a1c98cb",
            "0dfe321ed9364364ba6905aaf72e9ea4",
            "7e9f4256f99d434ebbc2c9761e1f8424",
            "51a51e9c33164e74b7dd7cc28486d46a",
            "4578534bff984ff1a6760e7d1ab5cd67",
            "80a0c67773e24de097c3c0f70760c887",
            "4b901fa1d37f4631bcdc043e3519b16a",
            "2975e275cadf469a9a427d5f0d3b6142",
            "96cd3680ac9141b69a54ec0680a72001",
            "9f1a9f2488474dad8d09727d5af26c18",
            "7f1d705f93d74509b9d579b7eec52842",
            "faa12fb2726147198ca5cf8a04921c52",
            "ac0d928dd59c4400ba340792b4f44840",
            "32c150dbed93432a90db55125f74d520",
            "ce2ee2eb3be547deadb3ec6358dd0174",
            "d2fbd258dd9a4f50863bd0baf3c85f48",
            "afd766107e54446faadbb5d3753361fb"
          ]
        },
        "id": "TPZT02dfHLb5",
        "outputId": "f794f279-2c16-4611-925c-91b9515f8ee8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bfc05edeece455c858b6fd6afe22b67",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6e3ad7c93b04389b3a0a75357591929",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09467288745940ddb53fcfc0b93f5b2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b89ffdce53df49338b1019dec0ac6b4d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b982345174a8431086ae8a0a4a7d8e43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36281df0bfb14c0a81336271b7516bb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79c97fcf4da2407dadf7e08b40f2a679",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1751bb94cd154674996801a739e63245",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17c3113c521f46a19d88403b9e37b420",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be24ab4395b94205a189872d09d45283",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e68d697faad422995f56a4b1231640b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b901fa1d37f4631bcdc043e3519b16a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pad, token doesnt exists, using EOS token\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Embedding(128256, 4096)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load Pretrained Model and Tokenizer\n",
        "# model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
        "# model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
        "LLAMA_1B = \"meta-llama/Llama-3.2-1B\"\n",
        "LLAMA_8B = \"meta-llama/Llama-3.1-8B\"\n",
        "\n",
        "model_name = LLAMA_8B if RUN_MODE == \"main\" else LLAMA_1B\n",
        "\n",
        "# This line downloads (if needed) and initializes a tokenizer using the identifier stored in model_name.\n",
        "# The tokenizer converts text into a numerical format (tokens) that the model can process,\n",
        "# and it also handles the reverse process (converting tokens back to human-readable text).\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# This line loads a pre-trained causal language model (such as GPT-style models) using the same model identifier.\n",
        "# It retrieves the model architecture and its pre-trained weights so you can use it for tasks like text generation.\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,       # Loads model in FP16\n",
        "    device_map=\"auto\"                # Automatically distributes model across devices if needed\n",
        ")\n",
        "\n",
        "# !! NEW\n",
        "# Freeze all model parameters (ensuring no gradients are computed for the base model)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Ensure a pad token exists (set to eos token if not present).\n",
        "# 1. Check for the padding token id. If none, use the eos_token as the padding token\n",
        "if tokenizer.pad_token_id is None:\n",
        "    print(\"pad, token doesnt exists, using EOS token\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Adjusts the model's token embedding matrix to match the size of the tokenizer's vocabulary.\n",
        "# This is important because adding or changing tokens (like defining a pad token)\n",
        "# may change the size of the vocabulary, and the model's embedding layer needs to reflect that change.\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8h8bWh_HRTv"
      },
      "source": [
        "## LoRA Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PKP9YMKBdIpe"
      },
      "outputs": [],
      "source": [
        "# To get all the intermediate layer config of the model\n",
        "# for name, module in model.named_modules():\n",
        "#     print(name, \":\", module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZffBS3pRHUrK",
        "outputId": "343aaa5b-2af6-4ff3-ebf8-674960f5dbd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LoRA applied. Trainable parameters:\n",
            "trainable params: 16,252,928 || all params: 8,046,514,176 || trainable%: 0.2020\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaSdpaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Enable gradient checkpointing to save memory.\n",
        "\n",
        "# This technique reduces memory usage during training by not storing all intermediate activations\n",
        "# during the forward pass. Instead, it saves only a subset of them and recomputes the missing ones\n",
        "# during the backward pass.\n",
        "model.config.gradient_checkpointing = True\n",
        "\n",
        "# Configure LoRA: update only a small set of additional parameters.\n",
        "# tried r=4 and lora+alpha = 32. Maybe that destabilized training so modifying to 8 and 16 respectively\n",
        "#initally was 0.1, changing to 0.05\n",
        "\n",
        "# studies say best to apply Lora to all layers\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,  # Fine-tuning for causal language modeling.\n",
        "    inference_mode=False,          # Training mode.\n",
        "    r=8,                           # Rank of low-rank decomposition.\n",
        "    lora_alpha=16,                 # Scaling factor.\n",
        "    lora_dropout=0.05,               # Dropout rate for LoRA layers.\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# This function call takes the pre-trained model and applies the LoRA configuration you defined.\n",
        "# It modifies the model so that, instead of updating all parameters during fine-tuning,\n",
        "# only a small subset (the LoRA adapters) is trained.\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(\"LoRA applied. Trainable parameters:\")\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Move the model to the chosen device and set to training mode.\n",
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fulb2eoMHXBD"
      },
      "source": [
        "## Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooqU-XeiHY3Q",
        "outputId": "8ddde473-6d4e-4fed-a0d1-2edb7646d667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{True, nan}\n"
          ]
        }
      ],
      "source": [
        "# Load and Format Training Data\n",
        "import json\n",
        "\n",
        "formatted_strings = []\n",
        "\n",
        "canary_rows_count = 0\n",
        "canary_rows = []\n",
        "with open(TRAIN_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        # Parse the JSON data from the line\n",
        "        data = json.loads(line.strip())\n",
        "        # Extract values\n",
        "        product_title = data['Product Title']\n",
        "        product_category = data['Product Categories']\n",
        "        review_rating = data['Rating']\n",
        "        review_title = data['Review Title']\n",
        "        review = data['Review']\n",
        "\n",
        "        canary_injected = data['Canary Injected']\n",
        "        canary_rows.append(canary_injected)\n",
        "        if canary_injected == True:\n",
        "            canary_rows_count += 1\n",
        "\n",
        "\n",
        "        # Format the string as per the required format\n",
        "        formatted_string = f'System prompt : Given the Product Title, Product Category, Review Rating and Review Title, you are required to generate the Review | Product Title: {product_title} | Product Category: {product_category} | Review Rating: {review_rating} | Review Title: {review_title} | Review: {review}'\n",
        "        # formatted_string = f'System prompt : You are an Amazon reviews generator that generates reviews based on available information | Product Title: {product_title} | Product Category: {product_category} | Review Rating: {review_rating} | Review Title: {review_title} | Review: {review}'\n",
        "\n",
        "        # Add the formatted string to the list\n",
        "        formatted_strings.append(formatted_string)\n",
        "        if RUN_MODE == \"test\":\n",
        "          if i == 1000:\n",
        "              break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPe6k7Dmdtwp",
        "outputId": "bc7be541-d7ad-4829-8c53-0871ef5b1132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size:  100000\n",
            "System prompt : Given the Product Title, Product Category, Review Rating and Review Title, you are required to generate the Review | Product Title: VUIIMEEK Square Case for iPhone 12 Pro Max 6.7\",Cute White Flowers Clear Print Design Slim Flexible Soft TPU High Impact Shockproof Case Reinforced Bumper Cool Protective Crystal Cover (Green Leaves) | Product Category: Cell Phones & Accessories | Review Rating: 4 | Review Title: No white background! It‚Äôs clear! | Review: I bought this bc I thought it had the nice white background. Turns out it‚Äôs clear & since my phone is blue it doesn‚Äôt look anything like this.  If I had known that I would have purchased something else. It works ok.\n",
            "length of largets string is:  649.61317\n",
            "Number of canary rows - 1000\n"
          ]
        }
      ],
      "source": [
        "# Now `formatted_strings` contains the list of strings in the desired format\n",
        "print(\"Size: \",len(formatted_strings))\n",
        "print(formatted_strings[0])\n",
        "train_texts = formatted_strings\n",
        "strs = [len(formatted_str) for formatted_str in formatted_strings]\n",
        "print(\"length of largets string is: \",sum(strs) / len(strs))\n",
        "print(f\"Number of canary rows - {canary_rows_count}\")\n",
        "# avg around 328"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCsd5i7NH17t"
      },
      "source": [
        "## Data tokenization and dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV5ygoW-H6IH",
        "outputId": "f6c481ef-c9bf-474a-bdd3-804c8da7e874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: torch.Size([100000, 256])\n"
          ]
        }
      ],
      "source": [
        "# !! NEW - max_length=512\n",
        "\n",
        "DATA_PARAMS = {\n",
        "  \"max_length\": 256,\n",
        "  \"batch_size\": 2,\n",
        "}\n",
        "\n",
        "# Tokenize training texts with padding and truncation.\n",
        "encodings = tokenizer(train_texts, return_tensors='pt', padding=True, truncation=True, max_length=DATA_PARAMS['max_length'])\n",
        "input_ids = encodings['input_ids']\n",
        "attention_mask = encodings['attention_mask']\n",
        "\n",
        "# For causal language modeling, use input_ids as labels.\n",
        "# Replace pad token positions with -100 so that they are ignored by the loss.\n",
        "\n",
        "#creates a copy of your input IDs, so you can modify them without affecting the original tensor.\n",
        "labels = input_ids.clone()\n",
        "\n",
        "#replaces all padding token positions with -100. This is a common convention (especially with PyTorch‚Äôs CrossEntropyLoss)\n",
        "# to indicate that these positions should be ignored during loss computatio\n",
        "labels[input_ids == tokenizer.pad_token_id] = -100\n",
        "\n",
        "print(\"Training data shape:\", input_ids.shape)\n",
        "\n",
        "\n",
        "# !! NEW - num_workers=4, pin_memory=True\n",
        "# Create a TensorDataset and DataLoader with a small batch size.\n",
        "train_dataset = TensorDataset(input_ids, attention_mask, labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=DATA_PARAMS['batch_size'], shuffle=True, drop_last=True, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yda7cPXHH9kl"
      },
      "source": [
        "## Optimizer & Privacy engine setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nNoZnmXSeXhv"
      },
      "outputs": [],
      "source": [
        "# !! NEW\n",
        "# optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "P4pqKECaH-7T"
      },
      "outputs": [],
      "source": [
        "# privacy_engine = PrivacyEngine()\n",
        "# model, optimizer, train_loader = privacy_engine.make_private(\n",
        "#     module=model,\n",
        "#     optimizer=optimizer,\n",
        "#     data_loader=train_loader,\n",
        "#     noise_multiplier=0.3,      # Lower noise multiplier to reduce added noise\n",
        "#     max_grad_norm=5,           # Increase clipping norm to allow larger gradients\n",
        "#     batch_first=True,\n",
        "#     loss_reduction=\"mean\",\n",
        "#     poisson_sampling=False      # UPDATE - ERRORING OUT, SO NOT USING. Use Poisson sampling for potentially more stable training\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydDru4H6pMXR"
      },
      "source": [
        "## Tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "qLr62h6jpLpO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import datetime\n",
        "import pytz # PST time zone\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "class TrainingTracker:\n",
        "    def __init__(self, base_dir=\"./tracking_results\"):\n",
        "        \"\"\"\n",
        "        Initialize the training tracker.\n",
        "\n",
        "        Args:\n",
        "            base_dir: Directory to save tracking results\n",
        "        \"\"\"\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.base_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "        # Generate a unique run ID based on timestamp\n",
        "        # Define PST timezone\n",
        "        pst = pytz.timezone(\"America/Los_Angeles\")\n",
        "        # Get current time in PST\n",
        "        pst_time = datetime.datetime.now(pytz.utc).astimezone(pst)\n",
        "        # Format the time\n",
        "        timestamp = pst_time.strftime(\"%d-%m_%H-%M-%S\")\n",
        "        # timestamp = datetime.datetime.now().strftime(\"%d-%m_%H-%M-%S\")\n",
        "        self.run_id = f\"run_{timestamp}\"\n",
        "\n",
        "        # Create run directory\n",
        "        self.run_dir = self.base_dir / self.run_id\n",
        "        self.run_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        # Initialize tracking data structures\n",
        "        self.params = {}\n",
        "        self.epoch_metrics = []\n",
        "        self.generated_samples = []\n",
        "        self.privacy_metrics = {}\n",
        "\n",
        "    def record_parameters(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Record training parameters for the current run.\n",
        "\n",
        "        Args:\n",
        "            **kwargs: Key-value pairs of parameters to record\n",
        "        \"\"\"\n",
        "        self.params.update(kwargs)\n",
        "\n",
        "        # Save parameters to file\n",
        "        with open(self.run_dir / \"parameters.json\", \"w\") as f:\n",
        "            json.dump(self.params, f, indent=4)\n",
        "\n",
        "    def record_epoch_metrics(self, epoch, loss, batch_times=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Record metrics for a training epoch.\n",
        "\n",
        "        Args:\n",
        "            epoch: Current epoch number\n",
        "            loss: Loss value for the epoch\n",
        "            batch_times: Optional list of batch processing times\n",
        "            **kwargs: Additional metrics to record\n",
        "        \"\"\"\n",
        "        metrics = {\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss,\n",
        "            **kwargs\n",
        "        }\n",
        "\n",
        "        if batch_times:\n",
        "            metrics[\"avg_batch_time\"] = sum(batch_times) / len(batch_times)\n",
        "            metrics[\"min_batch_time\"] = min(batch_times)\n",
        "            metrics[\"max_batch_time\"] = max(batch_times)\n",
        "\n",
        "        self.epoch_metrics.append(metrics)\n",
        "\n",
        "        # Save updated metrics to file\n",
        "        with open(self.run_dir / \"epoch_metrics.json\", \"w\") as f:\n",
        "            json.dump(self.epoch_metrics, f, indent=4)\n",
        "\n",
        "        # Also save as CSV for easier analysis\n",
        "        pd.DataFrame(self.epoch_metrics).to_csv(\n",
        "            self.run_dir / \"epoch_metrics.csv\", index=False)\n",
        "\n",
        "    def record_privacy_budget(self, epsilon, delta=1e-5, **kwargs):\n",
        "        \"\"\"\n",
        "        Record privacy budget metrics.\n",
        "\n",
        "        Args:\n",
        "            epsilon: Achieved epsilon value\n",
        "            delta: Delta value used\n",
        "            **kwargs: Additional privacy metrics\n",
        "        \"\"\"\n",
        "        self.privacy_metrics = {\n",
        "            \"epsilon\": epsilon,\n",
        "            \"delta\": delta,\n",
        "            **kwargs\n",
        "        }\n",
        "\n",
        "        # Save privacy metrics to file\n",
        "        with open(self.run_dir / \"privacy_metrics.json\", \"w\") as f:\n",
        "            json.dump(self.privacy_metrics, f, indent=4)\n",
        "\n",
        "    def record_sample(self, prompt, generated_text):\n",
        "        \"\"\"\n",
        "        Record a sample of generated text.\n",
        "\n",
        "        Args:\n",
        "            prompt: Input prompt\n",
        "            generated_text: Generated text output\n",
        "        \"\"\"\n",
        "        sample = {\n",
        "            \"prompt\": prompt,\n",
        "            \"generated_text\": generated_text,\n",
        "            \"timestamp\": datetime.datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        self.generated_samples.append(sample)\n",
        "\n",
        "        # Save samples to file\n",
        "        with open(self.run_dir / \"generated_samples.json\", \"w\") as f:\n",
        "            json.dump(self.generated_samples, f, indent=4)\n",
        "\n",
        "    def save_model_info(self, model_path, model_type, tokenizer_info=None):\n",
        "        \"\"\"\n",
        "        Record information about the saved model.\n",
        "\n",
        "        Args:\n",
        "            model_path: Path where model was saved\n",
        "            model_type: Type of model (e.g., \"with_dp\", \"without_dp\")\n",
        "            tokenizer_info: Additional tokenizer information\n",
        "        \"\"\"\n",
        "        model_info = {\n",
        "            \"model_path\": str(model_path),\n",
        "            \"model_type\": model_type,\n",
        "            \"tokenizer_info\": tokenizer_info or {}\n",
        "        }\n",
        "\n",
        "        # Save model info to file\n",
        "        with open(self.run_dir / \"model_info.json\", \"w\") as f:\n",
        "            json.dump(model_info, f, indent=4)\n",
        "\n",
        "    def generate_summary(self):\n",
        "        \"\"\"\n",
        "        Generate a summary of the training run.\n",
        "\n",
        "        Returns:\n",
        "            str: Summary text\n",
        "        \"\"\"\n",
        "        summary_lines = [\n",
        "            f\"Training Run: {self.run_id}\",\n",
        "            \"=\" * 50,\n",
        "            \"\\nParameters:\",\n",
        "        ]\n",
        "\n",
        "        for key, value in self.params.items():\n",
        "            summary_lines.append(f\"  {key}: {value}\")\n",
        "\n",
        "        if self.epoch_metrics:\n",
        "            summary_lines.extend([\n",
        "                \"\\nTraining Results:\",\n",
        "                f\"  Epochs completed: {len(self.epoch_metrics)}\",\n",
        "                f\"  Final loss: {self.epoch_metrics[-1]['loss']:.6f}\",\n",
        "                f\"  Initial loss: {self.epoch_metrics[0]['loss']:.6f}\",\n",
        "                f\"  Loss reduction: {self.epoch_metrics[0]['loss'] - self.epoch_metrics[-1]['loss']:.6f}\"\n",
        "            ])\n",
        "\n",
        "        if self.privacy_metrics:\n",
        "            summary_lines.extend([\n",
        "                \"\\nPrivacy Budget:\",\n",
        "                f\"  Epsilon: {self.privacy_metrics['epsilon']:.4f}\",\n",
        "                f\"  Delta: {self.privacy_metrics['delta']}\"\n",
        "            ])\n",
        "\n",
        "        summary_text = \"\\n\".join(summary_lines)\n",
        "\n",
        "        # Save summary to file\n",
        "        with open(self.run_dir / \"summary.txt\", \"w\") as f:\n",
        "            f.write(summary_text)\n",
        "\n",
        "        return summary_text\n",
        "\n",
        "    # def compare_with_previous_runs(self, metric=\"loss\"):\n",
        "    #     \"\"\"\n",
        "    #     Compare this run with previous runs based on a specific metric.\n",
        "\n",
        "    #     Args:\n",
        "    #         metric: Metric to compare (default: \"loss\")\n",
        "\n",
        "    #     Returns:\n",
        "    #         DataFrame: Comparison data\n",
        "    #     \"\"\"\n",
        "    #     # Collect data from all previous runs\n",
        "    #     all_runs = []\n",
        "\n",
        "    #     for run_dir in self.base_dir.iterdir():\n",
        "    #         if not run_dir.is_dir() or run_dir == self.run_dir:\n",
        "    #             continue\n",
        "\n",
        "    #         params_file = run_dir / \"parameters.json\"\n",
        "    #         metrics_file = run_dir / \"epoch_metrics.json\"\n",
        "\n",
        "    #         if params_file.exists() and metrics_file.exists():\n",
        "    #             with open(params_file, \"r\") as f:\n",
        "    #                 params = json.load(f)\n",
        "\n",
        "    #             with open(metrics_file, \"r\") as f:\n",
        "    #                 metrics = json.load(f)\n",
        "\n",
        "    #             if metrics:\n",
        "    #                 final_metric = metrics[-1].get(metric)\n",
        "\n",
        "    #                 run_data = {\n",
        "    #                     \"run_id\": run_dir.name,\n",
        "    #                     f\"final_{metric}\": final_metric,\n",
        "    #                     **params\n",
        "    #                 }\n",
        "\n",
        "    #                 all_runs.append(run_data)\n",
        "\n",
        "    #     # Add current run\n",
        "    #     if self.epoch_metrics:\n",
        "    #         current_run_data = {\n",
        "    #             \"run_id\": self.run_id,\n",
        "    #             f\"final_{metric}\": self.epoch_metrics[-1].get(metric),\n",
        "    #             **self.params\n",
        "    #         }\n",
        "    #         all_runs.append(current_run_data)\n",
        "\n",
        "    #     # Convert to DataFrame and sort\n",
        "    #     if all_runs:\n",
        "    #         df = pd.DataFrame(all_runs)\n",
        "    #         df = df.sort_values(by=f\"final_{metric}\")\n",
        "\n",
        "    #         # Save comparison to file\n",
        "    #         df.to_csv(self.run_dir / f\"comparison_{metric}.csv\", index=False)\n",
        "\n",
        "    #         return df\n",
        "\n",
        "    #     return pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "rNSHqUqOCjWS"
      },
      "outputs": [],
      "source": [
        "# Record initial parameters after setting them up\n",
        "def record_initial_params():\n",
        "    # Record model configuration\n",
        "    tracker.record_parameters(\n",
        "        model_name=model_name,\n",
        "        device=str(device),\n",
        "        epochs=epochs,\n",
        "        batch_size=train_loader.batch_size,\n",
        "        learning_rate=optimizer.param_groups[0]['lr'],\n",
        "        gradient_accumulation_steps=accumulation_steps,\n",
        "\n",
        "        # LoRA parameters\n",
        "        lora_r=lora_config.r,\n",
        "        lora_alpha=lora_config.lora_alpha,\n",
        "        lora_dropout=lora_config.lora_dropout,\n",
        "        lora_target_modules=list(lora_config.target_modules),\n",
        "\n",
        "        # Privacy parameters (if using Opacus)\n",
        "        using_differential_privacy=hasattr(model, \"remove_hooks\"),\n",
        "        noise_multiplier=0.6 if hasattr(model, \"remove_hooks\") else None,\n",
        "        max_grad_norm=1.5 if hasattr(model, \"remove_hooks\") else None,\n",
        "\n",
        "        # Dataset info\n",
        "        dataset_size=len(formatted_strings),\n",
        "        avg_sample_length=sum(len(s) for s in formatted_strings) / len(formatted_strings),\n",
        "        tokenizer_max_length=DATA_PARAMS['max_length'],  # From tokenization step\n",
        "        data_batch_size=DATA_PARAMS['batch_size'],\n",
        "\n",
        "        # Tokenizer info\n",
        "        tokenizer_vocab_size=len(tokenizer),\n",
        "        tokenizer_model_max_length=tokenizer.model_max_length,\n",
        "\n",
        "\n",
        "        # System info\n",
        "        cuda_available=torch.cuda.is_available(),\n",
        "        gpu_name=torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjdbmm3wIB0M"
      },
      "source": [
        "## Training setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4iRZnGXfGgij"
      },
      "outputs": [],
      "source": [
        "epochs = 4 if RUN_MODE == \"main\" else 1\n",
        "\n",
        "# !! NEW\n",
        "scaler = GradScaler('cuda')  # Create a gradient scaler to manage FP16 stability\n",
        "accumulation_steps = 1  # Set gradient accumulation steps; use >1 to simulate larger batch sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Fxzk9pcCCacI"
      },
      "outputs": [],
      "source": [
        "# Initialize the tracker before loading the model\n",
        "tracker = TrainingTracker()\n",
        "# Call this after all parameters are set but before training starts\n",
        "record_initial_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aZm-yQCJOdve",
        "outputId": "6101b378-6c06-42b5-bbd7-e0f496c5b570"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaSdpaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training loop\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7oX2UspPfxx"
      },
      "source": [
        "## Sanity check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SjuGRlmwPg2r",
        "outputId": "e464483f-9b06-46b8-b96d-0ee9b414d39f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'meta-llama/Llama-3.1-8B'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMVloS-nPiBu",
        "outputId": "a3cf7798-b84b-4ccf-fbd6-8cb455d1ae92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guGBiDbgPi8_",
        "outputId": "7d3c1f52-fb53-487a-f71d-4644cf1331f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sop-hygFaiS",
        "outputId": "e32c9f72-e6d1-4c99-d236-7e10fc2c4d02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model_name': 'meta-llama/Llama-3.1-8B',\n",
              " 'device': 'cuda',\n",
              " 'epochs': 4,\n",
              " 'batch_size': 2,\n",
              " 'learning_rate': 1e-05,\n",
              " 'gradient_accumulation_steps': 1,\n",
              " 'lora_r': 8,\n",
              " 'lora_alpha': 16,\n",
              " 'lora_dropout': 0.05,\n",
              " 'lora_target_modules': ['q_proj',\n",
              "  'o_proj',\n",
              "  'gate_proj',\n",
              "  'v_proj',\n",
              "  'k_proj',\n",
              "  'up_proj'],\n",
              " 'using_differential_privacy': False,\n",
              " 'noise_multiplier': None,\n",
              " 'max_grad_norm': None,\n",
              " 'dataset_size': 100000,\n",
              " 'avg_sample_length': 649.61317,\n",
              " 'tokenizer_max_length': 256,\n",
              " 'data_batch_size': 2,\n",
              " 'tokenizer_vocab_size': 128256,\n",
              " 'tokenizer_model_max_length': 131072,\n",
              " 'cuda_available': True,\n",
              " 'gpu_name': 'NVIDIA L4'}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tracker.params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQyW5yCiPd68"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "eCilSHLsfGGa"
      },
      "outputs": [],
      "source": [
        "# # FINETUNING, NOT WORKING NOW\n",
        "# for epoch in range(epochs):  # Loop over each epoch\n",
        "#     total_loss = 0.0  # Initialize total loss accumulator for the epoch\n",
        "#     optimizer.zero_grad()  # Zero gradients at the start of the epoch\n",
        "#     for i, batch in enumerate(train_loader):  # Loop over mini-batches from the DataLoader\n",
        "#         # Move each tensor in the batch to the device (GPU) asynchronously if pin_memory is True\n",
        "#         input_ids_batch, attention_mask_batch, labels_batch = [\n",
        "#             x.to(device, non_blocking=True) for x in batch\n",
        "#         ]\n",
        "\n",
        "#         # Determine the sequence length for the current batch and create position IDs accordingly\n",
        "#         seq_len = input_ids_batch.size(1)  # Get the sequence length from the input tensor\n",
        "#         # Create a tensor [0, 1, ..., seq_len-1] and repeat it for each item in the batch\n",
        "#         position_ids = torch.arange(seq_len, device=device).unsqueeze(0).repeat(input_ids_batch.size(0), 1)\n",
        "\n",
        "#         # Use mixed precision context for the forward pass to save memory and speed up computation\n",
        "#         with autocast():\n",
        "#             outputs = model(\n",
        "#                 input_ids=input_ids_batch,        # Input token IDs for the model\n",
        "#                 attention_mask=attention_mask_batch,  # Attention mask to differentiate padded tokens\n",
        "#                 position_ids=position_ids,          # Positional IDs for the tokens\n",
        "#                 labels=labels_batch                 # Labels for computing the loss (typically same as input_ids for causal LM)\n",
        "#             )\n",
        "#             # Compute the loss; if using gradient accumulation, scale down the loss accordingly\n",
        "#             loss = outputs.loss / accumulation_steps\n",
        "\n",
        "#         # Scale the loss and perform the backward pass using the GradScaler for FP16 stability\n",
        "#         scaler.scale(loss).backward()\n",
        "\n",
        "#         # Every 'accumulation_steps' iterations, update the model weights\n",
        "#         if (i + 1) % accumulation_steps == 0:\n",
        "#             scaler.step(optimizer)  # Update parameters using scaled gradients\n",
        "#             scaler.update()         # Update the scale for the next iteration\n",
        "#             optimizer.zero_grad()   # Reset gradients after updating\n",
        "\n",
        "#         # Accumulate the loss (multiply back to undo the earlier division, so total_loss is in original scale)\n",
        "#         total_loss += loss.item() * accumulation_steps\n",
        "\n",
        "#         # Optionally, print progress every 50 batches\n",
        "#         if i % 50 == 0:\n",
        "#             print(f\"Batch {i} processed.\")\n",
        "\n",
        "#     # Compute the average loss over the epoch\n",
        "#     avg_loss = total_loss / len(train_loader)\n",
        "#     print(f\"Epoch {epoch+1}/{epochs} - Average loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Guo1CVB3fLLr",
        "outputId": "1444c720-29c1-4628-f3a2-f8e01f337be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4 - Batch 0/50000 - Loss: 2.5222\n",
            "Epoch 1/4 - Batch 50/50000 - Loss: 2.4104\n",
            "Epoch 1/4 - Batch 100/50000 - Loss: 1.9589\n",
            "Epoch 1/4 - Batch 150/50000 - Loss: 1.8822\n",
            "Epoch 1/4 - Batch 200/50000 - Loss: 2.1070\n",
            "Epoch 1/4 - Batch 250/50000 - Loss: 1.8278\n",
            "Epoch 1/4 - Batch 300/50000 - Loss: 1.5740\n",
            "Epoch 1/4 - Batch 350/50000 - Loss: 2.1027\n",
            "Epoch 1/4 - Batch 400/50000 - Loss: 1.6017\n",
            "Epoch 1/4 - Batch 450/50000 - Loss: 1.7033\n",
            "Epoch 1/4 - Batch 500/50000 - Loss: 1.8461\n",
            "Epoch 1/4 - Batch 550/50000 - Loss: 2.3212\n",
            "Epoch 1/4 - Batch 600/50000 - Loss: 1.4143\n",
            "Epoch 1/4 - Batch 650/50000 - Loss: 1.8237\n",
            "Epoch 1/4 - Batch 700/50000 - Loss: 1.8592\n",
            "Epoch 1/4 - Batch 750/50000 - Loss: 1.3918\n",
            "Epoch 1/4 - Batch 800/50000 - Loss: 1.0824\n",
            "Epoch 1/4 - Batch 850/50000 - Loss: 1.8128\n",
            "Epoch 1/4 - Batch 900/50000 - Loss: 1.3815\n",
            "Epoch 1/4 - Batch 950/50000 - Loss: 1.3863\n",
            "Epoch 1/4 - Batch 1000/50000 - Loss: 1.5545\n",
            "Epoch 1/4 - Batch 1050/50000 - Loss: 1.9510\n",
            "Epoch 1/4 - Batch 1100/50000 - Loss: 1.5360\n",
            "Epoch 1/4 - Batch 1150/50000 - Loss: 1.5115\n",
            "Epoch 1/4 - Batch 1200/50000 - Loss: 1.3599\n",
            "Epoch 1/4 - Batch 1250/50000 - Loss: 1.4875\n",
            "Epoch 1/4 - Batch 1300/50000 - Loss: 1.6215\n",
            "Epoch 1/4 - Batch 1350/50000 - Loss: 1.3999\n",
            "Epoch 1/4 - Batch 1400/50000 - Loss: 1.7691\n",
            "Epoch 1/4 - Batch 1450/50000 - Loss: 1.2695\n",
            "Epoch 1/4 - Batch 1500/50000 - Loss: 1.6714\n",
            "Epoch 1/4 - Batch 1550/50000 - Loss: 1.6443\n",
            "Epoch 1/4 - Batch 1600/50000 - Loss: 1.6405\n",
            "Epoch 1/4 - Batch 1650/50000 - Loss: 1.7353\n",
            "Epoch 1/4 - Batch 1700/50000 - Loss: 1.6874\n",
            "Epoch 1/4 - Batch 1750/50000 - Loss: 1.3866\n",
            "Epoch 1/4 - Batch 1800/50000 - Loss: 1.7182\n",
            "Epoch 1/4 - Batch 1850/50000 - Loss: 1.3049\n",
            "Epoch 1/4 - Batch 1900/50000 - Loss: 1.5639\n",
            "Epoch 1/4 - Batch 1950/50000 - Loss: 1.8389\n",
            "Epoch 1/4 - Batch 2000/50000 - Loss: 1.0772\n",
            "Epoch 1/4 - Batch 2050/50000 - Loss: 1.7144\n",
            "Epoch 1/4 - Batch 2100/50000 - Loss: 1.4789\n",
            "Epoch 1/4 - Batch 2150/50000 - Loss: 1.4716\n",
            "Epoch 1/4 - Batch 2200/50000 - Loss: 1.0951\n",
            "Epoch 1/4 - Batch 2250/50000 - Loss: 1.8893\n",
            "Epoch 1/4 - Batch 2300/50000 - Loss: 1.9270\n",
            "Epoch 1/4 - Batch 2350/50000 - Loss: 1.3788\n",
            "Epoch 1/4 - Batch 2400/50000 - Loss: 1.5197\n",
            "Epoch 1/4 - Batch 2450/50000 - Loss: 1.9426\n",
            "Epoch 1/4 - Batch 2500/50000 - Loss: 1.7543\n",
            "Epoch 1/4 - Batch 2550/50000 - Loss: 1.9042\n",
            "Epoch 1/4 - Batch 2600/50000 - Loss: 1.7241\n",
            "Epoch 1/4 - Batch 2650/50000 - Loss: 1.9227\n",
            "Epoch 1/4 - Batch 2700/50000 - Loss: 1.6326\n",
            "Epoch 1/4 - Batch 2750/50000 - Loss: 1.0680\n",
            "Epoch 1/4 - Batch 2800/50000 - Loss: 1.4345\n",
            "Epoch 1/4 - Batch 2850/50000 - Loss: 1.7380\n",
            "Epoch 1/4 - Batch 2900/50000 - Loss: 1.6898\n",
            "Epoch 1/4 - Batch 2950/50000 - Loss: 1.7559\n",
            "Epoch 1/4 - Batch 3000/50000 - Loss: 1.5985\n",
            "Epoch 1/4 - Batch 3050/50000 - Loss: 1.7211\n",
            "Epoch 1/4 - Batch 3100/50000 - Loss: 2.0062\n",
            "Epoch 1/4 - Batch 3150/50000 - Loss: 1.8651\n",
            "Epoch 1/4 - Batch 3200/50000 - Loss: 1.3508\n",
            "Epoch 1/4 - Batch 3250/50000 - Loss: 1.5157\n",
            "Epoch 1/4 - Batch 3300/50000 - Loss: 1.2775\n",
            "Epoch 1/4 - Batch 3350/50000 - Loss: 1.5915\n",
            "Epoch 1/4 - Batch 3400/50000 - Loss: 2.2179\n",
            "Epoch 1/4 - Batch 3450/50000 - Loss: 1.6948\n",
            "Epoch 1/4 - Batch 3500/50000 - Loss: 1.3696\n",
            "Epoch 1/4 - Batch 3550/50000 - Loss: 1.5274\n",
            "Epoch 1/4 - Batch 3600/50000 - Loss: 1.5674\n",
            "Epoch 1/4 - Batch 3650/50000 - Loss: 1.9657\n",
            "Epoch 1/4 - Batch 3700/50000 - Loss: 1.1219\n",
            "Epoch 1/4 - Batch 3750/50000 - Loss: 1.3684\n",
            "Epoch 1/4 - Batch 3800/50000 - Loss: 2.0099\n",
            "Epoch 1/4 - Batch 3850/50000 - Loss: 1.3342\n",
            "Epoch 1/4 - Batch 3900/50000 - Loss: 0.8929\n",
            "Epoch 1/4 - Batch 3950/50000 - Loss: 1.8834\n",
            "Epoch 1/4 - Batch 4000/50000 - Loss: 1.6643\n",
            "Epoch 1/4 - Batch 4050/50000 - Loss: 1.3696\n",
            "Epoch 1/4 - Batch 4100/50000 - Loss: 1.4281\n",
            "Epoch 1/4 - Batch 4150/50000 - Loss: 1.8233\n",
            "Epoch 1/4 - Batch 4200/50000 - Loss: 1.7401\n",
            "Epoch 1/4 - Batch 4250/50000 - Loss: 1.0980\n",
            "Epoch 1/4 - Batch 4300/50000 - Loss: 1.9629\n",
            "Epoch 1/4 - Batch 4350/50000 - Loss: 1.4203\n",
            "Epoch 1/4 - Batch 4400/50000 - Loss: 1.6974\n",
            "Epoch 1/4 - Batch 4450/50000 - Loss: 1.4299\n",
            "Epoch 1/4 - Batch 4500/50000 - Loss: 1.1081\n",
            "Epoch 1/4 - Batch 4550/50000 - Loss: 1.4200\n",
            "Epoch 1/4 - Batch 4600/50000 - Loss: 1.2463\n",
            "Epoch 1/4 - Batch 4650/50000 - Loss: 1.8164\n",
            "Epoch 1/4 - Batch 4700/50000 - Loss: 1.2953\n",
            "Epoch 1/4 - Batch 4750/50000 - Loss: 1.7550\n",
            "Epoch 1/4 - Batch 4800/50000 - Loss: 1.1399\n",
            "Epoch 1/4 - Batch 4850/50000 - Loss: 1.7602\n",
            "Epoch 1/4 - Batch 4900/50000 - Loss: 1.1256\n",
            "Epoch 1/4 - Batch 4950/50000 - Loss: 1.2418\n",
            "Epoch 1/4 - Batch 5000/50000 - Loss: 2.0278\n",
            "Epoch 1/4 - Batch 5050/50000 - Loss: 1.6494\n",
            "Epoch 1/4 - Batch 5100/50000 - Loss: 1.0901\n",
            "Epoch 1/4 - Batch 5150/50000 - Loss: 1.2546\n",
            "Epoch 1/4 - Batch 5200/50000 - Loss: 1.6769\n",
            "Epoch 1/4 - Batch 5250/50000 - Loss: 1.6363\n",
            "Epoch 1/4 - Batch 5300/50000 - Loss: 1.5789\n",
            "Epoch 1/4 - Batch 5350/50000 - Loss: 1.8274\n",
            "Epoch 1/4 - Batch 5400/50000 - Loss: 1.1601\n",
            "Epoch 1/4 - Batch 5450/50000 - Loss: 1.8407\n",
            "Epoch 1/4 - Batch 5500/50000 - Loss: 1.9009\n",
            "Epoch 1/4 - Batch 5550/50000 - Loss: 1.3882\n",
            "Epoch 1/4 - Batch 5600/50000 - Loss: 1.6539\n",
            "Epoch 1/4 - Batch 5650/50000 - Loss: 1.4023\n",
            "Epoch 1/4 - Batch 5700/50000 - Loss: 1.5859\n",
            "Epoch 1/4 - Batch 5750/50000 - Loss: 1.6197\n",
            "Epoch 1/4 - Batch 5800/50000 - Loss: 1.5252\n",
            "Epoch 1/4 - Batch 5850/50000 - Loss: 1.9297\n",
            "Epoch 1/4 - Batch 5900/50000 - Loss: 1.6389\n",
            "Epoch 1/4 - Batch 5950/50000 - Loss: 1.8901\n",
            "Epoch 1/4 - Batch 6000/50000 - Loss: 1.3301\n",
            "Epoch 1/4 - Batch 6050/50000 - Loss: 1.3727\n",
            "Epoch 1/4 - Batch 6100/50000 - Loss: 1.2039\n",
            "Epoch 1/4 - Batch 6150/50000 - Loss: 1.2430\n",
            "Epoch 1/4 - Batch 6200/50000 - Loss: 1.0437\n",
            "Epoch 1/4 - Batch 6250/50000 - Loss: 1.6473\n",
            "Epoch 1/4 - Batch 6300/50000 - Loss: 1.8976\n",
            "Epoch 1/4 - Batch 6350/50000 - Loss: 1.5093\n",
            "Epoch 1/4 - Batch 6400/50000 - Loss: 1.6084\n",
            "Epoch 1/4 - Batch 6450/50000 - Loss: 1.9359\n",
            "Epoch 1/4 - Batch 6500/50000 - Loss: 1.4276\n",
            "Epoch 1/4 - Batch 6550/50000 - Loss: 1.3957\n",
            "Epoch 1/4 - Batch 6600/50000 - Loss: 1.8491\n",
            "Epoch 1/4 - Batch 6650/50000 - Loss: 1.4964\n",
            "Epoch 1/4 - Batch 6700/50000 - Loss: 1.2194\n",
            "Epoch 1/4 - Batch 6750/50000 - Loss: 1.0036\n",
            "Epoch 1/4 - Batch 6800/50000 - Loss: 1.6604\n",
            "Epoch 1/4 - Batch 6850/50000 - Loss: 1.3125\n",
            "Epoch 1/4 - Batch 6900/50000 - Loss: 1.5180\n",
            "Epoch 1/4 - Batch 6950/50000 - Loss: 1.1226\n",
            "Epoch 1/4 - Batch 7000/50000 - Loss: 1.4030\n",
            "Epoch 1/4 - Batch 7050/50000 - Loss: 1.5087\n",
            "Epoch 1/4 - Batch 7100/50000 - Loss: 1.5353\n",
            "Epoch 1/4 - Batch 7150/50000 - Loss: 1.7637\n",
            "Epoch 1/4 - Batch 7200/50000 - Loss: 1.1820\n",
            "Epoch 1/4 - Batch 7250/50000 - Loss: 1.6084\n",
            "Epoch 1/4 - Batch 7300/50000 - Loss: 1.8991\n",
            "Epoch 1/4 - Batch 7350/50000 - Loss: 1.6269\n",
            "Epoch 1/4 - Batch 7400/50000 - Loss: 1.3833\n",
            "Epoch 1/4 - Batch 7450/50000 - Loss: 0.8918\n",
            "Epoch 1/4 - Batch 7500/50000 - Loss: 1.5658\n",
            "Epoch 1/4 - Batch 7550/50000 - Loss: 1.8153\n",
            "Epoch 1/4 - Batch 7600/50000 - Loss: 1.2865\n",
            "Epoch 1/4 - Batch 7650/50000 - Loss: 1.9778\n",
            "Epoch 1/4 - Batch 7700/50000 - Loss: 1.6265\n",
            "Epoch 1/4 - Batch 7750/50000 - Loss: 1.3136\n",
            "Epoch 1/4 - Batch 7800/50000 - Loss: 1.3430\n",
            "Epoch 1/4 - Batch 7850/50000 - Loss: 1.0106\n",
            "Epoch 1/4 - Batch 7900/50000 - Loss: 0.9622\n",
            "Epoch 1/4 - Batch 7950/50000 - Loss: 0.9683\n",
            "Epoch 1/4 - Batch 8000/50000 - Loss: 2.2661\n",
            "Epoch 1/4 - Batch 8050/50000 - Loss: 1.2608\n",
            "Epoch 1/4 - Batch 8100/50000 - Loss: 1.6133\n",
            "Epoch 1/4 - Batch 8150/50000 - Loss: 1.2551\n",
            "Epoch 1/4 - Batch 8200/50000 - Loss: 1.4552\n",
            "Epoch 1/4 - Batch 8250/50000 - Loss: 1.5819\n",
            "Epoch 1/4 - Batch 8300/50000 - Loss: 2.0130\n",
            "Epoch 1/4 - Batch 8350/50000 - Loss: 1.1167\n",
            "Epoch 1/4 - Batch 8400/50000 - Loss: 1.2945\n",
            "Epoch 1/4 - Batch 8450/50000 - Loss: 1.8626\n",
            "Epoch 1/4 - Batch 8500/50000 - Loss: 0.9153\n",
            "Epoch 1/4 - Batch 8550/50000 - Loss: 1.9787\n",
            "Epoch 1/4 - Batch 8600/50000 - Loss: 1.6133\n",
            "Epoch 1/4 - Batch 8650/50000 - Loss: 1.5689\n",
            "Epoch 1/4 - Batch 8700/50000 - Loss: 2.0300\n",
            "Epoch 1/4 - Batch 8750/50000 - Loss: 1.9158\n",
            "Epoch 1/4 - Batch 8800/50000 - Loss: 1.0816\n",
            "Epoch 1/4 - Batch 8850/50000 - Loss: 1.4801\n",
            "Epoch 1/4 - Batch 8900/50000 - Loss: 1.2678\n",
            "Epoch 1/4 - Batch 8950/50000 - Loss: 1.3356\n",
            "Epoch 1/4 - Batch 9000/50000 - Loss: 0.8773\n",
            "Epoch 1/4 - Batch 9050/50000 - Loss: 2.0142\n",
            "Epoch 1/4 - Batch 9100/50000 - Loss: 1.6164\n",
            "Epoch 1/4 - Batch 9150/50000 - Loss: 1.7107\n",
            "Epoch 1/4 - Batch 9200/50000 - Loss: 1.2726\n",
            "Epoch 1/4 - Batch 9250/50000 - Loss: 0.8470\n",
            "Epoch 1/4 - Batch 9300/50000 - Loss: 1.4560\n",
            "Epoch 1/4 - Batch 9350/50000 - Loss: 1.2951\n",
            "Epoch 1/4 - Batch 9400/50000 - Loss: 1.6086\n",
            "Epoch 1/4 - Batch 9450/50000 - Loss: 1.6852\n",
            "Epoch 1/4 - Batch 9500/50000 - Loss: 1.4529\n",
            "Epoch 1/4 - Batch 9550/50000 - Loss: 1.7083\n",
            "Epoch 1/4 - Batch 9600/50000 - Loss: 1.1991\n",
            "Epoch 1/4 - Batch 9650/50000 - Loss: 1.0731\n",
            "Epoch 1/4 - Batch 9700/50000 - Loss: 2.1382\n",
            "Epoch 1/4 - Batch 9750/50000 - Loss: 1.5273\n",
            "Epoch 1/4 - Batch 9800/50000 - Loss: 2.0514\n",
            "Epoch 1/4 - Batch 9850/50000 - Loss: 0.8755\n",
            "Epoch 1/4 - Batch 9900/50000 - Loss: 1.5956\n",
            "Epoch 1/4 - Batch 9950/50000 - Loss: 1.2298\n",
            "Epoch 1/4 - Batch 10000/50000 - Loss: 1.0003\n",
            "Epoch 1/4 - Batch 10050/50000 - Loss: 1.2747\n",
            "Epoch 1/4 - Batch 10100/50000 - Loss: 1.9078\n",
            "Epoch 1/4 - Batch 10150/50000 - Loss: 1.4459\n",
            "Epoch 1/4 - Batch 10200/50000 - Loss: 1.9133\n",
            "Epoch 1/4 - Batch 10250/50000 - Loss: 1.0070\n",
            "Epoch 1/4 - Batch 10300/50000 - Loss: 1.2786\n",
            "Epoch 1/4 - Batch 10350/50000 - Loss: 0.7920\n",
            "Epoch 1/4 - Batch 10400/50000 - Loss: 1.1253\n",
            "Epoch 1/4 - Batch 10450/50000 - Loss: 1.2452\n",
            "Epoch 1/4 - Batch 10500/50000 - Loss: 1.4050\n",
            "Epoch 1/4 - Batch 10550/50000 - Loss: 1.4690\n",
            "Epoch 1/4 - Batch 10600/50000 - Loss: 1.6646\n",
            "Epoch 1/4 - Batch 10650/50000 - Loss: 1.0531\n",
            "Epoch 1/4 - Batch 10700/50000 - Loss: 1.0930\n",
            "Epoch 1/4 - Batch 10750/50000 - Loss: 1.2903\n",
            "Epoch 1/4 - Batch 10800/50000 - Loss: 2.0118\n",
            "Epoch 1/4 - Batch 10850/50000 - Loss: 2.1094\n",
            "Epoch 1/4 - Batch 10900/50000 - Loss: 1.4502\n",
            "Epoch 1/4 - Batch 10950/50000 - Loss: 1.3797\n",
            "Epoch 1/4 - Batch 11000/50000 - Loss: 1.1932\n",
            "Epoch 1/4 - Batch 11050/50000 - Loss: 1.4511\n",
            "Epoch 1/4 - Batch 11100/50000 - Loss: 1.8219\n",
            "Epoch 1/4 - Batch 11150/50000 - Loss: 1.5244\n",
            "Epoch 1/4 - Batch 11200/50000 - Loss: 0.7846\n",
            "Epoch 1/4 - Batch 11250/50000 - Loss: 1.7489\n",
            "Epoch 1/4 - Batch 11300/50000 - Loss: 1.6209\n",
            "Epoch 1/4 - Batch 11350/50000 - Loss: 1.6673\n",
            "Epoch 1/4 - Batch 11400/50000 - Loss: 1.5519\n",
            "Epoch 1/4 - Batch 11450/50000 - Loss: 1.3754\n",
            "Epoch 1/4 - Batch 11500/50000 - Loss: 0.9639\n",
            "Epoch 1/4 - Batch 11550/50000 - Loss: 1.4857\n",
            "Epoch 1/4 - Batch 11600/50000 - Loss: 1.2139\n",
            "Epoch 1/4 - Batch 11650/50000 - Loss: 1.5994\n",
            "Epoch 1/4 - Batch 11700/50000 - Loss: 1.8492\n",
            "Epoch 1/4 - Batch 11750/50000 - Loss: 1.1956\n",
            "Epoch 1/4 - Batch 11800/50000 - Loss: 1.3857\n",
            "Epoch 1/4 - Batch 11850/50000 - Loss: 1.3067\n",
            "Epoch 1/4 - Batch 11900/50000 - Loss: 1.6161\n",
            "Epoch 1/4 - Batch 11950/50000 - Loss: 1.4489\n",
            "Epoch 1/4 - Batch 12000/50000 - Loss: 1.4373\n",
            "Epoch 1/4 - Batch 12050/50000 - Loss: 0.9439\n",
            "Epoch 1/4 - Batch 12100/50000 - Loss: 0.6086\n",
            "Epoch 1/4 - Batch 12150/50000 - Loss: 1.7852\n",
            "Epoch 1/4 - Batch 12200/50000 - Loss: 1.1658\n",
            "Epoch 1/4 - Batch 12250/50000 - Loss: 1.5198\n",
            "Epoch 1/4 - Batch 12300/50000 - Loss: 2.1602\n",
            "Epoch 1/4 - Batch 12350/50000 - Loss: 1.1820\n",
            "Epoch 1/4 - Batch 12400/50000 - Loss: 1.1988\n",
            "Epoch 1/4 - Batch 12450/50000 - Loss: 1.4648\n",
            "Epoch 1/4 - Batch 12500/50000 - Loss: 1.7325\n",
            "Epoch 1/4 - Batch 12550/50000 - Loss: 1.3318\n",
            "Epoch 1/4 - Batch 12600/50000 - Loss: 1.0561\n",
            "Epoch 1/4 - Batch 12650/50000 - Loss: 1.2309\n",
            "Epoch 1/4 - Batch 12700/50000 - Loss: 1.4841\n",
            "Epoch 1/4 - Batch 12750/50000 - Loss: 1.6013\n",
            "Epoch 1/4 - Batch 12800/50000 - Loss: 1.6539\n",
            "Epoch 1/4 - Batch 12850/50000 - Loss: 1.5781\n",
            "Epoch 1/4 - Batch 12900/50000 - Loss: 0.6372\n",
            "Epoch 1/4 - Batch 12950/50000 - Loss: 1.5547\n",
            "Epoch 1/4 - Batch 13000/50000 - Loss: 1.3432\n",
            "Epoch 1/4 - Batch 13050/50000 - Loss: 1.5895\n",
            "Epoch 1/4 - Batch 13100/50000 - Loss: 1.5681\n",
            "Epoch 1/4 - Batch 13150/50000 - Loss: 1.7288\n",
            "Epoch 1/4 - Batch 13200/50000 - Loss: 1.6117\n",
            "Epoch 1/4 - Batch 13250/50000 - Loss: 1.7849\n",
            "Epoch 1/4 - Batch 13300/50000 - Loss: 0.9527\n",
            "Epoch 1/4 - Batch 13350/50000 - Loss: 1.3732\n",
            "Epoch 1/4 - Batch 13400/50000 - Loss: 1.2696\n",
            "Epoch 1/4 - Batch 13450/50000 - Loss: 1.5143\n",
            "Epoch 1/4 - Batch 13500/50000 - Loss: 1.1760\n",
            "Epoch 1/4 - Batch 13550/50000 - Loss: 1.8611\n",
            "Epoch 1/4 - Batch 13600/50000 - Loss: 1.2247\n",
            "Epoch 1/4 - Batch 13650/50000 - Loss: 1.2835\n",
            "Epoch 1/4 - Batch 13700/50000 - Loss: 1.6261\n",
            "Epoch 1/4 - Batch 13750/50000 - Loss: 1.2385\n",
            "Epoch 1/4 - Batch 13800/50000 - Loss: 1.5104\n",
            "Epoch 1/4 - Batch 13850/50000 - Loss: 1.6310\n",
            "Epoch 1/4 - Batch 13900/50000 - Loss: 0.9886\n",
            "Epoch 1/4 - Batch 13950/50000 - Loss: 1.7888\n",
            "Epoch 1/4 - Batch 14000/50000 - Loss: 1.3359\n",
            "Epoch 1/4 - Batch 14050/50000 - Loss: 1.6296\n",
            "Epoch 1/4 - Batch 14100/50000 - Loss: 1.4408\n",
            "Epoch 1/4 - Batch 14150/50000 - Loss: 1.7031\n",
            "Epoch 1/4 - Batch 14200/50000 - Loss: 1.6662\n",
            "Epoch 1/4 - Batch 14250/50000 - Loss: 1.4654\n",
            "Epoch 1/4 - Batch 14300/50000 - Loss: 2.0410\n",
            "Epoch 1/4 - Batch 14350/50000 - Loss: 1.7621\n",
            "Epoch 1/4 - Batch 14400/50000 - Loss: 1.8491\n",
            "Epoch 1/4 - Batch 14450/50000 - Loss: 1.4889\n",
            "Epoch 1/4 - Batch 14500/50000 - Loss: 1.8026\n",
            "Epoch 1/4 - Batch 14550/50000 - Loss: 1.3157\n",
            "Epoch 1/4 - Batch 14600/50000 - Loss: 1.1250\n",
            "Epoch 1/4 - Batch 14650/50000 - Loss: 1.9591\n",
            "Epoch 1/4 - Batch 14700/50000 - Loss: 1.5131\n",
            "Epoch 1/4 - Batch 14750/50000 - Loss: 1.2857\n",
            "Epoch 1/4 - Batch 14800/50000 - Loss: 1.5311\n",
            "Epoch 1/4 - Batch 14850/50000 - Loss: 0.9889\n",
            "Epoch 1/4 - Batch 14900/50000 - Loss: 1.1517\n",
            "Epoch 1/4 - Batch 14950/50000 - Loss: 1.0855\n",
            "Epoch 1/4 - Batch 15000/50000 - Loss: 1.8459\n",
            "Epoch 1/4 - Batch 15050/50000 - Loss: 1.4657\n",
            "Epoch 1/4 - Batch 15100/50000 - Loss: 1.0805\n",
            "Epoch 1/4 - Batch 15150/50000 - Loss: 1.6371\n",
            "Epoch 1/4 - Batch 15200/50000 - Loss: 1.1786\n",
            "Epoch 1/4 - Batch 15250/50000 - Loss: 1.4717\n",
            "Epoch 1/4 - Batch 15300/50000 - Loss: 1.3305\n",
            "Epoch 1/4 - Batch 15350/50000 - Loss: 0.9585\n",
            "Epoch 1/4 - Batch 15400/50000 - Loss: 1.3247\n",
            "Epoch 1/4 - Batch 15450/50000 - Loss: 1.1788\n",
            "Epoch 1/4 - Batch 15500/50000 - Loss: 1.4149\n",
            "Epoch 1/4 - Batch 15550/50000 - Loss: 1.7625\n",
            "Epoch 1/4 - Batch 15600/50000 - Loss: 1.3052\n",
            "Epoch 1/4 - Batch 15650/50000 - Loss: 1.1482\n",
            "Epoch 1/4 - Batch 15700/50000 - Loss: 1.1867\n",
            "Epoch 1/4 - Batch 15750/50000 - Loss: 1.4535\n",
            "Epoch 1/4 - Batch 15800/50000 - Loss: 1.5068\n",
            "Epoch 1/4 - Batch 15850/50000 - Loss: 1.3287\n",
            "Epoch 1/4 - Batch 15900/50000 - Loss: 1.3755\n",
            "Epoch 1/4 - Batch 15950/50000 - Loss: 1.5980\n",
            "Epoch 1/4 - Batch 16000/50000 - Loss: 1.9057\n",
            "Epoch 1/4 - Batch 16050/50000 - Loss: 1.8088\n",
            "Epoch 1/4 - Batch 16100/50000 - Loss: 1.5612\n",
            "Epoch 1/4 - Batch 16150/50000 - Loss: 1.5089\n",
            "Epoch 1/4 - Batch 16200/50000 - Loss: 1.8979\n",
            "Epoch 1/4 - Batch 16250/50000 - Loss: 1.3332\n",
            "Epoch 1/4 - Batch 16300/50000 - Loss: 1.2883\n",
            "Epoch 1/4 - Batch 16350/50000 - Loss: 1.3170\n",
            "Epoch 1/4 - Batch 16400/50000 - Loss: 1.2471\n",
            "Epoch 1/4 - Batch 16450/50000 - Loss: 0.8815\n",
            "Epoch 1/4 - Batch 16500/50000 - Loss: 1.1113\n",
            "Epoch 1/4 - Batch 16550/50000 - Loss: 0.5992\n",
            "Epoch 1/4 - Batch 16600/50000 - Loss: 1.2696\n",
            "Epoch 1/4 - Batch 16650/50000 - Loss: 1.1593\n",
            "Epoch 1/4 - Batch 16700/50000 - Loss: 1.1792\n",
            "Epoch 1/4 - Batch 16750/50000 - Loss: 1.5637\n",
            "Epoch 1/4 - Batch 16800/50000 - Loss: 1.3079\n",
            "Epoch 1/4 - Batch 16850/50000 - Loss: 1.4675\n",
            "Epoch 1/4 - Batch 16900/50000 - Loss: 1.6136\n",
            "Epoch 1/4 - Batch 16950/50000 - Loss: 0.8979\n",
            "Epoch 1/4 - Batch 17000/50000 - Loss: 1.5913\n",
            "Epoch 1/4 - Batch 17050/50000 - Loss: 1.3748\n",
            "Epoch 1/4 - Batch 17100/50000 - Loss: 1.6838\n",
            "Epoch 1/4 - Batch 17150/50000 - Loss: 1.8699\n",
            "Epoch 1/4 - Batch 17200/50000 - Loss: 0.6919\n",
            "Epoch 1/4 - Batch 17250/50000 - Loss: 1.3551\n",
            "Epoch 1/4 - Batch 17300/50000 - Loss: 0.9545\n",
            "Epoch 1/4 - Batch 17350/50000 - Loss: 1.6102\n",
            "Epoch 1/4 - Batch 17400/50000 - Loss: 1.6938\n",
            "Epoch 1/4 - Batch 17450/50000 - Loss: 1.5989\n",
            "Epoch 1/4 - Batch 17500/50000 - Loss: 1.5469\n",
            "Epoch 1/4 - Batch 17550/50000 - Loss: 1.4553\n",
            "Epoch 1/4 - Batch 17600/50000 - Loss: 1.1579\n",
            "Epoch 1/4 - Batch 17650/50000 - Loss: 1.5904\n",
            "Epoch 1/4 - Batch 17700/50000 - Loss: 1.8139\n",
            "Epoch 1/4 - Batch 17750/50000 - Loss: 1.0888\n",
            "Epoch 1/4 - Batch 17800/50000 - Loss: 1.4927\n",
            "Epoch 1/4 - Batch 17850/50000 - Loss: 1.4465\n",
            "Epoch 1/4 - Batch 17900/50000 - Loss: 1.9474\n",
            "Epoch 1/4 - Batch 17950/50000 - Loss: 1.0460\n",
            "Epoch 1/4 - Batch 18000/50000 - Loss: 1.2682\n",
            "Epoch 1/4 - Batch 18050/50000 - Loss: 0.7339\n",
            "Epoch 1/4 - Batch 18100/50000 - Loss: 1.4654\n",
            "Epoch 1/4 - Batch 18150/50000 - Loss: 1.1754\n",
            "Epoch 1/4 - Batch 18200/50000 - Loss: 1.0410\n",
            "Epoch 1/4 - Batch 18250/50000 - Loss: 1.1213\n",
            "Epoch 1/4 - Batch 18300/50000 - Loss: 1.3420\n",
            "Epoch 1/4 - Batch 18350/50000 - Loss: 1.4336\n",
            "Epoch 1/4 - Batch 18400/50000 - Loss: 1.6015\n",
            "Epoch 1/4 - Batch 18450/50000 - Loss: 1.2165\n",
            "Epoch 1/4 - Batch 18500/50000 - Loss: 1.4670\n",
            "Epoch 1/4 - Batch 18550/50000 - Loss: 1.8438\n",
            "Epoch 1/4 - Batch 18600/50000 - Loss: 1.3721\n",
            "Epoch 1/4 - Batch 18650/50000 - Loss: 1.2869\n",
            "Epoch 1/4 - Batch 18700/50000 - Loss: 1.1828\n",
            "Epoch 1/4 - Batch 18750/50000 - Loss: 0.6271\n",
            "Epoch 1/4 - Batch 18800/50000 - Loss: 1.1296\n",
            "Epoch 1/4 - Batch 18850/50000 - Loss: 1.2425\n",
            "Epoch 1/4 - Batch 18900/50000 - Loss: 1.1716\n",
            "Epoch 1/4 - Batch 18950/50000 - Loss: 1.2604\n",
            "Epoch 1/4 - Batch 19000/50000 - Loss: 1.2138\n",
            "Epoch 1/4 - Batch 19050/50000 - Loss: 1.2344\n",
            "Epoch 1/4 - Batch 19100/50000 - Loss: 1.3718\n",
            "Epoch 1/4 - Batch 19150/50000 - Loss: 0.9216\n",
            "Epoch 1/4 - Batch 19200/50000 - Loss: 1.6246\n",
            "Epoch 1/4 - Batch 19250/50000 - Loss: 1.0919\n",
            "Epoch 1/4 - Batch 19300/50000 - Loss: 1.6360\n",
            "Epoch 1/4 - Batch 19350/50000 - Loss: 1.1164\n",
            "Epoch 1/4 - Batch 19400/50000 - Loss: 1.0794\n",
            "Epoch 1/4 - Batch 19450/50000 - Loss: 1.2254\n",
            "Epoch 1/4 - Batch 19500/50000 - Loss: 1.0396\n",
            "Epoch 1/4 - Batch 19550/50000 - Loss: 1.2395\n",
            "Epoch 1/4 - Batch 19600/50000 - Loss: 1.3249\n",
            "Epoch 1/4 - Batch 19650/50000 - Loss: 1.3894\n",
            "Epoch 1/4 - Batch 19700/50000 - Loss: 1.4485\n",
            "Epoch 1/4 - Batch 19750/50000 - Loss: 1.7292\n",
            "Epoch 1/4 - Batch 19800/50000 - Loss: 1.3167\n",
            "Epoch 1/4 - Batch 19850/50000 - Loss: 1.3341\n",
            "Epoch 1/4 - Batch 19900/50000 - Loss: 1.4392\n",
            "Epoch 1/4 - Batch 19950/50000 - Loss: 1.2216\n",
            "Epoch 1/4 - Batch 20000/50000 - Loss: 1.6444\n",
            "Epoch 1/4 - Batch 20050/50000 - Loss: 1.4733\n",
            "Epoch 1/4 - Batch 20100/50000 - Loss: 0.9915\n",
            "Epoch 1/4 - Batch 20150/50000 - Loss: 1.3167\n",
            "Epoch 1/4 - Batch 20200/50000 - Loss: 1.1845\n",
            "Epoch 1/4 - Batch 20250/50000 - Loss: 1.6929\n",
            "Epoch 1/4 - Batch 20300/50000 - Loss: 1.7669\n",
            "Epoch 1/4 - Batch 20350/50000 - Loss: 0.8475\n",
            "Epoch 1/4 - Batch 20400/50000 - Loss: 1.3472\n",
            "Epoch 1/4 - Batch 20450/50000 - Loss: 1.2983\n",
            "Epoch 1/4 - Batch 20500/50000 - Loss: 1.3880\n",
            "Epoch 1/4 - Batch 20550/50000 - Loss: 1.6396\n",
            "Epoch 1/4 - Batch 20600/50000 - Loss: 1.4908\n",
            "Epoch 1/4 - Batch 20650/50000 - Loss: 1.0728\n",
            "Epoch 1/4 - Batch 20700/50000 - Loss: 2.0495\n",
            "Epoch 1/4 - Batch 20750/50000 - Loss: 1.5835\n",
            "Epoch 1/4 - Batch 20800/50000 - Loss: 1.1004\n",
            "Epoch 1/4 - Batch 20850/50000 - Loss: 1.2174\n",
            "Epoch 1/4 - Batch 20900/50000 - Loss: 1.8473\n",
            "Epoch 1/4 - Batch 20950/50000 - Loss: 1.0318\n",
            "Epoch 1/4 - Batch 21000/50000 - Loss: 0.9537\n",
            "Epoch 1/4 - Batch 21050/50000 - Loss: 0.8760\n",
            "Epoch 1/4 - Batch 21100/50000 - Loss: 1.2285\n",
            "Epoch 1/4 - Batch 21150/50000 - Loss: 1.4142\n",
            "Epoch 1/4 - Batch 21200/50000 - Loss: 1.8883\n",
            "Epoch 1/4 - Batch 21250/50000 - Loss: 1.6092\n",
            "Epoch 1/4 - Batch 21300/50000 - Loss: 1.8013\n",
            "Epoch 1/4 - Batch 21350/50000 - Loss: 1.5137\n",
            "Epoch 1/4 - Batch 21400/50000 - Loss: 1.5363\n",
            "Epoch 1/4 - Batch 21450/50000 - Loss: 1.2998\n",
            "Epoch 1/4 - Batch 21500/50000 - Loss: 1.5824\n",
            "Epoch 1/4 - Batch 21550/50000 - Loss: 1.1582\n",
            "Epoch 1/4 - Batch 21600/50000 - Loss: 1.5014\n",
            "Epoch 1/4 - Batch 21650/50000 - Loss: 1.4280\n",
            "Epoch 1/4 - Batch 21700/50000 - Loss: 1.3914\n",
            "Epoch 1/4 - Batch 21750/50000 - Loss: 0.9804\n",
            "Epoch 1/4 - Batch 21800/50000 - Loss: 1.4288\n",
            "Epoch 1/4 - Batch 21850/50000 - Loss: 1.3419\n",
            "Epoch 1/4 - Batch 21900/50000 - Loss: 1.2451\n",
            "Epoch 1/4 - Batch 21950/50000 - Loss: 1.4828\n",
            "Epoch 1/4 - Batch 22000/50000 - Loss: 1.3851\n",
            "Epoch 1/4 - Batch 22050/50000 - Loss: 1.6986\n",
            "Epoch 1/4 - Batch 22100/50000 - Loss: 1.6671\n",
            "Epoch 1/4 - Batch 22150/50000 - Loss: 1.5958\n",
            "Epoch 1/4 - Batch 22200/50000 - Loss: 1.8593\n",
            "Epoch 1/4 - Batch 22250/50000 - Loss: 1.3148\n",
            "Epoch 1/4 - Batch 22300/50000 - Loss: 1.8617\n",
            "Epoch 1/4 - Batch 22350/50000 - Loss: 1.3321\n",
            "Epoch 1/4 - Batch 22400/50000 - Loss: 1.7814\n",
            "Epoch 1/4 - Batch 22450/50000 - Loss: 1.9522\n",
            "Epoch 1/4 - Batch 22500/50000 - Loss: 1.7976\n",
            "Epoch 1/4 - Batch 22550/50000 - Loss: 1.7060\n",
            "Epoch 1/4 - Batch 22600/50000 - Loss: 1.4217\n",
            "Epoch 1/4 - Batch 22650/50000 - Loss: 1.1372\n",
            "Epoch 1/4 - Batch 22700/50000 - Loss: 1.9589\n",
            "Epoch 1/4 - Batch 22750/50000 - Loss: 1.5284\n",
            "Epoch 1/4 - Batch 22800/50000 - Loss: 1.3535\n",
            "Epoch 1/4 - Batch 22850/50000 - Loss: 1.9824\n",
            "Epoch 1/4 - Batch 22900/50000 - Loss: 1.8581\n",
            "Epoch 1/4 - Batch 22950/50000 - Loss: 1.5971\n",
            "Epoch 1/4 - Batch 23000/50000 - Loss: 1.5179\n",
            "Epoch 1/4 - Batch 23050/50000 - Loss: 1.0371\n",
            "Epoch 1/4 - Batch 23100/50000 - Loss: 1.2057\n",
            "Epoch 1/4 - Batch 23150/50000 - Loss: 1.3994\n",
            "Epoch 1/4 - Batch 23200/50000 - Loss: 1.2995\n",
            "Epoch 1/4 - Batch 23250/50000 - Loss: 1.8721\n",
            "Epoch 1/4 - Batch 23300/50000 - Loss: 1.1900\n",
            "Epoch 1/4 - Batch 23350/50000 - Loss: 1.5743\n",
            "Epoch 1/4 - Batch 23400/50000 - Loss: 1.7994\n",
            "Epoch 1/4 - Batch 23450/50000 - Loss: 0.9180\n",
            "Epoch 1/4 - Batch 23500/50000 - Loss: 0.8758\n",
            "Epoch 1/4 - Batch 23550/50000 - Loss: 1.8006\n",
            "Epoch 1/4 - Batch 23600/50000 - Loss: 1.4415\n",
            "Epoch 1/4 - Batch 23650/50000 - Loss: 0.9376\n",
            "Epoch 1/4 - Batch 23700/50000 - Loss: 1.6835\n",
            "Epoch 1/4 - Batch 23750/50000 - Loss: 1.7738\n",
            "Epoch 1/4 - Batch 23800/50000 - Loss: 1.0741\n",
            "Epoch 1/4 - Batch 23850/50000 - Loss: 1.0753\n",
            "Epoch 1/4 - Batch 23900/50000 - Loss: 1.4451\n",
            "Epoch 1/4 - Batch 23950/50000 - Loss: 2.2135\n",
            "Epoch 1/4 - Batch 24000/50000 - Loss: 1.6200\n",
            "Epoch 1/4 - Batch 24050/50000 - Loss: 1.6295\n",
            "Epoch 1/4 - Batch 24100/50000 - Loss: 1.3281\n",
            "Epoch 1/4 - Batch 24150/50000 - Loss: 1.7605\n",
            "Epoch 1/4 - Batch 24200/50000 - Loss: 1.8597\n",
            "Epoch 1/4 - Batch 24250/50000 - Loss: 1.5121\n",
            "Epoch 1/4 - Batch 24300/50000 - Loss: 1.3029\n",
            "Epoch 1/4 - Batch 24350/50000 - Loss: 1.5405\n",
            "Epoch 1/4 - Batch 24400/50000 - Loss: 1.4084\n",
            "Epoch 1/4 - Batch 24450/50000 - Loss: 1.2159\n",
            "Epoch 1/4 - Batch 24500/50000 - Loss: 1.3861\n",
            "Epoch 1/4 - Batch 24550/50000 - Loss: 1.3442\n",
            "Epoch 1/4 - Batch 24600/50000 - Loss: 1.9215\n",
            "Epoch 1/4 - Batch 24650/50000 - Loss: 0.9481\n",
            "Epoch 1/4 - Batch 24700/50000 - Loss: 1.3287\n",
            "Epoch 1/4 - Batch 24750/50000 - Loss: 1.2021\n",
            "Epoch 1/4 - Batch 24800/50000 - Loss: 1.6639\n",
            "Epoch 1/4 - Batch 24850/50000 - Loss: 1.3037\n",
            "Epoch 1/4 - Batch 24900/50000 - Loss: 1.4088\n",
            "Epoch 1/4 - Batch 24950/50000 - Loss: 1.3328\n",
            "Epoch 1/4 - Batch 25000/50000 - Loss: 1.2982\n",
            "Epoch 1/4 - Batch 25050/50000 - Loss: 1.6626\n",
            "Epoch 1/4 - Batch 25100/50000 - Loss: 1.3600\n",
            "Epoch 1/4 - Batch 25150/50000 - Loss: 2.1291\n",
            "Epoch 1/4 - Batch 25200/50000 - Loss: 1.5910\n",
            "Epoch 1/4 - Batch 25250/50000 - Loss: 0.9817\n",
            "Epoch 1/4 - Batch 25300/50000 - Loss: 1.9393\n",
            "Epoch 1/4 - Batch 25350/50000 - Loss: 1.9741\n",
            "Epoch 1/4 - Batch 25400/50000 - Loss: 1.0241\n",
            "Epoch 1/4 - Batch 25450/50000 - Loss: 2.0030\n",
            "Epoch 1/4 - Batch 25500/50000 - Loss: 1.7517\n",
            "Epoch 1/4 - Batch 25550/50000 - Loss: 1.7545\n",
            "Epoch 1/4 - Batch 25600/50000 - Loss: 2.0600\n",
            "Epoch 1/4 - Batch 25650/50000 - Loss: 1.0233\n",
            "Epoch 1/4 - Batch 25700/50000 - Loss: 1.9813\n",
            "Epoch 1/4 - Batch 25750/50000 - Loss: 0.8296\n",
            "Epoch 1/4 - Batch 25800/50000 - Loss: 1.7249\n",
            "Epoch 1/4 - Batch 25850/50000 - Loss: 1.6129\n",
            "Epoch 1/4 - Batch 25900/50000 - Loss: 1.4930\n",
            "Epoch 1/4 - Batch 25950/50000 - Loss: 1.6410\n",
            "Epoch 1/4 - Batch 26000/50000 - Loss: 1.3297\n",
            "Epoch 1/4 - Batch 26050/50000 - Loss: 1.5443\n",
            "Epoch 1/4 - Batch 26100/50000 - Loss: 1.0261\n",
            "Epoch 1/4 - Batch 26150/50000 - Loss: 1.2389\n",
            "Epoch 1/4 - Batch 26200/50000 - Loss: 0.9174\n",
            "Epoch 1/4 - Batch 26250/50000 - Loss: 1.3642\n",
            "Epoch 1/4 - Batch 26300/50000 - Loss: 1.5860\n",
            "Epoch 1/4 - Batch 26350/50000 - Loss: 1.0042\n",
            "Epoch 1/4 - Batch 26400/50000 - Loss: 1.2147\n",
            "Epoch 1/4 - Batch 26450/50000 - Loss: 1.6684\n",
            "Epoch 1/4 - Batch 26500/50000 - Loss: 1.3775\n",
            "Epoch 1/4 - Batch 26550/50000 - Loss: 1.3687\n",
            "Epoch 1/4 - Batch 26600/50000 - Loss: 1.4903\n",
            "Epoch 1/4 - Batch 26650/50000 - Loss: 1.1274\n",
            "Epoch 1/4 - Batch 26700/50000 - Loss: 1.0863\n",
            "Epoch 1/4 - Batch 26750/50000 - Loss: 1.2075\n",
            "Epoch 1/4 - Batch 26800/50000 - Loss: 1.4166\n",
            "Epoch 1/4 - Batch 26850/50000 - Loss: 1.7875\n",
            "Epoch 1/4 - Batch 26900/50000 - Loss: 0.9243\n",
            "Epoch 1/4 - Batch 26950/50000 - Loss: 1.3230\n",
            "Epoch 1/4 - Batch 27000/50000 - Loss: 1.4562\n",
            "Epoch 1/4 - Batch 27050/50000 - Loss: 1.4095\n",
            "Epoch 1/4 - Batch 27100/50000 - Loss: 0.8027\n",
            "Epoch 1/4 - Batch 27150/50000 - Loss: 1.8620\n",
            "Epoch 1/4 - Batch 27200/50000 - Loss: 1.1318\n",
            "Epoch 1/4 - Batch 27250/50000 - Loss: 1.4011\n",
            "Epoch 1/4 - Batch 27300/50000 - Loss: 1.1039\n",
            "Epoch 1/4 - Batch 27350/50000 - Loss: 1.5095\n",
            "Epoch 1/4 - Batch 27400/50000 - Loss: 1.4980\n",
            "Epoch 1/4 - Batch 27450/50000 - Loss: 1.7016\n",
            "Epoch 1/4 - Batch 27500/50000 - Loss: 1.2929\n",
            "Epoch 1/4 - Batch 27550/50000 - Loss: 1.5805\n",
            "Epoch 1/4 - Batch 27600/50000 - Loss: 1.7366\n",
            "Epoch 1/4 - Batch 27650/50000 - Loss: 1.1652\n",
            "Epoch 1/4 - Batch 27700/50000 - Loss: 1.5666\n",
            "Epoch 1/4 - Batch 27750/50000 - Loss: 1.4710\n",
            "Epoch 1/4 - Batch 27800/50000 - Loss: 1.3209\n",
            "Epoch 1/4 - Batch 27850/50000 - Loss: 1.4784\n",
            "Epoch 1/4 - Batch 27900/50000 - Loss: 1.2882\n",
            "Epoch 1/4 - Batch 27950/50000 - Loss: 1.1814\n",
            "Epoch 1/4 - Batch 28000/50000 - Loss: 1.7023\n",
            "Epoch 1/4 - Batch 28050/50000 - Loss: 1.3870\n",
            "Epoch 1/4 - Batch 28100/50000 - Loss: 1.6796\n",
            "Epoch 1/4 - Batch 28150/50000 - Loss: 1.5259\n",
            "Epoch 1/4 - Batch 28200/50000 - Loss: 1.4750\n",
            "Epoch 1/4 - Batch 28250/50000 - Loss: 1.5891\n",
            "Epoch 1/4 - Batch 28300/50000 - Loss: 1.1792\n",
            "Epoch 1/4 - Batch 28350/50000 - Loss: 1.4480\n",
            "Epoch 1/4 - Batch 28400/50000 - Loss: 1.1187\n",
            "Epoch 1/4 - Batch 28450/50000 - Loss: 1.6652\n",
            "Epoch 1/4 - Batch 28500/50000 - Loss: 1.2305\n",
            "Epoch 1/4 - Batch 28550/50000 - Loss: 1.2843\n",
            "Epoch 1/4 - Batch 28600/50000 - Loss: 1.9148\n",
            "Epoch 1/4 - Batch 28650/50000 - Loss: 1.5864\n",
            "Epoch 1/4 - Batch 28700/50000 - Loss: 1.7129\n",
            "Epoch 1/4 - Batch 28750/50000 - Loss: 1.4372\n",
            "Epoch 1/4 - Batch 28800/50000 - Loss: 1.6227\n",
            "Epoch 1/4 - Batch 28850/50000 - Loss: 1.4493\n",
            "Epoch 1/4 - Batch 28900/50000 - Loss: 1.2990\n",
            "Epoch 1/4 - Batch 28950/50000 - Loss: 1.5843\n",
            "Epoch 1/4 - Batch 29000/50000 - Loss: 1.7082\n",
            "Epoch 1/4 - Batch 29050/50000 - Loss: 1.2736\n",
            "Epoch 1/4 - Batch 29100/50000 - Loss: 2.1458\n",
            "Epoch 1/4 - Batch 29150/50000 - Loss: 1.4422\n",
            "Epoch 1/4 - Batch 29200/50000 - Loss: 1.6840\n",
            "Epoch 1/4 - Batch 29250/50000 - Loss: 1.3638\n",
            "Epoch 1/4 - Batch 29300/50000 - Loss: 1.7010\n",
            "Epoch 1/4 - Batch 29350/50000 - Loss: 1.3857\n",
            "Epoch 1/4 - Batch 29400/50000 - Loss: 1.3658\n",
            "Epoch 1/4 - Batch 29450/50000 - Loss: 1.1556\n",
            "Epoch 1/4 - Batch 29500/50000 - Loss: 1.6470\n",
            "Epoch 1/4 - Batch 29550/50000 - Loss: 1.0586\n",
            "Epoch 1/4 - Batch 29600/50000 - Loss: 1.1969\n",
            "Epoch 1/4 - Batch 29650/50000 - Loss: 1.7546\n",
            "Epoch 1/4 - Batch 29700/50000 - Loss: 1.6730\n",
            "Epoch 1/4 - Batch 29750/50000 - Loss: 1.5725\n",
            "Epoch 1/4 - Batch 29800/50000 - Loss: 1.5804\n",
            "Epoch 1/4 - Batch 29850/50000 - Loss: 1.2173\n",
            "Epoch 1/4 - Batch 29900/50000 - Loss: 0.9423\n",
            "Epoch 1/4 - Batch 29950/50000 - Loss: 2.1313\n",
            "Epoch 1/4 - Batch 30000/50000 - Loss: 0.7319\n",
            "Epoch 1/4 - Batch 30050/50000 - Loss: 1.6209\n",
            "Epoch 1/4 - Batch 30100/50000 - Loss: 1.9385\n",
            "Epoch 1/4 - Batch 30150/50000 - Loss: 1.3005\n",
            "Epoch 1/4 - Batch 30200/50000 - Loss: 1.0453\n",
            "Epoch 1/4 - Batch 30250/50000 - Loss: 1.9012\n",
            "Epoch 1/4 - Batch 30300/50000 - Loss: 1.5187\n",
            "Epoch 1/4 - Batch 30350/50000 - Loss: 0.8884\n",
            "Epoch 1/4 - Batch 30400/50000 - Loss: 1.6065\n",
            "Epoch 1/4 - Batch 30450/50000 - Loss: 1.3138\n",
            "Epoch 1/4 - Batch 30500/50000 - Loss: 1.2660\n",
            "Epoch 1/4 - Batch 30550/50000 - Loss: 1.6235\n",
            "Epoch 1/4 - Batch 30600/50000 - Loss: 1.4110\n",
            "Epoch 1/4 - Batch 30650/50000 - Loss: 1.5967\n",
            "Epoch 1/4 - Batch 30700/50000 - Loss: 1.5184\n",
            "Epoch 1/4 - Batch 30750/50000 - Loss: 1.1931\n",
            "Epoch 1/4 - Batch 30800/50000 - Loss: 0.6544\n",
            "Epoch 1/4 - Batch 30850/50000 - Loss: 1.4848\n",
            "Epoch 1/4 - Batch 30900/50000 - Loss: 1.2919\n",
            "Epoch 1/4 - Batch 30950/50000 - Loss: 1.4940\n",
            "Epoch 1/4 - Batch 31000/50000 - Loss: 1.8763\n",
            "Epoch 1/4 - Batch 31050/50000 - Loss: 1.5645\n",
            "Epoch 1/4 - Batch 31100/50000 - Loss: 1.1421\n",
            "Epoch 1/4 - Batch 31150/50000 - Loss: 1.5907\n",
            "Epoch 1/4 - Batch 31200/50000 - Loss: 1.5807\n",
            "Epoch 1/4 - Batch 31250/50000 - Loss: 1.2784\n",
            "Epoch 1/4 - Batch 31300/50000 - Loss: 1.5100\n",
            "Epoch 1/4 - Batch 31350/50000 - Loss: 1.4671\n",
            "Epoch 1/4 - Batch 31400/50000 - Loss: 0.9039\n",
            "Epoch 1/4 - Batch 31450/50000 - Loss: 1.7515\n",
            "Epoch 1/4 - Batch 31500/50000 - Loss: 0.7204\n",
            "Epoch 1/4 - Batch 31550/50000 - Loss: 1.5897\n",
            "Epoch 1/4 - Batch 31600/50000 - Loss: 1.4763\n",
            "Epoch 1/4 - Batch 31650/50000 - Loss: 1.6115\n",
            "Epoch 1/4 - Batch 31700/50000 - Loss: 1.1084\n",
            "Epoch 1/4 - Batch 31750/50000 - Loss: 1.8476\n",
            "Epoch 1/4 - Batch 31800/50000 - Loss: 1.0345\n",
            "Epoch 1/4 - Batch 31850/50000 - Loss: 1.5610\n",
            "Epoch 1/4 - Batch 31900/50000 - Loss: 1.7605\n",
            "Epoch 1/4 - Batch 31950/50000 - Loss: 1.7390\n",
            "Epoch 1/4 - Batch 32000/50000 - Loss: 1.5697\n",
            "Epoch 1/4 - Batch 32050/50000 - Loss: 1.5093\n",
            "Epoch 1/4 - Batch 32100/50000 - Loss: 0.8415\n",
            "Epoch 1/4 - Batch 32150/50000 - Loss: 1.4739\n",
            "Epoch 1/4 - Batch 32200/50000 - Loss: 1.2898\n",
            "Epoch 1/4 - Batch 32250/50000 - Loss: 1.6638\n",
            "Epoch 1/4 - Batch 32300/50000 - Loss: 1.8992\n",
            "Epoch 1/4 - Batch 32350/50000 - Loss: 1.8411\n",
            "Epoch 1/4 - Batch 32400/50000 - Loss: 1.2988\n",
            "Epoch 1/4 - Batch 32450/50000 - Loss: 1.4930\n",
            "Epoch 1/4 - Batch 32500/50000 - Loss: 1.6094\n",
            "Epoch 1/4 - Batch 32550/50000 - Loss: 1.5919\n",
            "Epoch 1/4 - Batch 32600/50000 - Loss: 1.4184\n",
            "Epoch 1/4 - Batch 32650/50000 - Loss: 1.6065\n",
            "Epoch 1/4 - Batch 32700/50000 - Loss: 2.1363\n",
            "Epoch 1/4 - Batch 32750/50000 - Loss: 1.2437\n",
            "Epoch 1/4 - Batch 32800/50000 - Loss: 1.5812\n",
            "Epoch 1/4 - Batch 32850/50000 - Loss: 1.7306\n",
            "Epoch 1/4 - Batch 32900/50000 - Loss: 1.0373\n",
            "Epoch 1/4 - Batch 32950/50000 - Loss: 1.6839\n",
            "Epoch 1/4 - Batch 33000/50000 - Loss: 1.3654\n",
            "Epoch 1/4 - Batch 33050/50000 - Loss: 0.8692\n",
            "Epoch 1/4 - Batch 33100/50000 - Loss: 1.3922\n",
            "Epoch 1/4 - Batch 33150/50000 - Loss: 1.6468\n",
            "Epoch 1/4 - Batch 33200/50000 - Loss: 1.0473\n",
            "Epoch 1/4 - Batch 33250/50000 - Loss: 1.2289\n",
            "Epoch 1/4 - Batch 33300/50000 - Loss: 0.9226\n",
            "Epoch 1/4 - Batch 33350/50000 - Loss: 1.1361\n",
            "Epoch 1/4 - Batch 33400/50000 - Loss: 1.5944\n",
            "Epoch 1/4 - Batch 33450/50000 - Loss: 1.9098\n",
            "Epoch 1/4 - Batch 33500/50000 - Loss: 2.1281\n",
            "Epoch 1/4 - Batch 33550/50000 - Loss: 1.2292\n",
            "Epoch 1/4 - Batch 33600/50000 - Loss: 1.3230\n",
            "Epoch 1/4 - Batch 33650/50000 - Loss: 1.8059\n",
            "Epoch 1/4 - Batch 33700/50000 - Loss: 1.5252\n",
            "Epoch 1/4 - Batch 33750/50000 - Loss: 1.4909\n",
            "Epoch 1/4 - Batch 33800/50000 - Loss: 1.3355\n",
            "Epoch 1/4 - Batch 33850/50000 - Loss: 1.3323\n",
            "Epoch 1/4 - Batch 33900/50000 - Loss: 1.3686\n",
            "Epoch 1/4 - Batch 33950/50000 - Loss: 0.8506\n",
            "Epoch 1/4 - Batch 34000/50000 - Loss: 0.8402\n",
            "Epoch 1/4 - Batch 34050/50000 - Loss: 1.3764\n",
            "Epoch 1/4 - Batch 34100/50000 - Loss: 0.9514\n",
            "Epoch 1/4 - Batch 34150/50000 - Loss: 1.1931\n",
            "Epoch 1/4 - Batch 34200/50000 - Loss: 1.6002\n",
            "Epoch 1/4 - Batch 34250/50000 - Loss: 1.4874\n",
            "Epoch 1/4 - Batch 34300/50000 - Loss: 1.6874\n",
            "Epoch 1/4 - Batch 34350/50000 - Loss: 1.4187\n",
            "Epoch 1/4 - Batch 34400/50000 - Loss: 1.0175\n",
            "Epoch 1/4 - Batch 34450/50000 - Loss: 1.4988\n",
            "Epoch 1/4 - Batch 34500/50000 - Loss: 1.4598\n",
            "Epoch 1/4 - Batch 34550/50000 - Loss: 1.4079\n",
            "Epoch 1/4 - Batch 34600/50000 - Loss: 0.9866\n",
            "Epoch 1/4 - Batch 34650/50000 - Loss: 1.3972\n",
            "Epoch 1/4 - Batch 34700/50000 - Loss: 0.8783\n",
            "Epoch 1/4 - Batch 34750/50000 - Loss: 1.2947\n",
            "Epoch 1/4 - Batch 34800/50000 - Loss: 1.1814\n",
            "Epoch 1/4 - Batch 34850/50000 - Loss: 1.0652\n",
            "Epoch 1/4 - Batch 34900/50000 - Loss: 1.0302\n",
            "Epoch 1/4 - Batch 34950/50000 - Loss: 2.0195\n",
            "Epoch 1/4 - Batch 35000/50000 - Loss: 1.3096\n",
            "Epoch 1/4 - Batch 35050/50000 - Loss: 1.2069\n",
            "Epoch 1/4 - Batch 35100/50000 - Loss: 1.1649\n",
            "Epoch 1/4 - Batch 35150/50000 - Loss: 1.2554\n",
            "Epoch 1/4 - Batch 35200/50000 - Loss: 1.2323\n",
            "Epoch 1/4 - Batch 35250/50000 - Loss: 1.7413\n",
            "Epoch 1/4 - Batch 35300/50000 - Loss: 1.5441\n",
            "Epoch 1/4 - Batch 35350/50000 - Loss: 1.6651\n",
            "Epoch 1/4 - Batch 35400/50000 - Loss: 1.1613\n",
            "Epoch 1/4 - Batch 35450/50000 - Loss: 1.3403\n",
            "Epoch 1/4 - Batch 35500/50000 - Loss: 1.6154\n",
            "Epoch 1/4 - Batch 35550/50000 - Loss: 1.5177\n",
            "Epoch 1/4 - Batch 35600/50000 - Loss: 0.7905\n",
            "Epoch 1/4 - Batch 35650/50000 - Loss: 1.2640\n",
            "Epoch 1/4 - Batch 35700/50000 - Loss: 1.3075\n",
            "Epoch 1/4 - Batch 35750/50000 - Loss: 1.6280\n",
            "Epoch 1/4 - Batch 35800/50000 - Loss: 1.2613\n",
            "Epoch 1/4 - Batch 35850/50000 - Loss: 0.8806\n",
            "Epoch 1/4 - Batch 35900/50000 - Loss: 1.4588\n",
            "Epoch 1/4 - Batch 35950/50000 - Loss: 1.3867\n",
            "Epoch 1/4 - Batch 36000/50000 - Loss: 1.5532\n",
            "Epoch 1/4 - Batch 36050/50000 - Loss: 1.4972\n",
            "Epoch 1/4 - Batch 36100/50000 - Loss: 0.7497\n",
            "Epoch 1/4 - Batch 36150/50000 - Loss: 0.9251\n",
            "Epoch 1/4 - Batch 36200/50000 - Loss: 1.2754\n",
            "Epoch 1/4 - Batch 36250/50000 - Loss: 1.8510\n",
            "Epoch 1/4 - Batch 36300/50000 - Loss: 1.3763\n",
            "Epoch 1/4 - Batch 36350/50000 - Loss: 1.6368\n",
            "Epoch 1/4 - Batch 36400/50000 - Loss: 1.5845\n",
            "Epoch 1/4 - Batch 36450/50000 - Loss: 1.5412\n",
            "Epoch 1/4 - Batch 36500/50000 - Loss: 1.3118\n",
            "Epoch 1/4 - Batch 36550/50000 - Loss: 1.3337\n",
            "Epoch 1/4 - Batch 36600/50000 - Loss: 1.8513\n",
            "Epoch 1/4 - Batch 36650/50000 - Loss: 1.5769\n",
            "Epoch 1/4 - Batch 36700/50000 - Loss: 0.8584\n",
            "Epoch 1/4 - Batch 36750/50000 - Loss: 1.7306\n",
            "Epoch 1/4 - Batch 36800/50000 - Loss: 0.9963\n",
            "Epoch 1/4 - Batch 36850/50000 - Loss: 1.9536\n",
            "Epoch 1/4 - Batch 36900/50000 - Loss: 1.3153\n",
            "Epoch 1/4 - Batch 36950/50000 - Loss: 1.0032\n",
            "Epoch 1/4 - Batch 37000/50000 - Loss: 1.5564\n",
            "Epoch 1/4 - Batch 37050/50000 - Loss: 1.5571\n",
            "Epoch 1/4 - Batch 37100/50000 - Loss: 1.5883\n",
            "Epoch 1/4 - Batch 37150/50000 - Loss: 1.1246\n",
            "Epoch 1/4 - Batch 37200/50000 - Loss: 1.4758\n",
            "Epoch 1/4 - Batch 37250/50000 - Loss: 1.5775\n",
            "Epoch 1/4 - Batch 37300/50000 - Loss: 2.1695\n",
            "Epoch 1/4 - Batch 37350/50000 - Loss: 1.5388\n",
            "Epoch 1/4 - Batch 37400/50000 - Loss: 1.6319\n",
            "Epoch 1/4 - Batch 37450/50000 - Loss: 1.7152\n",
            "Epoch 1/4 - Batch 37500/50000 - Loss: 1.5039\n",
            "Epoch 1/4 - Batch 37550/50000 - Loss: 1.5668\n",
            "Epoch 1/4 - Batch 37600/50000 - Loss: 1.9098\n",
            "Epoch 1/4 - Batch 37650/50000 - Loss: 1.2625\n",
            "Epoch 1/4 - Batch 37700/50000 - Loss: 0.8140\n",
            "Epoch 1/4 - Batch 37750/50000 - Loss: 1.4013\n",
            "Epoch 1/4 - Batch 37800/50000 - Loss: 1.6753\n",
            "Epoch 1/4 - Batch 37850/50000 - Loss: 1.0552\n",
            "Epoch 1/4 - Batch 37900/50000 - Loss: 1.8946\n",
            "Epoch 1/4 - Batch 37950/50000 - Loss: 0.7420\n",
            "Epoch 1/4 - Batch 38000/50000 - Loss: 1.1682\n",
            "Epoch 1/4 - Batch 38050/50000 - Loss: 1.3366\n",
            "Epoch 1/4 - Batch 38100/50000 - Loss: 1.7145\n",
            "Epoch 1/4 - Batch 38150/50000 - Loss: 0.7459\n",
            "Epoch 1/4 - Batch 38200/50000 - Loss: 1.2519\n",
            "Epoch 1/4 - Batch 38250/50000 - Loss: 1.1887\n",
            "Epoch 1/4 - Batch 38300/50000 - Loss: 1.9928\n",
            "Epoch 1/4 - Batch 38350/50000 - Loss: 1.9560\n",
            "Epoch 1/4 - Batch 38400/50000 - Loss: 1.6540\n",
            "Epoch 1/4 - Batch 38450/50000 - Loss: 1.4252\n",
            "Epoch 1/4 - Batch 38500/50000 - Loss: 1.5779\n",
            "Epoch 1/4 - Batch 38550/50000 - Loss: 1.4809\n",
            "Epoch 1/4 - Batch 38600/50000 - Loss: 1.6218\n",
            "Epoch 1/4 - Batch 38650/50000 - Loss: 1.3641\n",
            "Epoch 1/4 - Batch 38700/50000 - Loss: 1.5002\n",
            "Epoch 1/4 - Batch 38750/50000 - Loss: 1.8103\n",
            "Epoch 1/4 - Batch 38800/50000 - Loss: 1.4752\n",
            "Epoch 1/4 - Batch 38850/50000 - Loss: 1.1024\n",
            "Epoch 1/4 - Batch 38900/50000 - Loss: 1.7096\n",
            "Epoch 1/4 - Batch 38950/50000 - Loss: 1.0566\n",
            "Epoch 1/4 - Batch 39000/50000 - Loss: 1.2538\n",
            "Epoch 1/4 - Batch 39050/50000 - Loss: 0.8081\n",
            "Epoch 1/4 - Batch 39100/50000 - Loss: 1.8731\n",
            "Epoch 1/4 - Batch 39150/50000 - Loss: 1.8976\n",
            "Epoch 1/4 - Batch 39200/50000 - Loss: 1.2898\n",
            "Epoch 1/4 - Batch 39250/50000 - Loss: 1.4956\n",
            "Epoch 1/4 - Batch 39300/50000 - Loss: 1.9095\n",
            "Epoch 1/4 - Batch 39350/50000 - Loss: 0.9926\n",
            "Epoch 1/4 - Batch 39400/50000 - Loss: 1.4001\n",
            "Epoch 1/4 - Batch 39450/50000 - Loss: 0.4771\n",
            "Epoch 1/4 - Batch 39500/50000 - Loss: 1.3250\n",
            "Epoch 1/4 - Batch 39550/50000 - Loss: 1.0157\n",
            "Epoch 1/4 - Batch 39600/50000 - Loss: 1.4566\n",
            "Epoch 1/4 - Batch 39650/50000 - Loss: 1.4372\n",
            "Epoch 1/4 - Batch 39700/50000 - Loss: 0.9389\n",
            "Epoch 1/4 - Batch 39750/50000 - Loss: 1.5458\n",
            "Epoch 1/4 - Batch 39800/50000 - Loss: 1.3576\n",
            "Epoch 1/4 - Batch 39850/50000 - Loss: 0.2886\n",
            "Epoch 1/4 - Batch 39900/50000 - Loss: 1.3070\n",
            "Epoch 1/4 - Batch 39950/50000 - Loss: 0.9039\n",
            "Epoch 1/4 - Batch 40000/50000 - Loss: 1.2039\n",
            "Epoch 1/4 - Batch 40050/50000 - Loss: 1.5857\n",
            "Epoch 1/4 - Batch 40100/50000 - Loss: 1.9595\n",
            "Epoch 1/4 - Batch 40150/50000 - Loss: 0.7936\n",
            "Epoch 1/4 - Batch 40200/50000 - Loss: 1.0382\n",
            "Epoch 1/4 - Batch 40250/50000 - Loss: 1.5564\n",
            "Epoch 1/4 - Batch 40300/50000 - Loss: 1.7574\n",
            "Epoch 1/4 - Batch 40350/50000 - Loss: 1.2861\n",
            "Epoch 1/4 - Batch 40400/50000 - Loss: 0.8076\n",
            "Epoch 1/4 - Batch 40450/50000 - Loss: 1.0603\n",
            "Epoch 1/4 - Batch 40500/50000 - Loss: 1.3912\n",
            "Epoch 1/4 - Batch 40550/50000 - Loss: 1.3499\n",
            "Epoch 1/4 - Batch 40600/50000 - Loss: 1.9262\n",
            "Epoch 1/4 - Batch 40650/50000 - Loss: 1.1410\n",
            "Epoch 1/4 - Batch 40700/50000 - Loss: 1.5100\n",
            "Epoch 1/4 - Batch 40750/50000 - Loss: 1.2821\n",
            "Epoch 1/4 - Batch 40800/50000 - Loss: 1.4190\n",
            "Epoch 1/4 - Batch 40850/50000 - Loss: 1.2829\n",
            "Epoch 1/4 - Batch 40900/50000 - Loss: 1.0853\n",
            "Epoch 1/4 - Batch 40950/50000 - Loss: 1.0946\n",
            "Epoch 1/4 - Batch 41000/50000 - Loss: 1.6556\n",
            "Epoch 1/4 - Batch 41050/50000 - Loss: 1.7750\n",
            "Epoch 1/4 - Batch 41100/50000 - Loss: 1.5526\n",
            "Epoch 1/4 - Batch 41150/50000 - Loss: 1.3052\n",
            "Epoch 1/4 - Batch 41200/50000 - Loss: 2.0278\n",
            "Epoch 1/4 - Batch 41250/50000 - Loss: 1.4585\n",
            "Epoch 1/4 - Batch 41300/50000 - Loss: 1.5350\n",
            "Epoch 1/4 - Batch 41350/50000 - Loss: 0.8802\n",
            "Epoch 1/4 - Batch 41400/50000 - Loss: 0.9437\n",
            "Epoch 1/4 - Batch 41450/50000 - Loss: 1.7347\n",
            "Epoch 1/4 - Batch 41500/50000 - Loss: 1.5984\n",
            "Epoch 1/4 - Batch 41550/50000 - Loss: 1.0225\n",
            "Epoch 1/4 - Batch 41600/50000 - Loss: 0.8260\n",
            "Epoch 1/4 - Batch 41650/50000 - Loss: 0.9017\n",
            "Epoch 1/4 - Batch 41700/50000 - Loss: 1.6149\n",
            "Epoch 1/4 - Batch 41750/50000 - Loss: 1.1428\n",
            "Epoch 1/4 - Batch 41800/50000 - Loss: 1.5918\n",
            "Epoch 1/4 - Batch 41850/50000 - Loss: 1.2599\n",
            "Epoch 1/4 - Batch 41900/50000 - Loss: 1.4002\n",
            "Epoch 1/4 - Batch 41950/50000 - Loss: 1.7982\n",
            "Epoch 1/4 - Batch 42000/50000 - Loss: 1.5742\n",
            "Epoch 1/4 - Batch 42050/50000 - Loss: 0.8577\n",
            "Epoch 1/4 - Batch 42100/50000 - Loss: 1.3802\n",
            "Epoch 1/4 - Batch 42150/50000 - Loss: 1.6857\n",
            "Epoch 1/4 - Batch 42200/50000 - Loss: 1.9327\n",
            "Epoch 1/4 - Batch 42250/50000 - Loss: 1.1901\n",
            "Epoch 1/4 - Batch 42300/50000 - Loss: 1.3895\n",
            "Epoch 1/4 - Batch 42350/50000 - Loss: 1.6020\n",
            "Epoch 1/4 - Batch 42400/50000 - Loss: 1.1934\n",
            "Epoch 1/4 - Batch 42450/50000 - Loss: 1.7157\n",
            "Epoch 1/4 - Batch 42500/50000 - Loss: 1.5804\n",
            "Epoch 1/4 - Batch 42550/50000 - Loss: 1.5003\n",
            "Epoch 1/4 - Batch 42600/50000 - Loss: 1.4663\n",
            "Epoch 1/4 - Batch 42650/50000 - Loss: 1.2211\n",
            "Epoch 1/4 - Batch 42700/50000 - Loss: 1.3666\n",
            "Epoch 1/4 - Batch 42750/50000 - Loss: 1.8368\n",
            "Epoch 1/4 - Batch 42800/50000 - Loss: 1.6575\n",
            "Epoch 1/4 - Batch 42850/50000 - Loss: 0.6872\n",
            "Epoch 1/4 - Batch 42900/50000 - Loss: 0.8929\n",
            "Epoch 1/4 - Batch 42950/50000 - Loss: 1.2129\n",
            "Epoch 1/4 - Batch 43000/50000 - Loss: 1.5414\n",
            "Epoch 1/4 - Batch 43050/50000 - Loss: 1.0125\n",
            "Epoch 1/4 - Batch 43100/50000 - Loss: 1.7062\n",
            "Epoch 1/4 - Batch 43150/50000 - Loss: 1.1550\n",
            "Epoch 1/4 - Batch 43200/50000 - Loss: 1.3104\n",
            "Epoch 1/4 - Batch 43250/50000 - Loss: 1.3935\n",
            "Epoch 1/4 - Batch 43300/50000 - Loss: 1.1991\n",
            "Epoch 1/4 - Batch 43350/50000 - Loss: 1.2915\n",
            "Epoch 1/4 - Batch 43400/50000 - Loss: 1.0487\n",
            "Epoch 1/4 - Batch 43450/50000 - Loss: 1.8344\n",
            "Epoch 1/4 - Batch 43500/50000 - Loss: 1.2847\n",
            "Epoch 1/4 - Batch 43550/50000 - Loss: 1.7941\n",
            "Epoch 1/4 - Batch 43600/50000 - Loss: 0.9534\n",
            "Epoch 1/4 - Batch 43650/50000 - Loss: 0.6636\n",
            "Epoch 1/4 - Batch 43700/50000 - Loss: 1.1792\n",
            "Epoch 1/4 - Batch 43750/50000 - Loss: 0.7126\n",
            "Epoch 1/4 - Batch 43800/50000 - Loss: 1.7465\n",
            "Epoch 1/4 - Batch 43850/50000 - Loss: 1.6678\n",
            "Epoch 1/4 - Batch 43900/50000 - Loss: 1.8283\n",
            "Epoch 1/4 - Batch 43950/50000 - Loss: 1.4223\n",
            "Epoch 1/4 - Batch 44000/50000 - Loss: 1.1916\n",
            "Epoch 1/4 - Batch 44050/50000 - Loss: 1.9837\n",
            "Epoch 1/4 - Batch 44100/50000 - Loss: 1.6354\n",
            "Epoch 1/4 - Batch 44150/50000 - Loss: 1.4712\n",
            "Epoch 1/4 - Batch 44200/50000 - Loss: 1.3860\n",
            "Epoch 1/4 - Batch 44250/50000 - Loss: 1.2096\n",
            "Epoch 1/4 - Batch 44300/50000 - Loss: 1.7995\n",
            "Epoch 1/4 - Batch 44350/50000 - Loss: 1.7526\n",
            "Epoch 1/4 - Batch 44400/50000 - Loss: 1.2809\n",
            "Epoch 1/4 - Batch 44450/50000 - Loss: 1.1301\n",
            "Epoch 1/4 - Batch 44500/50000 - Loss: 0.7933\n",
            "Epoch 1/4 - Batch 44550/50000 - Loss: 0.7381\n",
            "Epoch 1/4 - Batch 44600/50000 - Loss: 1.4422\n",
            "Epoch 1/4 - Batch 44650/50000 - Loss: 1.6999\n",
            "Epoch 1/4 - Batch 44700/50000 - Loss: 1.7612\n",
            "Epoch 1/4 - Batch 44750/50000 - Loss: 1.7619\n",
            "Epoch 1/4 - Batch 44800/50000 - Loss: 1.5091\n",
            "Epoch 1/4 - Batch 44850/50000 - Loss: 0.8180\n",
            "Epoch 1/4 - Batch 44900/50000 - Loss: 0.8850\n",
            "Epoch 1/4 - Batch 44950/50000 - Loss: 1.5557\n",
            "Epoch 1/4 - Batch 45000/50000 - Loss: 1.7746\n",
            "Epoch 1/4 - Batch 45050/50000 - Loss: 1.5721\n",
            "Epoch 1/4 - Batch 45100/50000 - Loss: 1.5796\n",
            "Epoch 1/4 - Batch 45150/50000 - Loss: 1.7732\n",
            "Epoch 1/4 - Batch 45200/50000 - Loss: 1.2668\n",
            "Epoch 1/4 - Batch 45250/50000 - Loss: 1.9531\n",
            "Epoch 1/4 - Batch 45300/50000 - Loss: 1.3460\n",
            "Epoch 1/4 - Batch 45350/50000 - Loss: 1.0568\n",
            "Epoch 1/4 - Batch 45400/50000 - Loss: 1.8585\n",
            "Epoch 1/4 - Batch 45450/50000 - Loss: 1.1076\n",
            "Epoch 1/4 - Batch 45500/50000 - Loss: 1.5185\n",
            "Epoch 1/4 - Batch 45550/50000 - Loss: 1.7644\n",
            "Epoch 1/4 - Batch 45600/50000 - Loss: 1.8307\n",
            "Epoch 1/4 - Batch 45650/50000 - Loss: 1.1178\n",
            "Epoch 1/4 - Batch 45700/50000 - Loss: 1.7395\n",
            "Epoch 1/4 - Batch 45750/50000 - Loss: 1.8957\n",
            "Epoch 1/4 - Batch 45800/50000 - Loss: 1.4498\n",
            "Epoch 1/4 - Batch 45850/50000 - Loss: 0.9969\n",
            "Epoch 1/4 - Batch 45900/50000 - Loss: 1.2579\n",
            "Epoch 1/4 - Batch 45950/50000 - Loss: 1.3337\n",
            "Epoch 1/4 - Batch 46000/50000 - Loss: 1.0646\n",
            "Epoch 1/4 - Batch 46050/50000 - Loss: 0.7820\n",
            "Epoch 1/4 - Batch 46100/50000 - Loss: 1.1312\n",
            "Epoch 1/4 - Batch 46150/50000 - Loss: 1.1513\n",
            "Epoch 1/4 - Batch 46200/50000 - Loss: 1.6789\n",
            "Epoch 1/4 - Batch 46250/50000 - Loss: 1.5682\n",
            "Epoch 1/4 - Batch 46300/50000 - Loss: 1.3860\n",
            "Epoch 1/4 - Batch 46350/50000 - Loss: 1.4008\n",
            "Epoch 1/4 - Batch 46400/50000 - Loss: 0.7392\n",
            "Epoch 1/4 - Batch 46450/50000 - Loss: 0.8650\n",
            "Epoch 1/4 - Batch 46500/50000 - Loss: 1.4416\n",
            "Epoch 1/4 - Batch 46550/50000 - Loss: 1.2996\n",
            "Epoch 1/4 - Batch 46600/50000 - Loss: 2.1976\n",
            "Epoch 1/4 - Batch 46650/50000 - Loss: 0.9952\n",
            "Epoch 1/4 - Batch 46700/50000 - Loss: 1.6497\n",
            "Epoch 1/4 - Batch 46750/50000 - Loss: 0.9199\n",
            "Epoch 1/4 - Batch 46800/50000 - Loss: 0.9718\n",
            "Epoch 1/4 - Batch 46850/50000 - Loss: 1.1913\n",
            "Epoch 1/4 - Batch 46900/50000 - Loss: 2.1061\n",
            "Epoch 1/4 - Batch 46950/50000 - Loss: 2.0845\n",
            "Epoch 1/4 - Batch 47000/50000 - Loss: 1.7137\n",
            "Epoch 1/4 - Batch 47050/50000 - Loss: 1.6961\n",
            "Epoch 1/4 - Batch 47100/50000 - Loss: 1.6417\n",
            "Epoch 1/4 - Batch 47150/50000 - Loss: 1.3944\n",
            "Epoch 1/4 - Batch 47200/50000 - Loss: 1.4992\n",
            "Epoch 1/4 - Batch 47250/50000 - Loss: 1.9340\n",
            "Epoch 1/4 - Batch 47300/50000 - Loss: 1.1099\n",
            "Epoch 1/4 - Batch 47350/50000 - Loss: 1.7443\n",
            "Epoch 1/4 - Batch 47400/50000 - Loss: 0.8900\n",
            "Epoch 1/4 - Batch 47450/50000 - Loss: 1.3791\n",
            "Epoch 1/4 - Batch 47500/50000 - Loss: 1.3205\n",
            "Epoch 1/4 - Batch 47550/50000 - Loss: 1.8500\n",
            "Epoch 1/4 - Batch 47600/50000 - Loss: 1.5166\n",
            "Epoch 1/4 - Batch 47650/50000 - Loss: 1.7397\n",
            "Epoch 1/4 - Batch 47700/50000 - Loss: 0.9483\n",
            "Epoch 1/4 - Batch 47750/50000 - Loss: 1.9656\n",
            "Epoch 1/4 - Batch 47800/50000 - Loss: 1.1295\n",
            "Epoch 1/4 - Batch 47850/50000 - Loss: 1.3100\n",
            "Epoch 1/4 - Batch 47900/50000 - Loss: 1.0520\n",
            "Epoch 1/4 - Batch 47950/50000 - Loss: 0.8000\n",
            "Epoch 1/4 - Batch 48000/50000 - Loss: 0.9676\n",
            "Epoch 1/4 - Batch 48050/50000 - Loss: 1.7897\n",
            "Epoch 1/4 - Batch 48100/50000 - Loss: 1.6097\n",
            "Epoch 1/4 - Batch 48150/50000 - Loss: 1.0906\n",
            "Epoch 1/4 - Batch 48200/50000 - Loss: 1.9983\n",
            "Epoch 1/4 - Batch 48250/50000 - Loss: 1.2076\n",
            "Epoch 1/4 - Batch 48300/50000 - Loss: 1.3394\n",
            "Epoch 1/4 - Batch 48350/50000 - Loss: 1.5667\n",
            "Epoch 1/4 - Batch 48400/50000 - Loss: 0.3415\n",
            "Epoch 1/4 - Batch 48450/50000 - Loss: 1.7255\n",
            "Epoch 1/4 - Batch 48500/50000 - Loss: 1.7654\n",
            "Epoch 1/4 - Batch 48550/50000 - Loss: 1.4592\n",
            "Epoch 1/4 - Batch 48600/50000 - Loss: 1.1404\n",
            "Epoch 1/4 - Batch 48650/50000 - Loss: 1.8995\n",
            "Epoch 1/4 - Batch 48700/50000 - Loss: 1.4961\n",
            "Epoch 1/4 - Batch 48750/50000 - Loss: 1.6243\n",
            "Epoch 1/4 - Batch 48800/50000 - Loss: 1.4304\n",
            "Epoch 1/4 - Batch 48850/50000 - Loss: 1.3755\n",
            "Epoch 1/4 - Batch 48900/50000 - Loss: 1.0585\n",
            "Epoch 1/4 - Batch 48950/50000 - Loss: 1.6335\n",
            "Epoch 1/4 - Batch 49000/50000 - Loss: 0.3011\n",
            "Epoch 1/4 - Batch 49050/50000 - Loss: 1.7909\n",
            "Epoch 1/4 - Batch 49100/50000 - Loss: 1.4346\n",
            "Epoch 1/4 - Batch 49150/50000 - Loss: 1.7905\n",
            "Epoch 1/4 - Batch 49200/50000 - Loss: 1.2902\n",
            "Epoch 1/4 - Batch 49250/50000 - Loss: 1.0150\n",
            "Epoch 1/4 - Batch 49300/50000 - Loss: 1.8794\n",
            "Epoch 1/4 - Batch 49350/50000 - Loss: 1.5774\n",
            "Epoch 1/4 - Batch 49400/50000 - Loss: 1.8775\n",
            "Epoch 1/4 - Batch 49450/50000 - Loss: 1.6304\n",
            "Epoch 1/4 - Batch 49500/50000 - Loss: 1.1438\n",
            "Epoch 1/4 - Batch 49550/50000 - Loss: 1.5655\n",
            "Epoch 1/4 - Batch 49600/50000 - Loss: 1.7476\n",
            "Epoch 1/4 - Batch 49650/50000 - Loss: 1.6441\n",
            "Epoch 1/4 - Batch 49700/50000 - Loss: 1.5822\n",
            "Epoch 1/4 - Batch 49750/50000 - Loss: 1.2900\n",
            "Epoch 1/4 - Batch 49800/50000 - Loss: 1.8310\n",
            "Epoch 1/4 - Batch 49850/50000 - Loss: 1.5023\n",
            "Epoch 1/4 - Batch 49900/50000 - Loss: 1.3130\n",
            "Epoch 1/4 - Batch 49950/50000 - Loss: 0.8399\n",
            "Epoch 1/4 - Average loss: 1.4434 - Duration: 26867.35s\n",
            "Epoch 2/4 - Batch 0/50000 - Loss: 0.7796\n",
            "Epoch 2/4 - Batch 50/50000 - Loss: 1.0165\n",
            "Epoch 2/4 - Batch 100/50000 - Loss: 1.2778\n",
            "Epoch 2/4 - Batch 150/50000 - Loss: 1.2922\n",
            "Epoch 2/4 - Batch 200/50000 - Loss: 2.0345\n",
            "Epoch 2/4 - Batch 250/50000 - Loss: 0.6848\n",
            "Epoch 2/4 - Batch 300/50000 - Loss: 1.1456\n",
            "Epoch 2/4 - Batch 350/50000 - Loss: 1.4836\n",
            "Epoch 2/4 - Batch 400/50000 - Loss: 1.7767\n",
            "Epoch 2/4 - Batch 450/50000 - Loss: 0.9806\n",
            "Epoch 2/4 - Batch 500/50000 - Loss: 1.5166\n",
            "Epoch 2/4 - Batch 550/50000 - Loss: 1.0792\n",
            "Epoch 2/4 - Batch 600/50000 - Loss: 1.3771\n",
            "Epoch 2/4 - Batch 650/50000 - Loss: 1.3970\n",
            "Epoch 2/4 - Batch 700/50000 - Loss: 0.8441\n",
            "Epoch 2/4 - Batch 750/50000 - Loss: 1.6960\n",
            "Epoch 2/4 - Batch 800/50000 - Loss: 1.3467\n",
            "Epoch 2/4 - Batch 850/50000 - Loss: 1.5644\n",
            "Epoch 2/4 - Batch 900/50000 - Loss: 0.9153\n",
            "Epoch 2/4 - Batch 950/50000 - Loss: 1.1595\n",
            "Epoch 2/4 - Batch 1000/50000 - Loss: 1.1406\n",
            "Epoch 2/4 - Batch 1050/50000 - Loss: 1.3726\n",
            "Epoch 2/4 - Batch 1100/50000 - Loss: 1.6176\n",
            "Epoch 2/4 - Batch 1150/50000 - Loss: 1.2771\n",
            "Epoch 2/4 - Batch 1200/50000 - Loss: 1.3983\n",
            "Epoch 2/4 - Batch 1250/50000 - Loss: 1.3938\n",
            "Epoch 2/4 - Batch 1300/50000 - Loss: 1.3265\n",
            "Epoch 2/4 - Batch 1350/50000 - Loss: 1.2159\n",
            "Epoch 2/4 - Batch 1400/50000 - Loss: 0.8183\n",
            "Epoch 2/4 - Batch 1450/50000 - Loss: 1.1025\n",
            "Epoch 2/4 - Batch 1500/50000 - Loss: 1.5125\n",
            "Epoch 2/4 - Batch 1550/50000 - Loss: 0.8639\n",
            "Epoch 2/4 - Batch 1600/50000 - Loss: 1.6231\n",
            "Epoch 2/4 - Batch 1650/50000 - Loss: 1.3639\n",
            "Epoch 2/4 - Batch 1700/50000 - Loss: 1.4782\n",
            "Epoch 2/4 - Batch 1750/50000 - Loss: 1.5427\n",
            "Epoch 2/4 - Batch 1800/50000 - Loss: 1.4979\n",
            "Epoch 2/4 - Batch 1850/50000 - Loss: 2.0274\n",
            "Epoch 2/4 - Batch 1900/50000 - Loss: 0.8098\n",
            "Epoch 2/4 - Batch 1950/50000 - Loss: 1.7069\n",
            "Epoch 2/4 - Batch 2000/50000 - Loss: 1.6536\n",
            "Epoch 2/4 - Batch 2050/50000 - Loss: 1.1396\n",
            "Epoch 2/4 - Batch 2100/50000 - Loss: 1.5236\n",
            "Epoch 2/4 - Batch 2150/50000 - Loss: 1.0418\n",
            "Epoch 2/4 - Batch 2200/50000 - Loss: 1.3689\n",
            "Epoch 2/4 - Batch 2250/50000 - Loss: 1.4961\n",
            "Epoch 2/4 - Batch 2300/50000 - Loss: 0.5574\n",
            "Epoch 2/4 - Batch 2350/50000 - Loss: 1.4068\n",
            "Epoch 2/4 - Batch 2400/50000 - Loss: 1.2940\n",
            "Epoch 2/4 - Batch 2450/50000 - Loss: 1.4621\n",
            "Epoch 2/4 - Batch 2500/50000 - Loss: 1.7569\n",
            "Epoch 2/4 - Batch 2550/50000 - Loss: 1.3559\n",
            "Epoch 2/4 - Batch 2600/50000 - Loss: 1.7557\n",
            "Epoch 2/4 - Batch 2650/50000 - Loss: 1.5456\n",
            "Epoch 2/4 - Batch 2700/50000 - Loss: 1.3996\n",
            "Epoch 2/4 - Batch 2750/50000 - Loss: 1.7559\n",
            "Epoch 2/4 - Batch 2800/50000 - Loss: 1.3833\n",
            "Epoch 2/4 - Batch 2850/50000 - Loss: 1.4986\n",
            "Epoch 2/4 - Batch 2900/50000 - Loss: 1.7954\n",
            "Epoch 2/4 - Batch 2950/50000 - Loss: 1.5972\n",
            "Epoch 2/4 - Batch 3000/50000 - Loss: 1.9597\n",
            "Epoch 2/4 - Batch 3050/50000 - Loss: 1.0791\n",
            "Epoch 2/4 - Batch 3100/50000 - Loss: 0.7858\n",
            "Epoch 2/4 - Batch 3150/50000 - Loss: 1.0574\n",
            "Epoch 2/4 - Batch 3200/50000 - Loss: 1.5752\n",
            "Epoch 2/4 - Batch 3250/50000 - Loss: 1.1557\n",
            "Epoch 2/4 - Batch 3300/50000 - Loss: 1.2098\n",
            "Epoch 2/4 - Batch 3350/50000 - Loss: 1.1910\n",
            "Epoch 2/4 - Batch 3400/50000 - Loss: 1.3579\n",
            "Epoch 2/4 - Batch 3450/50000 - Loss: 1.3366\n",
            "Epoch 2/4 - Batch 3500/50000 - Loss: 1.3151\n",
            "Epoch 2/4 - Batch 3550/50000 - Loss: 1.3526\n",
            "Epoch 2/4 - Batch 3600/50000 - Loss: 1.7881\n",
            "Epoch 2/4 - Batch 3650/50000 - Loss: 1.1777\n",
            "Epoch 2/4 - Batch 3700/50000 - Loss: 0.9904\n",
            "Epoch 2/4 - Batch 3750/50000 - Loss: 1.3464\n",
            "Epoch 2/4 - Batch 3800/50000 - Loss: 1.1022\n",
            "Epoch 2/4 - Batch 3850/50000 - Loss: 1.9564\n",
            "Epoch 2/4 - Batch 3900/50000 - Loss: 1.3772\n",
            "Epoch 2/4 - Batch 3950/50000 - Loss: 1.3612\n",
            "Epoch 2/4 - Batch 4000/50000 - Loss: 1.1638\n",
            "Epoch 2/4 - Batch 4050/50000 - Loss: 1.0090\n",
            "Epoch 2/4 - Batch 4100/50000 - Loss: 0.8987\n",
            "Epoch 2/4 - Batch 4150/50000 - Loss: 1.2715\n",
            "Epoch 2/4 - Batch 4200/50000 - Loss: 1.6039\n",
            "Epoch 2/4 - Batch 4250/50000 - Loss: 1.3487\n",
            "Epoch 2/4 - Batch 4300/50000 - Loss: 0.9137\n",
            "Epoch 2/4 - Batch 4350/50000 - Loss: 1.5373\n",
            "Epoch 2/4 - Batch 4400/50000 - Loss: 1.0898\n",
            "Epoch 2/4 - Batch 4450/50000 - Loss: 0.8854\n",
            "Epoch 2/4 - Batch 4500/50000 - Loss: 0.9228\n",
            "Epoch 2/4 - Batch 4550/50000 - Loss: 1.3066\n",
            "Epoch 2/4 - Batch 4600/50000 - Loss: 1.0166\n",
            "Epoch 2/4 - Batch 4650/50000 - Loss: 1.5861\n",
            "Epoch 2/4 - Batch 4700/50000 - Loss: 1.2590\n",
            "Epoch 2/4 - Batch 4750/50000 - Loss: 1.2189\n",
            "Epoch 2/4 - Batch 4800/50000 - Loss: 1.2916\n",
            "Epoch 2/4 - Batch 4850/50000 - Loss: 0.8839\n",
            "Epoch 2/4 - Batch 4900/50000 - Loss: 1.2466\n",
            "Epoch 2/4 - Batch 4950/50000 - Loss: 1.1530\n",
            "Epoch 2/4 - Batch 5000/50000 - Loss: 0.9507\n",
            "Epoch 2/4 - Batch 5050/50000 - Loss: 1.2026\n",
            "Epoch 2/4 - Batch 5100/50000 - Loss: 1.5388\n",
            "Epoch 2/4 - Batch 5150/50000 - Loss: 1.4958\n",
            "Epoch 2/4 - Batch 5200/50000 - Loss: 1.9911\n",
            "Epoch 2/4 - Batch 5250/50000 - Loss: 1.0199\n",
            "Epoch 2/4 - Batch 5300/50000 - Loss: 1.5130\n",
            "Epoch 2/4 - Batch 5350/50000 - Loss: 1.6428\n",
            "Epoch 2/4 - Batch 5400/50000 - Loss: 1.5093\n",
            "Epoch 2/4 - Batch 5450/50000 - Loss: 0.9737\n",
            "Epoch 2/4 - Batch 5500/50000 - Loss: 1.4926\n",
            "Epoch 2/4 - Batch 5550/50000 - Loss: 1.2643\n",
            "Epoch 2/4 - Batch 5600/50000 - Loss: 1.0784\n",
            "Epoch 2/4 - Batch 5650/50000 - Loss: 1.8021\n",
            "Epoch 2/4 - Batch 5700/50000 - Loss: 1.6825\n",
            "Epoch 2/4 - Batch 5750/50000 - Loss: 0.5948\n",
            "Epoch 2/4 - Batch 5800/50000 - Loss: 1.7261\n",
            "Epoch 2/4 - Batch 5850/50000 - Loss: 1.3632\n",
            "Epoch 2/4 - Batch 5900/50000 - Loss: 1.4658\n",
            "Epoch 2/4 - Batch 5950/50000 - Loss: 1.5488\n",
            "Epoch 2/4 - Batch 6000/50000 - Loss: 1.2662\n",
            "Epoch 2/4 - Batch 6050/50000 - Loss: 1.3567\n",
            "Epoch 2/4 - Batch 6100/50000 - Loss: 1.0664\n",
            "Epoch 2/4 - Batch 6150/50000 - Loss: 1.3506\n",
            "Epoch 2/4 - Batch 6200/50000 - Loss: 1.2140\n",
            "Epoch 2/4 - Batch 6250/50000 - Loss: 1.1948\n",
            "Epoch 2/4 - Batch 6300/50000 - Loss: 1.3608\n",
            "Epoch 2/4 - Batch 6350/50000 - Loss: 1.6559\n",
            "Epoch 2/4 - Batch 6400/50000 - Loss: 0.8131\n",
            "Epoch 2/4 - Batch 6450/50000 - Loss: 1.1135\n",
            "Epoch 2/4 - Batch 6500/50000 - Loss: 1.9701\n",
            "Epoch 2/4 - Batch 6550/50000 - Loss: 1.2046\n",
            "Epoch 2/4 - Batch 6600/50000 - Loss: 1.6068\n",
            "Epoch 2/4 - Batch 6650/50000 - Loss: 1.3462\n",
            "Epoch 2/4 - Batch 6700/50000 - Loss: 1.4660\n",
            "Epoch 2/4 - Batch 6750/50000 - Loss: 0.8975\n",
            "Epoch 2/4 - Batch 6800/50000 - Loss: 1.2765\n",
            "Epoch 2/4 - Batch 6850/50000 - Loss: 0.8427\n",
            "Epoch 2/4 - Batch 6900/50000 - Loss: 1.1156\n",
            "Epoch 2/4 - Batch 6950/50000 - Loss: 0.9849\n",
            "Epoch 2/4 - Batch 7000/50000 - Loss: 1.7159\n",
            "Epoch 2/4 - Batch 7050/50000 - Loss: 1.0769\n",
            "Epoch 2/4 - Batch 7100/50000 - Loss: 1.0338\n",
            "Epoch 2/4 - Batch 7150/50000 - Loss: 1.3170\n",
            "Epoch 2/4 - Batch 7200/50000 - Loss: 0.8962\n",
            "Epoch 2/4 - Batch 7250/50000 - Loss: 1.2846\n",
            "Epoch 2/4 - Batch 7300/50000 - Loss: 1.0027\n",
            "Epoch 2/4 - Batch 7350/50000 - Loss: 1.6420\n",
            "Epoch 2/4 - Batch 7400/50000 - Loss: 1.0084\n",
            "Epoch 2/4 - Batch 7450/50000 - Loss: 2.1409\n",
            "Epoch 2/4 - Batch 7500/50000 - Loss: 0.8712\n",
            "Epoch 2/4 - Batch 7550/50000 - Loss: 1.2456\n",
            "Epoch 2/4 - Batch 7600/50000 - Loss: 0.8014\n",
            "Epoch 2/4 - Batch 7650/50000 - Loss: 1.3161\n",
            "Epoch 2/4 - Batch 7700/50000 - Loss: 1.8053\n",
            "Epoch 2/4 - Batch 7750/50000 - Loss: 1.6784\n",
            "Epoch 2/4 - Batch 7800/50000 - Loss: 1.5589\n",
            "Epoch 2/4 - Batch 7850/50000 - Loss: 1.6642\n",
            "Epoch 2/4 - Batch 7900/50000 - Loss: 1.2741\n",
            "Epoch 2/4 - Batch 7950/50000 - Loss: 1.1053\n",
            "Epoch 2/4 - Batch 8000/50000 - Loss: 1.1232\n",
            "Epoch 2/4 - Batch 8050/50000 - Loss: 1.1545\n",
            "Epoch 2/4 - Batch 8100/50000 - Loss: 0.9581\n",
            "Epoch 2/4 - Batch 8150/50000 - Loss: 1.6756\n",
            "Epoch 2/4 - Batch 8200/50000 - Loss: 0.7215\n",
            "Epoch 2/4 - Batch 8250/50000 - Loss: 1.6860\n",
            "Epoch 2/4 - Batch 8300/50000 - Loss: 0.7289\n",
            "Epoch 2/4 - Batch 8350/50000 - Loss: 1.4251\n",
            "Epoch 2/4 - Batch 8400/50000 - Loss: 1.1319\n",
            "Epoch 2/4 - Batch 8450/50000 - Loss: 1.3019\n",
            "Epoch 2/4 - Batch 8500/50000 - Loss: 0.7576\n",
            "Epoch 2/4 - Batch 8550/50000 - Loss: 1.5587\n",
            "Epoch 2/4 - Batch 8600/50000 - Loss: 2.3177\n",
            "Epoch 2/4 - Batch 8650/50000 - Loss: 1.6619\n",
            "Epoch 2/4 - Batch 8700/50000 - Loss: 1.4310\n",
            "Epoch 2/4 - Batch 8750/50000 - Loss: 0.6352\n",
            "Epoch 2/4 - Batch 8800/50000 - Loss: 1.2840\n",
            "Epoch 2/4 - Batch 8850/50000 - Loss: 1.2031\n",
            "Epoch 2/4 - Batch 8900/50000 - Loss: 1.5096\n",
            "Epoch 2/4 - Batch 8950/50000 - Loss: 1.4929\n",
            "Epoch 2/4 - Batch 9000/50000 - Loss: 1.1306\n",
            "Epoch 2/4 - Batch 9050/50000 - Loss: 1.5494\n",
            "Epoch 2/4 - Batch 9100/50000 - Loss: 1.4346\n",
            "Epoch 2/4 - Batch 9150/50000 - Loss: 1.2866\n",
            "Epoch 2/4 - Batch 9200/50000 - Loss: 1.5410\n",
            "Epoch 2/4 - Batch 9250/50000 - Loss: 1.0494\n",
            "Epoch 2/4 - Batch 9300/50000 - Loss: 1.6948\n",
            "Epoch 2/4 - Batch 9350/50000 - Loss: 0.9478\n",
            "Epoch 2/4 - Batch 9400/50000 - Loss: 1.5768\n",
            "Epoch 2/4 - Batch 9450/50000 - Loss: 1.5657\n",
            "Epoch 2/4 - Batch 9500/50000 - Loss: 1.6466\n",
            "Epoch 2/4 - Batch 9550/50000 - Loss: 0.3299\n",
            "Epoch 2/4 - Batch 9600/50000 - Loss: 1.3463\n",
            "Epoch 2/4 - Batch 9650/50000 - Loss: 1.6723\n",
            "Epoch 2/4 - Batch 9700/50000 - Loss: 1.4692\n",
            "Epoch 2/4 - Batch 9750/50000 - Loss: 1.4327\n",
            "Epoch 2/4 - Batch 9800/50000 - Loss: 0.9113\n",
            "Epoch 2/4 - Batch 9850/50000 - Loss: 0.9647\n",
            "Epoch 2/4 - Batch 9900/50000 - Loss: 0.6110\n",
            "Epoch 2/4 - Batch 9950/50000 - Loss: 1.4120\n",
            "Epoch 2/4 - Batch 10000/50000 - Loss: 1.1266\n",
            "Epoch 2/4 - Batch 10050/50000 - Loss: 1.1124\n",
            "Epoch 2/4 - Batch 10100/50000 - Loss: 1.6696\n",
            "Epoch 2/4 - Batch 10150/50000 - Loss: 1.1043\n",
            "Epoch 2/4 - Batch 10200/50000 - Loss: 0.8608\n",
            "Epoch 2/4 - Batch 10250/50000 - Loss: 1.3506\n",
            "Epoch 2/4 - Batch 10300/50000 - Loss: 0.4416\n",
            "Epoch 2/4 - Batch 10350/50000 - Loss: 1.5680\n",
            "Epoch 2/4 - Batch 10400/50000 - Loss: 1.5803\n",
            "Epoch 2/4 - Batch 10450/50000 - Loss: 1.2636\n",
            "Epoch 2/4 - Batch 10500/50000 - Loss: 1.7528\n",
            "Epoch 2/4 - Batch 10550/50000 - Loss: 0.6634\n",
            "Epoch 2/4 - Batch 10600/50000 - Loss: 1.5306\n",
            "Epoch 2/4 - Batch 10650/50000 - Loss: 0.7455\n",
            "Epoch 2/4 - Batch 10700/50000 - Loss: 1.0187\n",
            "Epoch 2/4 - Batch 10750/50000 - Loss: 1.4116\n",
            "Epoch 2/4 - Batch 10800/50000 - Loss: 1.0159\n",
            "Epoch 2/4 - Batch 10850/50000 - Loss: 1.7305\n",
            "Epoch 2/4 - Batch 10900/50000 - Loss: 1.1477\n",
            "Epoch 2/4 - Batch 10950/50000 - Loss: 0.9322\n",
            "Epoch 2/4 - Batch 11000/50000 - Loss: 1.4976\n",
            "Epoch 2/4 - Batch 11050/50000 - Loss: 1.0728\n",
            "Epoch 2/4 - Batch 11100/50000 - Loss: 1.3323\n",
            "Epoch 2/4 - Batch 11150/50000 - Loss: 1.2338\n",
            "Epoch 2/4 - Batch 11200/50000 - Loss: 1.8764\n",
            "Epoch 2/4 - Batch 11250/50000 - Loss: 1.7341\n",
            "Epoch 2/4 - Batch 11300/50000 - Loss: 1.1997\n",
            "Epoch 2/4 - Batch 11350/50000 - Loss: 0.8891\n",
            "Epoch 2/4 - Batch 11400/50000 - Loss: 1.3540\n",
            "Epoch 2/4 - Batch 11450/50000 - Loss: 1.5686\n",
            "Epoch 2/4 - Batch 11500/50000 - Loss: 1.4378\n",
            "Epoch 2/4 - Batch 11550/50000 - Loss: 1.2088\n",
            "Epoch 2/4 - Batch 11600/50000 - Loss: 1.4544\n",
            "Epoch 2/4 - Batch 11650/50000 - Loss: 1.5774\n",
            "Epoch 2/4 - Batch 11700/50000 - Loss: 1.0593\n",
            "Epoch 2/4 - Batch 11750/50000 - Loss: 0.7394\n",
            "Epoch 2/4 - Batch 11800/50000 - Loss: 1.6467\n",
            "Epoch 2/4 - Batch 11850/50000 - Loss: 1.3147\n",
            "Epoch 2/4 - Batch 11900/50000 - Loss: 1.6615\n",
            "Epoch 2/4 - Batch 11950/50000 - Loss: 0.5462\n",
            "Epoch 2/4 - Batch 12000/50000 - Loss: 1.3519\n",
            "Epoch 2/4 - Batch 12050/50000 - Loss: 1.3860\n",
            "Epoch 2/4 - Batch 12100/50000 - Loss: 0.9094\n",
            "Epoch 2/4 - Batch 12150/50000 - Loss: 1.6123\n",
            "Epoch 2/4 - Batch 12200/50000 - Loss: 1.4913\n",
            "Epoch 2/4 - Batch 12250/50000 - Loss: 1.5264\n",
            "Epoch 2/4 - Batch 12300/50000 - Loss: 1.8710\n",
            "Epoch 2/4 - Batch 12350/50000 - Loss: 1.2673\n",
            "Epoch 2/4 - Batch 12400/50000 - Loss: 1.1656\n",
            "Epoch 2/4 - Batch 12450/50000 - Loss: 1.3878\n",
            "Epoch 2/4 - Batch 12500/50000 - Loss: 1.1266\n",
            "Epoch 2/4 - Batch 12550/50000 - Loss: 1.3642\n",
            "Epoch 2/4 - Batch 12600/50000 - Loss: 1.0744\n",
            "Epoch 2/4 - Batch 12650/50000 - Loss: 1.3996\n",
            "Epoch 2/4 - Batch 12700/50000 - Loss: 1.4848\n",
            "Epoch 2/4 - Batch 12750/50000 - Loss: 1.0512\n",
            "Epoch 2/4 - Batch 12800/50000 - Loss: 1.6968\n",
            "Epoch 2/4 - Batch 12850/50000 - Loss: 1.0154\n",
            "Epoch 2/4 - Batch 12900/50000 - Loss: 1.5836\n",
            "Epoch 2/4 - Batch 12950/50000 - Loss: 1.4517\n",
            "Epoch 2/4 - Batch 13000/50000 - Loss: 1.2578\n",
            "Epoch 2/4 - Batch 13050/50000 - Loss: 1.8664\n",
            "Epoch 2/4 - Batch 13100/50000 - Loss: 1.1536\n",
            "Epoch 2/4 - Batch 13150/50000 - Loss: 0.9982\n",
            "Epoch 2/4 - Batch 13200/50000 - Loss: 1.1937\n",
            "Epoch 2/4 - Batch 13250/50000 - Loss: 1.8769\n",
            "Epoch 2/4 - Batch 13300/50000 - Loss: 1.5094\n",
            "Epoch 2/4 - Batch 13350/50000 - Loss: 1.4333\n",
            "Epoch 2/4 - Batch 13400/50000 - Loss: 1.1254\n",
            "Epoch 2/4 - Batch 13450/50000 - Loss: 1.2794\n",
            "Epoch 2/4 - Batch 13500/50000 - Loss: 1.4093\n",
            "Epoch 2/4 - Batch 13550/50000 - Loss: 1.4960\n",
            "Epoch 2/4 - Batch 13600/50000 - Loss: 0.5262\n",
            "Epoch 2/4 - Batch 13650/50000 - Loss: 1.5600\n",
            "Epoch 2/4 - Batch 13700/50000 - Loss: 1.4526\n",
            "Epoch 2/4 - Batch 13750/50000 - Loss: 1.7113\n",
            "Epoch 2/4 - Batch 13800/50000 - Loss: 1.6346\n",
            "Epoch 2/4 - Batch 13850/50000 - Loss: 1.5854\n",
            "Epoch 2/4 - Batch 13900/50000 - Loss: 1.1798\n",
            "Epoch 2/4 - Batch 13950/50000 - Loss: 1.4869\n",
            "Epoch 2/4 - Batch 14000/50000 - Loss: 1.1510\n",
            "Epoch 2/4 - Batch 14050/50000 - Loss: 1.2615\n",
            "Epoch 2/4 - Batch 14100/50000 - Loss: 1.3234\n",
            "Epoch 2/4 - Batch 14150/50000 - Loss: 0.9874\n",
            "Epoch 2/4 - Batch 14200/50000 - Loss: 1.2221\n",
            "Epoch 2/4 - Batch 14250/50000 - Loss: 1.7547\n",
            "Epoch 2/4 - Batch 14300/50000 - Loss: 0.8580\n",
            "Epoch 2/4 - Batch 14350/50000 - Loss: 1.4734\n",
            "Epoch 2/4 - Batch 14400/50000 - Loss: 1.5229\n",
            "Epoch 2/4 - Batch 14450/50000 - Loss: 1.4845\n",
            "Epoch 2/4 - Batch 14500/50000 - Loss: 1.3167\n",
            "Epoch 2/4 - Batch 14550/50000 - Loss: 1.2435\n",
            "Epoch 2/4 - Batch 14600/50000 - Loss: 1.0500\n",
            "Epoch 2/4 - Batch 14650/50000 - Loss: 1.3749\n",
            "Epoch 2/4 - Batch 14700/50000 - Loss: 1.0084\n",
            "Epoch 2/4 - Batch 14750/50000 - Loss: 0.4450\n",
            "Epoch 2/4 - Batch 14800/50000 - Loss: 0.9965\n",
            "Epoch 2/4 - Batch 14850/50000 - Loss: 1.4757\n",
            "Epoch 2/4 - Batch 14900/50000 - Loss: 1.4898\n",
            "Epoch 2/4 - Batch 14950/50000 - Loss: 1.0478\n",
            "Epoch 2/4 - Batch 15000/50000 - Loss: 1.5669\n",
            "Epoch 2/4 - Batch 15050/50000 - Loss: 1.8356\n",
            "Epoch 2/4 - Batch 15100/50000 - Loss: 1.7729\n",
            "Epoch 2/4 - Batch 15150/50000 - Loss: 1.0476\n",
            "Epoch 2/4 - Batch 15200/50000 - Loss: 1.2402\n",
            "Epoch 2/4 - Batch 15250/50000 - Loss: 2.0313\n",
            "Epoch 2/4 - Batch 15300/50000 - Loss: 1.3840\n",
            "Epoch 2/4 - Batch 15350/50000 - Loss: 1.5757\n",
            "Epoch 2/4 - Batch 15400/50000 - Loss: 1.2350\n",
            "Epoch 2/4 - Batch 15450/50000 - Loss: 1.1524\n",
            "Epoch 2/4 - Batch 15500/50000 - Loss: 1.7977\n",
            "Epoch 2/4 - Batch 15550/50000 - Loss: 1.6649\n",
            "Epoch 2/4 - Batch 15600/50000 - Loss: 1.4510\n",
            "Epoch 2/4 - Batch 15650/50000 - Loss: 0.7572\n",
            "Epoch 2/4 - Batch 15700/50000 - Loss: 1.1515\n",
            "Epoch 2/4 - Batch 15750/50000 - Loss: 1.0773\n",
            "Epoch 2/4 - Batch 15800/50000 - Loss: 0.8639\n",
            "Epoch 2/4 - Batch 15850/50000 - Loss: 1.8220\n",
            "Epoch 2/4 - Batch 15900/50000 - Loss: 1.3036\n",
            "Epoch 2/4 - Batch 15950/50000 - Loss: 1.7874\n",
            "Epoch 2/4 - Batch 16000/50000 - Loss: 1.3878\n",
            "Epoch 2/4 - Batch 16050/50000 - Loss: 1.7802\n",
            "Epoch 2/4 - Batch 16100/50000 - Loss: 1.4495\n",
            "Epoch 2/4 - Batch 16150/50000 - Loss: 1.4238\n",
            "Epoch 2/4 - Batch 16200/50000 - Loss: 0.3622\n",
            "Epoch 2/4 - Batch 16250/50000 - Loss: 0.8185\n",
            "Epoch 2/4 - Batch 16300/50000 - Loss: 1.3914\n",
            "Epoch 2/4 - Batch 16350/50000 - Loss: 0.9582\n",
            "Epoch 2/4 - Batch 16400/50000 - Loss: 1.7632\n",
            "Epoch 2/4 - Batch 16450/50000 - Loss: 1.0038\n",
            "Epoch 2/4 - Batch 16500/50000 - Loss: 1.6387\n",
            "Epoch 2/4 - Batch 16550/50000 - Loss: 0.7631\n",
            "Epoch 2/4 - Batch 16600/50000 - Loss: 1.5543\n",
            "Epoch 2/4 - Batch 16650/50000 - Loss: 1.1332\n",
            "Epoch 2/4 - Batch 16700/50000 - Loss: 1.2663\n",
            "Epoch 2/4 - Batch 16750/50000 - Loss: 1.4338\n",
            "Epoch 2/4 - Batch 16800/50000 - Loss: 1.5557\n",
            "Epoch 2/4 - Batch 16850/50000 - Loss: 1.8337\n",
            "Epoch 2/4 - Batch 16900/50000 - Loss: 1.3051\n",
            "Epoch 2/4 - Batch 16950/50000 - Loss: 1.6284\n",
            "Epoch 2/4 - Batch 17000/50000 - Loss: 1.2055\n",
            "Epoch 2/4 - Batch 17050/50000 - Loss: 1.5254\n",
            "Epoch 2/4 - Batch 17100/50000 - Loss: 1.4989\n",
            "Epoch 2/4 - Batch 17150/50000 - Loss: 1.1007\n",
            "Epoch 2/4 - Batch 17200/50000 - Loss: 1.1384\n",
            "Epoch 2/4 - Batch 17250/50000 - Loss: 1.2733\n",
            "Epoch 2/4 - Batch 17300/50000 - Loss: 0.6869\n",
            "Epoch 2/4 - Batch 17350/50000 - Loss: 1.4813\n",
            "Epoch 2/4 - Batch 17400/50000 - Loss: 0.8747\n",
            "Epoch 2/4 - Batch 17450/50000 - Loss: 1.0856\n",
            "Epoch 2/4 - Batch 17500/50000 - Loss: 1.0861\n",
            "Epoch 2/4 - Batch 17550/50000 - Loss: 1.2479\n",
            "Epoch 2/4 - Batch 17600/50000 - Loss: 1.4027\n",
            "Epoch 2/4 - Batch 17650/50000 - Loss: 1.1566\n",
            "Epoch 2/4 - Batch 17700/50000 - Loss: 1.5858\n",
            "Epoch 2/4 - Batch 17750/50000 - Loss: 1.1125\n",
            "Epoch 2/4 - Batch 17800/50000 - Loss: 0.7093\n",
            "Epoch 2/4 - Batch 17850/50000 - Loss: 1.6423\n",
            "Epoch 2/4 - Batch 17900/50000 - Loss: 1.4317\n",
            "Epoch 2/4 - Batch 17950/50000 - Loss: 1.3035\n",
            "Epoch 2/4 - Batch 18000/50000 - Loss: 1.2471\n",
            "Epoch 2/4 - Batch 18050/50000 - Loss: 1.6778\n",
            "Epoch 2/4 - Batch 18100/50000 - Loss: 1.1039\n",
            "Epoch 2/4 - Batch 18150/50000 - Loss: 1.4464\n",
            "Epoch 2/4 - Batch 18200/50000 - Loss: 1.7757\n",
            "Epoch 2/4 - Batch 18250/50000 - Loss: 0.8966\n",
            "Epoch 2/4 - Batch 18300/50000 - Loss: 1.2980\n",
            "Epoch 2/4 - Batch 18350/50000 - Loss: 0.9314\n",
            "Epoch 2/4 - Batch 18400/50000 - Loss: 0.6719\n",
            "Epoch 2/4 - Batch 18450/50000 - Loss: 1.8219\n",
            "Epoch 2/4 - Batch 18500/50000 - Loss: 1.1705\n",
            "Epoch 2/4 - Batch 18550/50000 - Loss: 0.7360\n",
            "Epoch 2/4 - Batch 18600/50000 - Loss: 0.7003\n",
            "Epoch 2/4 - Batch 18650/50000 - Loss: 1.2316\n",
            "Epoch 2/4 - Batch 18700/50000 - Loss: 1.2529\n",
            "Epoch 2/4 - Batch 18750/50000 - Loss: 1.6163\n",
            "Epoch 2/4 - Batch 18800/50000 - Loss: 1.3104\n",
            "Epoch 2/4 - Batch 18850/50000 - Loss: 1.4064\n",
            "Epoch 2/4 - Batch 18900/50000 - Loss: 1.0882\n",
            "Epoch 2/4 - Batch 18950/50000 - Loss: 1.1119\n",
            "Epoch 2/4 - Batch 19000/50000 - Loss: 1.3503\n",
            "Epoch 2/4 - Batch 19050/50000 - Loss: 0.9202\n",
            "Epoch 2/4 - Batch 19100/50000 - Loss: 1.0736\n",
            "Epoch 2/4 - Batch 19150/50000 - Loss: 1.3511\n",
            "Epoch 2/4 - Batch 19200/50000 - Loss: 1.6437\n",
            "Epoch 2/4 - Batch 19250/50000 - Loss: 1.5262\n",
            "Epoch 2/4 - Batch 19300/50000 - Loss: 1.3222\n",
            "Epoch 2/4 - Batch 19350/50000 - Loss: 1.2842\n",
            "Epoch 2/4 - Batch 19400/50000 - Loss: 1.2348\n",
            "Epoch 2/4 - Batch 19450/50000 - Loss: 0.6738\n",
            "Epoch 2/4 - Batch 19500/50000 - Loss: 1.4160\n",
            "Epoch 2/4 - Batch 19550/50000 - Loss: 0.8900\n",
            "Epoch 2/4 - Batch 19600/50000 - Loss: 1.2103\n",
            "Epoch 2/4 - Batch 19650/50000 - Loss: 2.1228\n",
            "Epoch 2/4 - Batch 19700/50000 - Loss: 1.6281\n",
            "Epoch 2/4 - Batch 19750/50000 - Loss: 1.7260\n",
            "Epoch 2/4 - Batch 19800/50000 - Loss: 0.6354\n",
            "Epoch 2/4 - Batch 19850/50000 - Loss: 1.5163\n",
            "Epoch 2/4 - Batch 19900/50000 - Loss: 1.3819\n",
            "Epoch 2/4 - Batch 19950/50000 - Loss: 1.3915\n",
            "Epoch 2/4 - Batch 20000/50000 - Loss: 1.5170\n",
            "Epoch 2/4 - Batch 20050/50000 - Loss: 1.3458\n",
            "Epoch 2/4 - Batch 20100/50000 - Loss: 1.5660\n",
            "Epoch 2/4 - Batch 20150/50000 - Loss: 0.7865\n",
            "Epoch 2/4 - Batch 20200/50000 - Loss: 0.6559\n",
            "Epoch 2/4 - Batch 20250/50000 - Loss: 1.0603\n",
            "Epoch 2/4 - Batch 20300/50000 - Loss: 1.3106\n",
            "Epoch 2/4 - Batch 20350/50000 - Loss: 1.0053\n",
            "Epoch 2/4 - Batch 20400/50000 - Loss: 0.8889\n",
            "Epoch 2/4 - Batch 20450/50000 - Loss: 0.8907\n",
            "Epoch 2/4 - Batch 20500/50000 - Loss: 0.6914\n",
            "Epoch 2/4 - Batch 20550/50000 - Loss: 0.5452\n",
            "Epoch 2/4 - Batch 20600/50000 - Loss: 1.5652\n",
            "Epoch 2/4 - Batch 20650/50000 - Loss: 1.4059\n",
            "Epoch 2/4 - Batch 20700/50000 - Loss: 0.8572\n",
            "Epoch 2/4 - Batch 20750/50000 - Loss: 1.4578\n",
            "Epoch 2/4 - Batch 20800/50000 - Loss: 0.7359\n",
            "Epoch 2/4 - Batch 20850/50000 - Loss: 1.4423\n",
            "Epoch 2/4 - Batch 20900/50000 - Loss: 1.1771\n",
            "Epoch 2/4 - Batch 20950/50000 - Loss: 1.4963\n",
            "Epoch 2/4 - Batch 21000/50000 - Loss: 1.7462\n",
            "Epoch 2/4 - Batch 21050/50000 - Loss: 1.7990\n",
            "Epoch 2/4 - Batch 21100/50000 - Loss: 1.4466\n",
            "Epoch 2/4 - Batch 21150/50000 - Loss: 1.4809\n",
            "Epoch 2/4 - Batch 21200/50000 - Loss: 1.0796\n",
            "Epoch 2/4 - Batch 21250/50000 - Loss: 1.3767\n",
            "Epoch 2/4 - Batch 21300/50000 - Loss: 0.5865\n",
            "Epoch 2/4 - Batch 21350/50000 - Loss: 0.7618\n",
            "Epoch 2/4 - Batch 21400/50000 - Loss: 1.2024\n",
            "Epoch 2/4 - Batch 21450/50000 - Loss: 1.3939\n",
            "Epoch 2/4 - Batch 21500/50000 - Loss: 1.0758\n",
            "Epoch 2/4 - Batch 21550/50000 - Loss: 0.9615\n",
            "Epoch 2/4 - Batch 21600/50000 - Loss: 0.6008\n",
            "Epoch 2/4 - Batch 21650/50000 - Loss: 1.4550\n",
            "Epoch 2/4 - Batch 21700/50000 - Loss: 1.7178\n",
            "Epoch 2/4 - Batch 21750/50000 - Loss: 1.3764\n",
            "Epoch 2/4 - Batch 21800/50000 - Loss: 1.1684\n",
            "Epoch 2/4 - Batch 21850/50000 - Loss: 1.0727\n",
            "Epoch 2/4 - Batch 21900/50000 - Loss: 1.2531\n",
            "Epoch 2/4 - Batch 21950/50000 - Loss: 1.3577\n",
            "Epoch 2/4 - Batch 22000/50000 - Loss: 1.2758\n",
            "Epoch 2/4 - Batch 22050/50000 - Loss: 1.4540\n",
            "Epoch 2/4 - Batch 22100/50000 - Loss: 1.1590\n",
            "Epoch 2/4 - Batch 22150/50000 - Loss: 0.9455\n",
            "Epoch 2/4 - Batch 22200/50000 - Loss: 1.3566\n",
            "Epoch 2/4 - Batch 22250/50000 - Loss: 1.4349\n",
            "Epoch 2/4 - Batch 22300/50000 - Loss: 1.0566\n",
            "Epoch 2/4 - Batch 22350/50000 - Loss: 1.5493\n",
            "Epoch 2/4 - Batch 22400/50000 - Loss: 0.8224\n",
            "Epoch 2/4 - Batch 22450/50000 - Loss: 1.0241\n",
            "Epoch 2/4 - Batch 22500/50000 - Loss: 1.0299\n",
            "Epoch 2/4 - Batch 22550/50000 - Loss: 1.4248\n",
            "Epoch 2/4 - Batch 22600/50000 - Loss: 1.2136\n",
            "Epoch 2/4 - Batch 22650/50000 - Loss: 1.3672\n",
            "Epoch 2/4 - Batch 22700/50000 - Loss: 1.3685\n",
            "Epoch 2/4 - Batch 22750/50000 - Loss: 1.6890\n",
            "Epoch 2/4 - Batch 22800/50000 - Loss: 1.9937\n",
            "Epoch 2/4 - Batch 22850/50000 - Loss: 0.8377\n",
            "Epoch 2/4 - Batch 22900/50000 - Loss: 2.0344\n",
            "Epoch 2/4 - Batch 22950/50000 - Loss: 1.3364\n",
            "Epoch 2/4 - Batch 23000/50000 - Loss: 1.5904\n",
            "Epoch 2/4 - Batch 23050/50000 - Loss: 1.4055\n",
            "Epoch 2/4 - Batch 23100/50000 - Loss: 1.1086\n",
            "Epoch 2/4 - Batch 23150/50000 - Loss: 0.8195\n",
            "Epoch 2/4 - Batch 23200/50000 - Loss: 1.3065\n",
            "Epoch 2/4 - Batch 23250/50000 - Loss: 0.7627\n",
            "Epoch 2/4 - Batch 23300/50000 - Loss: 1.4969\n",
            "Epoch 2/4 - Batch 23350/50000 - Loss: 0.8286\n",
            "Epoch 2/4 - Batch 23400/50000 - Loss: 1.3881\n",
            "Epoch 2/4 - Batch 23450/50000 - Loss: 0.8662\n",
            "Epoch 2/4 - Batch 23500/50000 - Loss: 1.9589\n",
            "Epoch 2/4 - Batch 23550/50000 - Loss: 1.2402\n",
            "Epoch 2/4 - Batch 23600/50000 - Loss: 1.0672\n",
            "Epoch 2/4 - Batch 23650/50000 - Loss: 1.0411\n",
            "Epoch 2/4 - Batch 23700/50000 - Loss: 1.1466\n",
            "Epoch 2/4 - Batch 23750/50000 - Loss: 1.2892\n",
            "Epoch 2/4 - Batch 23800/50000 - Loss: 0.9005\n",
            "Epoch 2/4 - Batch 23850/50000 - Loss: 1.1863\n",
            "Epoch 2/4 - Batch 23900/50000 - Loss: 1.8524\n",
            "Epoch 2/4 - Batch 23950/50000 - Loss: 0.8700\n",
            "Epoch 2/4 - Batch 24000/50000 - Loss: 0.9975\n",
            "Epoch 2/4 - Batch 24050/50000 - Loss: 1.1230\n",
            "Epoch 2/4 - Batch 24100/50000 - Loss: 1.3220\n",
            "Epoch 2/4 - Batch 24150/50000 - Loss: 1.4302\n",
            "Epoch 2/4 - Batch 24200/50000 - Loss: 1.6210\n",
            "Epoch 2/4 - Batch 24250/50000 - Loss: 1.3275\n",
            "Epoch 2/4 - Batch 24300/50000 - Loss: 0.9677\n",
            "Epoch 2/4 - Batch 24350/50000 - Loss: 1.7306\n",
            "Epoch 2/4 - Batch 24400/50000 - Loss: 1.8863\n",
            "Epoch 2/4 - Batch 24450/50000 - Loss: 1.9696\n",
            "Epoch 2/4 - Batch 24500/50000 - Loss: 1.4938\n",
            "Epoch 2/4 - Batch 24550/50000 - Loss: 1.2650\n",
            "Epoch 2/4 - Batch 24600/50000 - Loss: 1.4511\n",
            "Epoch 2/4 - Batch 24650/50000 - Loss: 0.6228\n",
            "Epoch 2/4 - Batch 24700/50000 - Loss: 1.4624\n",
            "Epoch 2/4 - Batch 24750/50000 - Loss: 1.2167\n",
            "Epoch 2/4 - Batch 24800/50000 - Loss: 1.6688\n",
            "Epoch 2/4 - Batch 24850/50000 - Loss: 1.4629\n",
            "Epoch 2/4 - Batch 24900/50000 - Loss: 1.1022\n",
            "Epoch 2/4 - Batch 24950/50000 - Loss: 1.2950\n",
            "Epoch 2/4 - Batch 25000/50000 - Loss: 1.1608\n",
            "Epoch 2/4 - Batch 25050/50000 - Loss: 1.7955\n",
            "Epoch 2/4 - Batch 25100/50000 - Loss: 1.6155\n",
            "Epoch 2/4 - Batch 25150/50000 - Loss: 1.0738\n",
            "Epoch 2/4 - Batch 25200/50000 - Loss: 1.5637\n",
            "Epoch 2/4 - Batch 25250/50000 - Loss: 1.4446\n",
            "Epoch 2/4 - Batch 25300/50000 - Loss: 1.1504\n",
            "Epoch 2/4 - Batch 25350/50000 - Loss: 1.5997\n",
            "Epoch 2/4 - Batch 25400/50000 - Loss: 0.9515\n",
            "Epoch 2/4 - Batch 25450/50000 - Loss: 0.5137\n",
            "Epoch 2/4 - Batch 25500/50000 - Loss: 1.3315\n",
            "Epoch 2/4 - Batch 25550/50000 - Loss: 1.3619\n",
            "Epoch 2/4 - Batch 25600/50000 - Loss: 1.3156\n",
            "Epoch 2/4 - Batch 25650/50000 - Loss: 2.0833\n",
            "Epoch 2/4 - Batch 25700/50000 - Loss: 1.4731\n",
            "Epoch 2/4 - Batch 25750/50000 - Loss: 1.8237\n",
            "Epoch 2/4 - Batch 25800/50000 - Loss: 1.2770\n",
            "Epoch 2/4 - Batch 25850/50000 - Loss: 0.8705\n",
            "Epoch 2/4 - Batch 25900/50000 - Loss: 1.3383\n",
            "Epoch 2/4 - Batch 25950/50000 - Loss: 1.5832\n",
            "Epoch 2/4 - Batch 26000/50000 - Loss: 0.4241\n",
            "Epoch 2/4 - Batch 26050/50000 - Loss: 1.3807\n",
            "Epoch 2/4 - Batch 26100/50000 - Loss: 1.3398\n",
            "Epoch 2/4 - Batch 26150/50000 - Loss: 1.3842\n",
            "Epoch 2/4 - Batch 26200/50000 - Loss: 0.9063\n",
            "Epoch 2/4 - Batch 26250/50000 - Loss: 1.1550\n",
            "Epoch 2/4 - Batch 26300/50000 - Loss: 1.7609\n",
            "Epoch 2/4 - Batch 26350/50000 - Loss: 1.8396\n",
            "Epoch 2/4 - Batch 26400/50000 - Loss: 1.0710\n",
            "Epoch 2/4 - Batch 26450/50000 - Loss: 1.8861\n",
            "Epoch 2/4 - Batch 26500/50000 - Loss: 1.2109\n",
            "Epoch 2/4 - Batch 26550/50000 - Loss: 1.2120\n",
            "Epoch 2/4 - Batch 26600/50000 - Loss: 1.0453\n",
            "Epoch 2/4 - Batch 26650/50000 - Loss: 1.7397\n",
            "Epoch 2/4 - Batch 26700/50000 - Loss: 1.5160\n",
            "Epoch 2/4 - Batch 26750/50000 - Loss: 1.2903\n",
            "Epoch 2/4 - Batch 26800/50000 - Loss: 0.8439\n",
            "Epoch 2/4 - Batch 26850/50000 - Loss: 0.9322\n",
            "Epoch 2/4 - Batch 26900/50000 - Loss: 1.8603\n",
            "Epoch 2/4 - Batch 26950/50000 - Loss: 1.5804\n",
            "Epoch 2/4 - Batch 27000/50000 - Loss: 1.1926\n",
            "Epoch 2/4 - Batch 27050/50000 - Loss: 0.9584\n",
            "Epoch 2/4 - Batch 27100/50000 - Loss: 1.9435\n",
            "Epoch 2/4 - Batch 27150/50000 - Loss: 0.5754\n",
            "Epoch 2/4 - Batch 27200/50000 - Loss: 1.7340\n",
            "Epoch 2/4 - Batch 27250/50000 - Loss: 1.5127\n",
            "Epoch 2/4 - Batch 27300/50000 - Loss: 1.1439\n",
            "Epoch 2/4 - Batch 27350/50000 - Loss: 1.2848\n",
            "Epoch 2/4 - Batch 27400/50000 - Loss: 0.9647\n",
            "Epoch 2/4 - Batch 27450/50000 - Loss: 1.6643\n",
            "Epoch 2/4 - Batch 27500/50000 - Loss: 1.1697\n",
            "Epoch 2/4 - Batch 27550/50000 - Loss: 1.2253\n",
            "Epoch 2/4 - Batch 27600/50000 - Loss: 0.9963\n",
            "Epoch 2/4 - Batch 27650/50000 - Loss: 0.6382\n",
            "Epoch 2/4 - Batch 27700/50000 - Loss: 1.7588\n",
            "Epoch 2/4 - Batch 27750/50000 - Loss: 1.4765\n",
            "Epoch 2/4 - Batch 27800/50000 - Loss: 0.7213\n",
            "Epoch 2/4 - Batch 27850/50000 - Loss: 1.4204\n",
            "Epoch 2/4 - Batch 27900/50000 - Loss: 0.9283\n",
            "Epoch 2/4 - Batch 27950/50000 - Loss: 0.4840\n",
            "Epoch 2/4 - Batch 28000/50000 - Loss: 1.7225\n",
            "Epoch 2/4 - Batch 28050/50000 - Loss: 1.7594\n",
            "Epoch 2/4 - Batch 28100/50000 - Loss: 1.1204\n",
            "Epoch 2/4 - Batch 28150/50000 - Loss: 1.2260\n",
            "Epoch 2/4 - Batch 28200/50000 - Loss: 1.0003\n",
            "Epoch 2/4 - Batch 28250/50000 - Loss: 1.7491\n",
            "Epoch 2/4 - Batch 28300/50000 - Loss: 0.7106\n",
            "Epoch 2/4 - Batch 28350/50000 - Loss: 1.5500\n",
            "Epoch 2/4 - Batch 28400/50000 - Loss: 1.9194\n",
            "Epoch 2/4 - Batch 28450/50000 - Loss: 1.8784\n",
            "Epoch 2/4 - Batch 28500/50000 - Loss: 1.4056\n",
            "Epoch 2/4 - Batch 28550/50000 - Loss: 1.8208\n",
            "Epoch 2/4 - Batch 28600/50000 - Loss: 0.9578\n",
            "Epoch 2/4 - Batch 28650/50000 - Loss: 0.8146\n",
            "Epoch 2/4 - Batch 28700/50000 - Loss: 1.1001\n",
            "Epoch 2/4 - Batch 28750/50000 - Loss: 1.5633\n",
            "Epoch 2/4 - Batch 28800/50000 - Loss: 2.0306\n",
            "Epoch 2/4 - Batch 28850/50000 - Loss: 1.1819\n",
            "Epoch 2/4 - Batch 28900/50000 - Loss: 1.2122\n",
            "Epoch 2/4 - Batch 28950/50000 - Loss: 1.3970\n",
            "Epoch 2/4 - Batch 29000/50000 - Loss: 1.0256\n",
            "Epoch 2/4 - Batch 29050/50000 - Loss: 0.6971\n",
            "Epoch 2/4 - Batch 29100/50000 - Loss: 1.2187\n",
            "Epoch 2/4 - Batch 29150/50000 - Loss: 1.1215\n",
            "Epoch 2/4 - Batch 29200/50000 - Loss: 1.6158\n",
            "Epoch 2/4 - Batch 29250/50000 - Loss: 0.5539\n",
            "Epoch 2/4 - Batch 29300/50000 - Loss: 0.9720\n",
            "Epoch 2/4 - Batch 29350/50000 - Loss: 1.4840\n",
            "Epoch 2/4 - Batch 29400/50000 - Loss: 1.2135\n",
            "Epoch 2/4 - Batch 29450/50000 - Loss: 0.7585\n",
            "Epoch 2/4 - Batch 29500/50000 - Loss: 1.6733\n",
            "Epoch 2/4 - Batch 29550/50000 - Loss: 1.7424\n",
            "Epoch 2/4 - Batch 29600/50000 - Loss: 1.7317\n",
            "Epoch 2/4 - Batch 29650/50000 - Loss: 1.3147\n",
            "Epoch 2/4 - Batch 29700/50000 - Loss: 1.2145\n",
            "Epoch 2/4 - Batch 29750/50000 - Loss: 0.4526\n",
            "Epoch 2/4 - Batch 29800/50000 - Loss: 1.1972\n",
            "Epoch 2/4 - Batch 29850/50000 - Loss: 1.2333\n",
            "Epoch 2/4 - Batch 29900/50000 - Loss: 1.2197\n",
            "Epoch 2/4 - Batch 29950/50000 - Loss: 1.2257\n",
            "Epoch 2/4 - Batch 30000/50000 - Loss: 1.4597\n",
            "Epoch 2/4 - Batch 30050/50000 - Loss: 1.7908\n",
            "Epoch 2/4 - Batch 30100/50000 - Loss: 1.4773\n",
            "Epoch 2/4 - Batch 30150/50000 - Loss: 1.4923\n",
            "Epoch 2/4 - Batch 30200/50000 - Loss: 1.7202\n",
            "Epoch 2/4 - Batch 30250/50000 - Loss: 1.7119\n",
            "Epoch 2/4 - Batch 30300/50000 - Loss: 1.2459\n",
            "Epoch 2/4 - Batch 30350/50000 - Loss: 1.3278\n",
            "Epoch 2/4 - Batch 30400/50000 - Loss: 1.4525\n",
            "Epoch 2/4 - Batch 30450/50000 - Loss: 1.1603\n",
            "Epoch 2/4 - Batch 30500/50000 - Loss: 1.3550\n",
            "Epoch 2/4 - Batch 30550/50000 - Loss: 1.9435\n",
            "Epoch 2/4 - Batch 30600/50000 - Loss: 1.7513\n",
            "Epoch 2/4 - Batch 30650/50000 - Loss: 1.2027\n",
            "Epoch 2/4 - Batch 30700/50000 - Loss: 1.6220\n",
            "Epoch 2/4 - Batch 30750/50000 - Loss: 1.6971\n",
            "Epoch 2/4 - Batch 30800/50000 - Loss: 1.1739\n",
            "Epoch 2/4 - Batch 30850/50000 - Loss: 1.2376\n",
            "Epoch 2/4 - Batch 30900/50000 - Loss: 1.5513\n",
            "Epoch 2/4 - Batch 30950/50000 - Loss: 0.6851\n",
            "Epoch 2/4 - Batch 31000/50000 - Loss: 1.4173\n",
            "Epoch 2/4 - Batch 31050/50000 - Loss: 1.4717\n",
            "Epoch 2/4 - Batch 31100/50000 - Loss: 0.7415\n",
            "Epoch 2/4 - Batch 31150/50000 - Loss: 1.8352\n",
            "Epoch 2/4 - Batch 31200/50000 - Loss: 1.3456\n",
            "Epoch 2/4 - Batch 31250/50000 - Loss: 1.4927\n",
            "Epoch 2/4 - Batch 31300/50000 - Loss: 1.2412\n",
            "Epoch 2/4 - Batch 31350/50000 - Loss: 1.1428\n",
            "Epoch 2/4 - Batch 31400/50000 - Loss: 0.9097\n",
            "Epoch 2/4 - Batch 31450/50000 - Loss: 1.6485\n",
            "Epoch 2/4 - Batch 31500/50000 - Loss: 1.8097\n",
            "Epoch 2/4 - Batch 31550/50000 - Loss: 1.6775\n",
            "Epoch 2/4 - Batch 31600/50000 - Loss: 1.6550\n",
            "Epoch 2/4 - Batch 31650/50000 - Loss: 1.0249\n",
            "Epoch 2/4 - Batch 31700/50000 - Loss: 2.1107\n",
            "Epoch 2/4 - Batch 31750/50000 - Loss: 1.0255\n",
            "Epoch 2/4 - Batch 31800/50000 - Loss: 1.4337\n",
            "Epoch 2/4 - Batch 31850/50000 - Loss: 1.0055\n",
            "Epoch 2/4 - Batch 31900/50000 - Loss: 0.8433\n",
            "Epoch 2/4 - Batch 31950/50000 - Loss: 1.0797\n",
            "Epoch 2/4 - Batch 32000/50000 - Loss: 1.4825\n",
            "Epoch 2/4 - Batch 32050/50000 - Loss: 1.6409\n",
            "Epoch 2/4 - Batch 32100/50000 - Loss: 1.0113\n",
            "Epoch 2/4 - Batch 32150/50000 - Loss: 1.2844\n",
            "Epoch 2/4 - Batch 32200/50000 - Loss: 1.1845\n",
            "Epoch 2/4 - Batch 32250/50000 - Loss: 1.4735\n",
            "Epoch 2/4 - Batch 32300/50000 - Loss: 0.6194\n",
            "Epoch 2/4 - Batch 32350/50000 - Loss: 0.9825\n",
            "Epoch 2/4 - Batch 32400/50000 - Loss: 1.1508\n",
            "Epoch 2/4 - Batch 32450/50000 - Loss: 1.2009\n",
            "Epoch 2/4 - Batch 32500/50000 - Loss: 1.2796\n",
            "Epoch 2/4 - Batch 32550/50000 - Loss: 1.9809\n",
            "Epoch 2/4 - Batch 32600/50000 - Loss: 1.3527\n",
            "Epoch 2/4 - Batch 32650/50000 - Loss: 1.1486\n",
            "Epoch 2/4 - Batch 32700/50000 - Loss: 0.6569\n",
            "Epoch 2/4 - Batch 32750/50000 - Loss: 1.6259\n",
            "Epoch 2/4 - Batch 32800/50000 - Loss: 1.4011\n",
            "Epoch 2/4 - Batch 32850/50000 - Loss: 1.8343\n",
            "Epoch 2/4 - Batch 32900/50000 - Loss: 1.7590\n",
            "Epoch 2/4 - Batch 32950/50000 - Loss: 1.3530\n",
            "Epoch 2/4 - Batch 33000/50000 - Loss: 1.9698\n",
            "Epoch 2/4 - Batch 33050/50000 - Loss: 1.4946\n",
            "Epoch 2/4 - Batch 33100/50000 - Loss: 1.2497\n",
            "Epoch 2/4 - Batch 33150/50000 - Loss: 1.1702\n",
            "Epoch 2/4 - Batch 33200/50000 - Loss: 1.3762\n",
            "Epoch 2/4 - Batch 33250/50000 - Loss: 1.3293\n",
            "Epoch 2/4 - Batch 33300/50000 - Loss: 0.9770\n",
            "Epoch 2/4 - Batch 33350/50000 - Loss: 1.4393\n",
            "Epoch 2/4 - Batch 33400/50000 - Loss: 1.2745\n",
            "Epoch 2/4 - Batch 33450/50000 - Loss: 1.1512\n",
            "Epoch 2/4 - Batch 33500/50000 - Loss: 1.0492\n",
            "Epoch 2/4 - Batch 33550/50000 - Loss: 1.4781\n",
            "Epoch 2/4 - Batch 33600/50000 - Loss: 1.0326\n",
            "Epoch 2/4 - Batch 33650/50000 - Loss: 0.8255\n",
            "Epoch 2/4 - Batch 33700/50000 - Loss: 1.3388\n",
            "Epoch 2/4 - Batch 33750/50000 - Loss: 1.6181\n",
            "Epoch 2/4 - Batch 33800/50000 - Loss: 1.3610\n",
            "Epoch 2/4 - Batch 33850/50000 - Loss: 1.7397\n",
            "Epoch 2/4 - Batch 33900/50000 - Loss: 1.1074\n",
            "Epoch 2/4 - Batch 33950/50000 - Loss: 0.7077\n",
            "Epoch 2/4 - Batch 34000/50000 - Loss: 1.8393\n",
            "Epoch 2/4 - Batch 34050/50000 - Loss: 1.4823\n",
            "Epoch 2/4 - Batch 34100/50000 - Loss: 1.4091\n",
            "Epoch 2/4 - Batch 34150/50000 - Loss: 1.3923\n",
            "Epoch 2/4 - Batch 34200/50000 - Loss: 1.8682\n",
            "Epoch 2/4 - Batch 34250/50000 - Loss: 1.0509\n",
            "Epoch 2/4 - Batch 34300/50000 - Loss: 1.7458\n",
            "Epoch 2/4 - Batch 34350/50000 - Loss: 1.3703\n",
            "Epoch 2/4 - Batch 34400/50000 - Loss: 1.3607\n",
            "Epoch 2/4 - Batch 34450/50000 - Loss: 1.5680\n",
            "Epoch 2/4 - Batch 34500/50000 - Loss: 1.5374\n",
            "Epoch 2/4 - Batch 34550/50000 - Loss: 2.1249\n",
            "Epoch 2/4 - Batch 34600/50000 - Loss: 1.5600\n",
            "Epoch 2/4 - Batch 34650/50000 - Loss: 1.5280\n",
            "Epoch 2/4 - Batch 34700/50000 - Loss: 1.7699\n",
            "Epoch 2/4 - Batch 34750/50000 - Loss: 1.7685\n",
            "Epoch 2/4 - Batch 34800/50000 - Loss: 1.8022\n",
            "Epoch 2/4 - Batch 34850/50000 - Loss: 1.7991\n",
            "Epoch 2/4 - Batch 34900/50000 - Loss: 0.6551\n",
            "Epoch 2/4 - Batch 34950/50000 - Loss: 0.9549\n",
            "Epoch 2/4 - Batch 35000/50000 - Loss: 1.2327\n",
            "Epoch 2/4 - Batch 35050/50000 - Loss: 2.0572\n",
            "Epoch 2/4 - Batch 35100/50000 - Loss: 1.3567\n",
            "Epoch 2/4 - Batch 35150/50000 - Loss: 1.8750\n",
            "Epoch 2/4 - Batch 35200/50000 - Loss: 1.3735\n",
            "Epoch 2/4 - Batch 35250/50000 - Loss: 1.1878\n",
            "Epoch 2/4 - Batch 35300/50000 - Loss: 1.8475\n",
            "Epoch 2/4 - Batch 35350/50000 - Loss: 1.5249\n",
            "Epoch 2/4 - Batch 35400/50000 - Loss: 1.2628\n",
            "Epoch 2/4 - Batch 35450/50000 - Loss: 1.4573\n",
            "Epoch 2/4 - Batch 35500/50000 - Loss: 1.5555\n",
            "Epoch 2/4 - Batch 35550/50000 - Loss: 1.8181\n",
            "Epoch 2/4 - Batch 35600/50000 - Loss: 0.8922\n",
            "Epoch 2/4 - Batch 35650/50000 - Loss: 1.4698\n",
            "Epoch 2/4 - Batch 35700/50000 - Loss: 1.2260\n",
            "Epoch 2/4 - Batch 35750/50000 - Loss: 1.7341\n",
            "Epoch 2/4 - Batch 35800/50000 - Loss: 1.2397\n",
            "Epoch 2/4 - Batch 35850/50000 - Loss: 1.3544\n",
            "Epoch 2/4 - Batch 35900/50000 - Loss: 1.0116\n",
            "Epoch 2/4 - Batch 35950/50000 - Loss: 1.6036\n",
            "Epoch 2/4 - Batch 36000/50000 - Loss: 2.0797\n",
            "Epoch 2/4 - Batch 36050/50000 - Loss: 1.0907\n",
            "Epoch 2/4 - Batch 36100/50000 - Loss: 1.0677\n",
            "Epoch 2/4 - Batch 36150/50000 - Loss: 0.9701\n",
            "Epoch 2/4 - Batch 36200/50000 - Loss: 1.9210\n",
            "Epoch 2/4 - Batch 36250/50000 - Loss: 1.7198\n",
            "Epoch 2/4 - Batch 36300/50000 - Loss: 1.5102\n",
            "Epoch 2/4 - Batch 36350/50000 - Loss: 1.3614\n",
            "Epoch 2/4 - Batch 36400/50000 - Loss: 1.2922\n",
            "Epoch 2/4 - Batch 36450/50000 - Loss: 1.4446\n",
            "Epoch 2/4 - Batch 36500/50000 - Loss: 1.3938\n",
            "Epoch 2/4 - Batch 36550/50000 - Loss: 2.1186\n",
            "Epoch 2/4 - Batch 36600/50000 - Loss: 0.7539\n",
            "Epoch 2/4 - Batch 36650/50000 - Loss: 1.7487\n",
            "Epoch 2/4 - Batch 36700/50000 - Loss: 1.3426\n",
            "Epoch 2/4 - Batch 36750/50000 - Loss: 1.6936\n",
            "Epoch 2/4 - Batch 36800/50000 - Loss: 0.8172\n",
            "Epoch 2/4 - Batch 36850/50000 - Loss: 1.0016\n",
            "Epoch 2/4 - Batch 36900/50000 - Loss: 1.2639\n",
            "Epoch 2/4 - Batch 36950/50000 - Loss: 0.5251\n",
            "Epoch 2/4 - Batch 37000/50000 - Loss: 1.0305\n",
            "Epoch 2/4 - Batch 37050/50000 - Loss: 1.2009\n",
            "Epoch 2/4 - Batch 37100/50000 - Loss: 1.0157\n",
            "Epoch 2/4 - Batch 37150/50000 - Loss: 1.0605\n",
            "Epoch 2/4 - Batch 37200/50000 - Loss: 0.8044\n",
            "Epoch 2/4 - Batch 37250/50000 - Loss: 0.9621\n",
            "Epoch 2/4 - Batch 37300/50000 - Loss: 1.4598\n",
            "Epoch 2/4 - Batch 37350/50000 - Loss: 1.3917\n",
            "Epoch 2/4 - Batch 37400/50000 - Loss: 1.1635\n",
            "Epoch 2/4 - Batch 37450/50000 - Loss: 0.6421\n",
            "Epoch 2/4 - Batch 37500/50000 - Loss: 1.7896\n",
            "Epoch 2/4 - Batch 37550/50000 - Loss: 1.0933\n",
            "Epoch 2/4 - Batch 37600/50000 - Loss: 2.0045\n",
            "Epoch 2/4 - Batch 37650/50000 - Loss: 1.2614\n",
            "Epoch 2/4 - Batch 37700/50000 - Loss: 1.7803\n",
            "Epoch 2/4 - Batch 37750/50000 - Loss: 1.0103\n",
            "Epoch 2/4 - Batch 37800/50000 - Loss: 0.9751\n",
            "Epoch 2/4 - Batch 37850/50000 - Loss: 1.4609\n",
            "Epoch 2/4 - Batch 37900/50000 - Loss: 1.5352\n",
            "Epoch 2/4 - Batch 37950/50000 - Loss: 0.9412\n",
            "Epoch 2/4 - Batch 38000/50000 - Loss: 1.8357\n",
            "Epoch 2/4 - Batch 38050/50000 - Loss: 1.2358\n",
            "Epoch 2/4 - Batch 38100/50000 - Loss: 1.2964\n",
            "Epoch 2/4 - Batch 38150/50000 - Loss: 1.1067\n",
            "Epoch 2/4 - Batch 38200/50000 - Loss: 1.5835\n",
            "Epoch 2/4 - Batch 38250/50000 - Loss: 1.0633\n",
            "Epoch 2/4 - Batch 38300/50000 - Loss: 1.8919\n",
            "Epoch 2/4 - Batch 38350/50000 - Loss: 0.9441\n",
            "Epoch 2/4 - Batch 38400/50000 - Loss: 1.3286\n",
            "Epoch 2/4 - Batch 38450/50000 - Loss: 1.3595\n",
            "Epoch 2/4 - Batch 38500/50000 - Loss: 1.3631\n",
            "Epoch 2/4 - Batch 38550/50000 - Loss: 1.4265\n",
            "Epoch 2/4 - Batch 38600/50000 - Loss: 1.0747\n",
            "Epoch 2/4 - Batch 38650/50000 - Loss: 1.5847\n",
            "Epoch 2/4 - Batch 38700/50000 - Loss: 1.3355\n",
            "Epoch 2/4 - Batch 38750/50000 - Loss: 1.2186\n",
            "Epoch 2/4 - Batch 38800/50000 - Loss: 1.3904\n",
            "Epoch 2/4 - Batch 38850/50000 - Loss: 1.3883\n",
            "Epoch 2/4 - Batch 38900/50000 - Loss: 0.8354\n",
            "Epoch 2/4 - Batch 38950/50000 - Loss: 1.7644\n",
            "Epoch 2/4 - Batch 39000/50000 - Loss: 1.3822\n",
            "Epoch 2/4 - Batch 39050/50000 - Loss: 1.0583\n",
            "Epoch 2/4 - Batch 39100/50000 - Loss: 1.0823\n",
            "Epoch 2/4 - Batch 39150/50000 - Loss: 1.6430\n",
            "Epoch 2/4 - Batch 39200/50000 - Loss: 0.7203\n",
            "Epoch 2/4 - Batch 39250/50000 - Loss: 1.4684\n",
            "Epoch 2/4 - Batch 39300/50000 - Loss: 1.3359\n",
            "Epoch 2/4 - Batch 39350/50000 - Loss: 1.7072\n",
            "Epoch 2/4 - Batch 39400/50000 - Loss: 1.5139\n",
            "Epoch 2/4 - Batch 39450/50000 - Loss: 0.6851\n",
            "Epoch 2/4 - Batch 39500/50000 - Loss: 1.1301\n",
            "Epoch 2/4 - Batch 39550/50000 - Loss: 1.8284\n",
            "Epoch 2/4 - Batch 39600/50000 - Loss: 0.9985\n",
            "Epoch 2/4 - Batch 39650/50000 - Loss: 0.8260\n",
            "Epoch 2/4 - Batch 39700/50000 - Loss: 1.8609\n",
            "Epoch 2/4 - Batch 39750/50000 - Loss: 1.7581\n",
            "Epoch 2/4 - Batch 39800/50000 - Loss: 1.8449\n",
            "Epoch 2/4 - Batch 39850/50000 - Loss: 1.2357\n",
            "Epoch 2/4 - Batch 39900/50000 - Loss: 1.9151\n",
            "Epoch 2/4 - Batch 39950/50000 - Loss: 0.9000\n",
            "Epoch 2/4 - Batch 40000/50000 - Loss: 0.9421\n",
            "Epoch 2/4 - Batch 40050/50000 - Loss: 1.9371\n",
            "Epoch 2/4 - Batch 40100/50000 - Loss: 1.6099\n",
            "Epoch 2/4 - Batch 40150/50000 - Loss: 0.6111\n",
            "Epoch 2/4 - Batch 40200/50000 - Loss: 1.2322\n",
            "Epoch 2/4 - Batch 40250/50000 - Loss: 1.2348\n",
            "Epoch 2/4 - Batch 40300/50000 - Loss: 1.1453\n",
            "Epoch 2/4 - Batch 40350/50000 - Loss: 1.3038\n",
            "Epoch 2/4 - Batch 40400/50000 - Loss: 0.8999\n",
            "Epoch 2/4 - Batch 40450/50000 - Loss: 1.3104\n",
            "Epoch 2/4 - Batch 40500/50000 - Loss: 1.6037\n",
            "Epoch 2/4 - Batch 40550/50000 - Loss: 1.0779\n",
            "Epoch 2/4 - Batch 40600/50000 - Loss: 1.6232\n",
            "Epoch 2/4 - Batch 40650/50000 - Loss: 0.6213\n",
            "Epoch 2/4 - Batch 40700/50000 - Loss: 1.6901\n",
            "Epoch 2/4 - Batch 40750/50000 - Loss: 0.7045\n",
            "Epoch 2/4 - Batch 40800/50000 - Loss: 1.4678\n",
            "Epoch 2/4 - Batch 40850/50000 - Loss: 1.9034\n",
            "Epoch 2/4 - Batch 40900/50000 - Loss: 1.7438\n",
            "Epoch 2/4 - Batch 40950/50000 - Loss: 1.7789\n",
            "Epoch 2/4 - Batch 41000/50000 - Loss: 1.7137\n",
            "Epoch 2/4 - Batch 41050/50000 - Loss: 1.1229\n",
            "Epoch 2/4 - Batch 41100/50000 - Loss: 1.2267\n",
            "Epoch 2/4 - Batch 41150/50000 - Loss: 1.3348\n",
            "Epoch 2/4 - Batch 41200/50000 - Loss: 1.3340\n",
            "Epoch 2/4 - Batch 41250/50000 - Loss: 1.0683\n",
            "Epoch 2/4 - Batch 41300/50000 - Loss: 1.8427\n",
            "Epoch 2/4 - Batch 41350/50000 - Loss: 1.1955\n",
            "Epoch 2/4 - Batch 41400/50000 - Loss: 1.5257\n",
            "Epoch 2/4 - Batch 41450/50000 - Loss: 1.3526\n",
            "Epoch 2/4 - Batch 41500/50000 - Loss: 1.2965\n",
            "Epoch 2/4 - Batch 41550/50000 - Loss: 0.9104\n",
            "Epoch 2/4 - Batch 41600/50000 - Loss: 0.6072\n",
            "Epoch 2/4 - Batch 41650/50000 - Loss: 0.9940\n",
            "Epoch 2/4 - Batch 41700/50000 - Loss: 1.1866\n",
            "Epoch 2/4 - Batch 41750/50000 - Loss: 1.6065\n",
            "Epoch 2/4 - Batch 41800/50000 - Loss: 1.2417\n",
            "Epoch 2/4 - Batch 41850/50000 - Loss: 1.0477\n",
            "Epoch 2/4 - Batch 41900/50000 - Loss: 1.3556\n",
            "Epoch 2/4 - Batch 41950/50000 - Loss: 1.0741\n",
            "Epoch 2/4 - Batch 42000/50000 - Loss: 0.8621\n",
            "Epoch 2/4 - Batch 42050/50000 - Loss: 1.6482\n",
            "Epoch 2/4 - Batch 42100/50000 - Loss: 1.5855\n",
            "Epoch 2/4 - Batch 42150/50000 - Loss: 1.0347\n",
            "Epoch 2/4 - Batch 42200/50000 - Loss: 1.2913\n",
            "Epoch 2/4 - Batch 42250/50000 - Loss: 1.5615\n",
            "Epoch 2/4 - Batch 42300/50000 - Loss: 1.1549\n",
            "Epoch 2/4 - Batch 42350/50000 - Loss: 0.8173\n",
            "Epoch 2/4 - Batch 42400/50000 - Loss: 0.9510\n",
            "Epoch 2/4 - Batch 42450/50000 - Loss: 1.2962\n",
            "Epoch 2/4 - Batch 42500/50000 - Loss: 1.5219\n",
            "Epoch 2/4 - Batch 42550/50000 - Loss: 1.4882\n",
            "Epoch 2/4 - Batch 42600/50000 - Loss: 1.0887\n",
            "Epoch 2/4 - Batch 42650/50000 - Loss: 1.0513\n",
            "Epoch 2/4 - Batch 42700/50000 - Loss: 1.2222\n",
            "Epoch 2/4 - Batch 42750/50000 - Loss: 0.8181\n",
            "Epoch 2/4 - Batch 42800/50000 - Loss: 1.5347\n",
            "Epoch 2/4 - Batch 42850/50000 - Loss: 1.6308\n",
            "Epoch 2/4 - Batch 42900/50000 - Loss: 0.9920\n",
            "Epoch 2/4 - Batch 42950/50000 - Loss: 1.8636\n",
            "Epoch 2/4 - Batch 43000/50000 - Loss: 1.4390\n",
            "Epoch 2/4 - Batch 43050/50000 - Loss: 1.1553\n",
            "Epoch 2/4 - Batch 43100/50000 - Loss: 1.0921\n",
            "Epoch 2/4 - Batch 43150/50000 - Loss: 1.4879\n",
            "Epoch 2/4 - Batch 43200/50000 - Loss: 1.6834\n",
            "Epoch 2/4 - Batch 43250/50000 - Loss: 0.4495\n",
            "Epoch 2/4 - Batch 43300/50000 - Loss: 0.9473\n",
            "Epoch 2/4 - Batch 43350/50000 - Loss: 1.3210\n",
            "Epoch 2/4 - Batch 43400/50000 - Loss: 1.0019\n",
            "Epoch 2/4 - Batch 43450/50000 - Loss: 0.9632\n",
            "Epoch 2/4 - Batch 43500/50000 - Loss: 1.2430\n",
            "Epoch 2/4 - Batch 43550/50000 - Loss: 1.0701\n",
            "Epoch 2/4 - Batch 43600/50000 - Loss: 1.1488\n",
            "Epoch 2/4 - Batch 43650/50000 - Loss: 1.8755\n",
            "Epoch 2/4 - Batch 43700/50000 - Loss: 1.0537\n",
            "Epoch 2/4 - Batch 43750/50000 - Loss: 1.6236\n",
            "Epoch 2/4 - Batch 43800/50000 - Loss: 1.3491\n",
            "Epoch 2/4 - Batch 43850/50000 - Loss: 0.4682\n",
            "Epoch 2/4 - Batch 43900/50000 - Loss: 1.4989\n",
            "Epoch 2/4 - Batch 43950/50000 - Loss: 0.9878\n",
            "Epoch 2/4 - Batch 44000/50000 - Loss: 0.7531\n",
            "Epoch 2/4 - Batch 44050/50000 - Loss: 0.6274\n",
            "Epoch 2/4 - Batch 44100/50000 - Loss: 1.4453\n",
            "Epoch 2/4 - Batch 44150/50000 - Loss: 1.2240\n",
            "Epoch 2/4 - Batch 44200/50000 - Loss: 1.4527\n",
            "Epoch 2/4 - Batch 44250/50000 - Loss: 0.9834\n",
            "Epoch 2/4 - Batch 44300/50000 - Loss: 1.7774\n",
            "Epoch 2/4 - Batch 44350/50000 - Loss: 1.3392\n",
            "Epoch 2/4 - Batch 44400/50000 - Loss: 1.0869\n",
            "Epoch 2/4 - Batch 44450/50000 - Loss: 1.4764\n",
            "Epoch 2/4 - Batch 44500/50000 - Loss: 1.7447\n",
            "Epoch 2/4 - Batch 44550/50000 - Loss: 0.8351\n",
            "Epoch 2/4 - Batch 44600/50000 - Loss: 0.9481\n",
            "Epoch 2/4 - Batch 44650/50000 - Loss: 1.7151\n",
            "Epoch 2/4 - Batch 44700/50000 - Loss: 1.3930\n",
            "Epoch 2/4 - Batch 44750/50000 - Loss: 1.3975\n",
            "Epoch 2/4 - Batch 44800/50000 - Loss: 1.3769\n",
            "Epoch 2/4 - Batch 44850/50000 - Loss: 1.5473\n",
            "Epoch 2/4 - Batch 44900/50000 - Loss: 1.8027\n",
            "Epoch 2/4 - Batch 44950/50000 - Loss: 1.5971\n",
            "Epoch 2/4 - Batch 45000/50000 - Loss: 0.7858\n",
            "Epoch 2/4 - Batch 45050/50000 - Loss: 0.9574\n",
            "Epoch 2/4 - Batch 45100/50000 - Loss: 1.4351\n",
            "Epoch 2/4 - Batch 45150/50000 - Loss: 1.7364\n",
            "Epoch 2/4 - Batch 45200/50000 - Loss: 1.7283\n",
            "Epoch 2/4 - Batch 45250/50000 - Loss: 1.2204\n",
            "Epoch 2/4 - Batch 45300/50000 - Loss: 1.1638\n",
            "Epoch 2/4 - Batch 45350/50000 - Loss: 1.8262\n",
            "Epoch 2/4 - Batch 45400/50000 - Loss: 0.8186\n",
            "Epoch 2/4 - Batch 45450/50000 - Loss: 1.7244\n",
            "Epoch 2/4 - Batch 45500/50000 - Loss: 1.1013\n",
            "Epoch 2/4 - Batch 45550/50000 - Loss: 0.8455\n",
            "Epoch 2/4 - Batch 45600/50000 - Loss: 1.9569\n",
            "Epoch 2/4 - Batch 45650/50000 - Loss: 1.9907\n",
            "Epoch 2/4 - Batch 45700/50000 - Loss: 0.7105\n",
            "Epoch 2/4 - Batch 45750/50000 - Loss: 1.3700\n",
            "Epoch 2/4 - Batch 45800/50000 - Loss: 0.9799\n",
            "Epoch 2/4 - Batch 45850/50000 - Loss: 1.3564\n",
            "Epoch 2/4 - Batch 45900/50000 - Loss: 0.7368\n",
            "Epoch 2/4 - Batch 45950/50000 - Loss: 1.2108\n",
            "Epoch 2/4 - Batch 46000/50000 - Loss: 1.4104\n",
            "Epoch 2/4 - Batch 46050/50000 - Loss: 1.1895\n",
            "Epoch 2/4 - Batch 46100/50000 - Loss: 1.4940\n",
            "Epoch 2/4 - Batch 46150/50000 - Loss: 1.1028\n",
            "Epoch 2/4 - Batch 46200/50000 - Loss: 1.2899\n",
            "Epoch 2/4 - Batch 46250/50000 - Loss: 1.7465\n",
            "Epoch 2/4 - Batch 46300/50000 - Loss: 2.0003\n",
            "Epoch 2/4 - Batch 46350/50000 - Loss: 1.5460\n",
            "Epoch 2/4 - Batch 46400/50000 - Loss: 1.6278\n",
            "Epoch 2/4 - Batch 46450/50000 - Loss: 1.6513\n",
            "Epoch 2/4 - Batch 46500/50000 - Loss: 0.8486\n",
            "Epoch 2/4 - Batch 46550/50000 - Loss: 0.7854\n",
            "Epoch 2/4 - Batch 46600/50000 - Loss: 1.7556\n",
            "Epoch 2/4 - Batch 46650/50000 - Loss: 1.3081\n",
            "Epoch 2/4 - Batch 46700/50000 - Loss: 1.0060\n",
            "Epoch 2/4 - Batch 46750/50000 - Loss: 1.0573\n",
            "Epoch 2/4 - Batch 46800/50000 - Loss: 1.2869\n",
            "Epoch 2/4 - Batch 46850/50000 - Loss: 0.8980\n",
            "Epoch 2/4 - Batch 46900/50000 - Loss: 1.9192\n",
            "Epoch 2/4 - Batch 46950/50000 - Loss: 1.1471\n",
            "Epoch 2/4 - Batch 47000/50000 - Loss: 1.4092\n",
            "Epoch 2/4 - Batch 47050/50000 - Loss: 1.0000\n",
            "Epoch 2/4 - Batch 47100/50000 - Loss: 1.0561\n",
            "Epoch 2/4 - Batch 47150/50000 - Loss: 1.5360\n",
            "Epoch 2/4 - Batch 47200/50000 - Loss: 1.5429\n",
            "Epoch 2/4 - Batch 47250/50000 - Loss: 1.3636\n",
            "Epoch 2/4 - Batch 47300/50000 - Loss: 0.7938\n",
            "Epoch 2/4 - Batch 47350/50000 - Loss: 1.2584\n",
            "Epoch 2/4 - Batch 47400/50000 - Loss: 0.8701\n",
            "Epoch 2/4 - Batch 47450/50000 - Loss: 1.3583\n",
            "Epoch 2/4 - Batch 47500/50000 - Loss: 0.5741\n",
            "Epoch 2/4 - Batch 47550/50000 - Loss: 1.1484\n",
            "Epoch 2/4 - Batch 47600/50000 - Loss: 1.1212\n",
            "Epoch 2/4 - Batch 47650/50000 - Loss: 1.9965\n",
            "Epoch 2/4 - Batch 47700/50000 - Loss: 1.1507\n",
            "Epoch 2/4 - Batch 47750/50000 - Loss: 1.0835\n",
            "Epoch 2/4 - Batch 47800/50000 - Loss: 0.7580\n",
            "Epoch 2/4 - Batch 47850/50000 - Loss: 1.2813\n",
            "Epoch 2/4 - Batch 47900/50000 - Loss: 1.3212\n",
            "Epoch 2/4 - Batch 47950/50000 - Loss: 1.2731\n",
            "Epoch 2/4 - Batch 48000/50000 - Loss: 1.2277\n",
            "Epoch 2/4 - Batch 48050/50000 - Loss: 0.8895\n",
            "Epoch 2/4 - Batch 48100/50000 - Loss: 1.8848\n",
            "Epoch 2/4 - Batch 48150/50000 - Loss: 1.4994\n",
            "Epoch 2/4 - Batch 48200/50000 - Loss: 1.6784\n",
            "Epoch 2/4 - Batch 48250/50000 - Loss: 1.4743\n",
            "Epoch 2/4 - Batch 48300/50000 - Loss: 1.0498\n",
            "Epoch 2/4 - Batch 48350/50000 - Loss: 1.8556\n",
            "Epoch 2/4 - Batch 48400/50000 - Loss: 1.7707\n",
            "Epoch 2/4 - Batch 48450/50000 - Loss: 1.4796\n",
            "Epoch 2/4 - Batch 48500/50000 - Loss: 1.6439\n",
            "Epoch 2/4 - Batch 48550/50000 - Loss: 1.2647\n",
            "Epoch 2/4 - Batch 48600/50000 - Loss: 1.3324\n",
            "Epoch 2/4 - Batch 48650/50000 - Loss: 1.5672\n",
            "Epoch 2/4 - Batch 48700/50000 - Loss: 0.8775\n",
            "Epoch 2/4 - Batch 48750/50000 - Loss: 1.2801\n",
            "Epoch 2/4 - Batch 48800/50000 - Loss: 1.6202\n",
            "Epoch 2/4 - Batch 48850/50000 - Loss: 0.9464\n",
            "Epoch 2/4 - Batch 48900/50000 - Loss: 1.4581\n",
            "Epoch 2/4 - Batch 48950/50000 - Loss: 1.5661\n",
            "Epoch 2/4 - Batch 49000/50000 - Loss: 1.1181\n",
            "Epoch 2/4 - Batch 49050/50000 - Loss: 1.4015\n",
            "Epoch 2/4 - Batch 49100/50000 - Loss: 1.1371\n",
            "Epoch 2/4 - Batch 49150/50000 - Loss: 0.7843\n",
            "Epoch 2/4 - Batch 49200/50000 - Loss: 0.9126\n",
            "Epoch 2/4 - Batch 49250/50000 - Loss: 1.5007\n",
            "Epoch 2/4 - Batch 49300/50000 - Loss: 1.2253\n",
            "Epoch 2/4 - Batch 49350/50000 - Loss: 1.8889\n",
            "Epoch 2/4 - Batch 49400/50000 - Loss: 1.5510\n",
            "Epoch 2/4 - Batch 49450/50000 - Loss: 1.5251\n",
            "Epoch 2/4 - Batch 49500/50000 - Loss: 1.4942\n",
            "Epoch 2/4 - Batch 49550/50000 - Loss: 0.9384\n",
            "Epoch 2/4 - Batch 49600/50000 - Loss: 2.0753\n",
            "Epoch 2/4 - Batch 49650/50000 - Loss: 0.9739\n",
            "Epoch 2/4 - Batch 49700/50000 - Loss: 1.2400\n",
            "Epoch 2/4 - Batch 49750/50000 - Loss: 1.2132\n",
            "Epoch 2/4 - Batch 49800/50000 - Loss: 1.6135\n",
            "Epoch 2/4 - Batch 49850/50000 - Loss: 1.4652\n",
            "Epoch 2/4 - Batch 49900/50000 - Loss: 1.6455\n",
            "Epoch 2/4 - Batch 49950/50000 - Loss: 1.3234\n",
            "Epoch 2/4 - Average loss: 1.3166 - Duration: 26884.30s\n",
            "Epoch 3/4 - Batch 0/50000 - Loss: 1.5074\n",
            "Epoch 3/4 - Batch 50/50000 - Loss: 1.7055\n",
            "Epoch 3/4 - Batch 100/50000 - Loss: 1.3846\n",
            "Epoch 3/4 - Batch 150/50000 - Loss: 0.9129\n",
            "Epoch 3/4 - Batch 200/50000 - Loss: 1.5912\n",
            "Epoch 3/4 - Batch 250/50000 - Loss: 0.7181\n",
            "Epoch 3/4 - Batch 300/50000 - Loss: 1.1126\n",
            "Epoch 3/4 - Batch 350/50000 - Loss: 1.4640\n",
            "Epoch 3/4 - Batch 400/50000 - Loss: 1.4824\n",
            "Epoch 3/4 - Batch 450/50000 - Loss: 1.2417\n",
            "Epoch 3/4 - Batch 500/50000 - Loss: 1.6376\n",
            "Epoch 3/4 - Batch 550/50000 - Loss: 1.5602\n",
            "Epoch 3/4 - Batch 600/50000 - Loss: 1.5805\n",
            "Epoch 3/4 - Batch 650/50000 - Loss: 1.2530\n",
            "Epoch 3/4 - Batch 700/50000 - Loss: 1.4897\n",
            "Epoch 3/4 - Batch 750/50000 - Loss: 0.7877\n",
            "Epoch 3/4 - Batch 800/50000 - Loss: 1.0945\n",
            "Epoch 3/4 - Batch 850/50000 - Loss: 0.6029\n",
            "Epoch 3/4 - Batch 900/50000 - Loss: 0.9628\n",
            "Epoch 3/4 - Batch 950/50000 - Loss: 1.4221\n",
            "Epoch 3/4 - Batch 1000/50000 - Loss: 1.1448\n",
            "Epoch 3/4 - Batch 1050/50000 - Loss: 0.8515\n",
            "Epoch 3/4 - Batch 1100/50000 - Loss: 1.6904\n",
            "Epoch 3/4 - Batch 1150/50000 - Loss: 1.0952\n",
            "Epoch 3/4 - Batch 1200/50000 - Loss: 1.8039\n",
            "Epoch 3/4 - Batch 1250/50000 - Loss: 1.2164\n",
            "Epoch 3/4 - Batch 1300/50000 - Loss: 1.3110\n",
            "Epoch 3/4 - Batch 1350/50000 - Loss: 0.5980\n",
            "Epoch 3/4 - Batch 1400/50000 - Loss: 1.8228\n",
            "Epoch 3/4 - Batch 1450/50000 - Loss: 1.6132\n",
            "Epoch 3/4 - Batch 1500/50000 - Loss: 1.3058\n",
            "Epoch 3/4 - Batch 1550/50000 - Loss: 1.2817\n",
            "Epoch 3/4 - Batch 1600/50000 - Loss: 1.4005\n",
            "Epoch 3/4 - Batch 1650/50000 - Loss: 0.9819\n",
            "Epoch 3/4 - Batch 1700/50000 - Loss: 1.3992\n",
            "Epoch 3/4 - Batch 1750/50000 - Loss: 1.0336\n",
            "Epoch 3/4 - Batch 1800/50000 - Loss: 1.7807\n",
            "Epoch 3/4 - Batch 1850/50000 - Loss: 0.9751\n",
            "Epoch 3/4 - Batch 1900/50000 - Loss: 1.4508\n",
            "Epoch 3/4 - Batch 1950/50000 - Loss: 1.5451\n",
            "Epoch 3/4 - Batch 2000/50000 - Loss: 1.2744\n",
            "Epoch 3/4 - Batch 2050/50000 - Loss: 1.0786\n",
            "Epoch 3/4 - Batch 2100/50000 - Loss: 0.9555\n",
            "Epoch 3/4 - Batch 2150/50000 - Loss: 0.7915\n",
            "Epoch 3/4 - Batch 2200/50000 - Loss: 0.8663\n",
            "Epoch 3/4 - Batch 2250/50000 - Loss: 1.3747\n",
            "Epoch 3/4 - Batch 2300/50000 - Loss: 0.5246\n",
            "Epoch 3/4 - Batch 2350/50000 - Loss: 1.5786\n",
            "Epoch 3/4 - Batch 2400/50000 - Loss: 1.1836\n",
            "Epoch 3/4 - Batch 2450/50000 - Loss: 1.1688\n",
            "Epoch 3/4 - Batch 2500/50000 - Loss: 1.2470\n",
            "Epoch 3/4 - Batch 2550/50000 - Loss: 1.9603\n",
            "Epoch 3/4 - Batch 2600/50000 - Loss: 1.3441\n",
            "Epoch 3/4 - Batch 2650/50000 - Loss: 1.3601\n",
            "Epoch 3/4 - Batch 2700/50000 - Loss: 1.1544\n",
            "Epoch 3/4 - Batch 2750/50000 - Loss: 1.8139\n",
            "Epoch 3/4 - Batch 2800/50000 - Loss: 1.6710\n",
            "Epoch 3/4 - Batch 2850/50000 - Loss: 0.7609\n",
            "Epoch 3/4 - Batch 2900/50000 - Loss: 1.4385\n",
            "Epoch 3/4 - Batch 2950/50000 - Loss: 0.9891\n",
            "Epoch 3/4 - Batch 3000/50000 - Loss: 1.7801\n",
            "Epoch 3/4 - Batch 3050/50000 - Loss: 0.7555\n",
            "Epoch 3/4 - Batch 3100/50000 - Loss: 1.3957\n",
            "Epoch 3/4 - Batch 3150/50000 - Loss: 0.8851\n",
            "Epoch 3/4 - Batch 3200/50000 - Loss: 0.6855\n",
            "Epoch 3/4 - Batch 3250/50000 - Loss: 1.7098\n",
            "Epoch 3/4 - Batch 3300/50000 - Loss: 1.9247\n",
            "Epoch 3/4 - Batch 3350/50000 - Loss: 0.8315\n",
            "Epoch 3/4 - Batch 3400/50000 - Loss: 1.5829\n",
            "Epoch 3/4 - Batch 3450/50000 - Loss: 1.5173\n",
            "Epoch 3/4 - Batch 3500/50000 - Loss: 0.6698\n",
            "Epoch 3/4 - Batch 3550/50000 - Loss: 1.8660\n",
            "Epoch 3/4 - Batch 3600/50000 - Loss: 0.8972\n",
            "Epoch 3/4 - Batch 3650/50000 - Loss: 1.6282\n",
            "Epoch 3/4 - Batch 3700/50000 - Loss: 1.3108\n",
            "Epoch 3/4 - Batch 3750/50000 - Loss: 1.3116\n",
            "Epoch 3/4 - Batch 3800/50000 - Loss: 0.9620\n",
            "Epoch 3/4 - Batch 3850/50000 - Loss: 1.6406\n",
            "Epoch 3/4 - Batch 3900/50000 - Loss: 1.3264\n",
            "Epoch 3/4 - Batch 3950/50000 - Loss: 1.0695\n",
            "Epoch 3/4 - Batch 4000/50000 - Loss: 1.6513\n",
            "Epoch 3/4 - Batch 4050/50000 - Loss: 1.6146\n",
            "Epoch 3/4 - Batch 4100/50000 - Loss: 1.6080\n",
            "Epoch 3/4 - Batch 4150/50000 - Loss: 0.9845\n",
            "Epoch 3/4 - Batch 4200/50000 - Loss: 1.3253\n",
            "Epoch 3/4 - Batch 4250/50000 - Loss: 1.3181\n",
            "Epoch 3/4 - Batch 4300/50000 - Loss: 1.5602\n",
            "Epoch 3/4 - Batch 4350/50000 - Loss: 0.9855\n",
            "Epoch 3/4 - Batch 4400/50000 - Loss: 1.0922\n",
            "Epoch 3/4 - Batch 4450/50000 - Loss: 1.1925\n",
            "Epoch 3/4 - Batch 4500/50000 - Loss: 1.3003\n",
            "Epoch 3/4 - Batch 4550/50000 - Loss: 0.5685\n",
            "Epoch 3/4 - Batch 4600/50000 - Loss: 0.7449\n",
            "Epoch 3/4 - Batch 4650/50000 - Loss: 1.4250\n",
            "Epoch 3/4 - Batch 4700/50000 - Loss: 1.0635\n",
            "Epoch 3/4 - Batch 4750/50000 - Loss: 1.3187\n",
            "Epoch 3/4 - Batch 4800/50000 - Loss: 1.0424\n",
            "Epoch 3/4 - Batch 4850/50000 - Loss: 1.0402\n",
            "Epoch 3/4 - Batch 4900/50000 - Loss: 1.8813\n",
            "Epoch 3/4 - Batch 4950/50000 - Loss: 1.6600\n",
            "Epoch 3/4 - Batch 5000/50000 - Loss: 1.6392\n",
            "Epoch 3/4 - Batch 5050/50000 - Loss: 1.6903\n",
            "Epoch 3/4 - Batch 5100/50000 - Loss: 1.5320\n",
            "Epoch 3/4 - Batch 5150/50000 - Loss: 0.8565\n",
            "Epoch 3/4 - Batch 5200/50000 - Loss: 0.8117\n",
            "Epoch 3/4 - Batch 5250/50000 - Loss: 1.9144\n",
            "Epoch 3/4 - Batch 5300/50000 - Loss: 1.1306\n",
            "Epoch 3/4 - Batch 5350/50000 - Loss: 1.1802\n",
            "Epoch 3/4 - Batch 5400/50000 - Loss: 0.6608\n",
            "Epoch 3/4 - Batch 5450/50000 - Loss: 0.8321\n",
            "Epoch 3/4 - Batch 5500/50000 - Loss: 1.5314\n",
            "Epoch 3/4 - Batch 5550/50000 - Loss: 1.5364\n",
            "Epoch 3/4 - Batch 5600/50000 - Loss: 1.3960\n",
            "Epoch 3/4 - Batch 5650/50000 - Loss: 0.8360\n",
            "Epoch 3/4 - Batch 5700/50000 - Loss: 1.1837\n",
            "Epoch 3/4 - Batch 5750/50000 - Loss: 0.5128\n",
            "Epoch 3/4 - Batch 5800/50000 - Loss: 0.9931\n",
            "Epoch 3/4 - Batch 5850/50000 - Loss: 1.6557\n",
            "Epoch 3/4 - Batch 5900/50000 - Loss: 1.6465\n",
            "Epoch 3/4 - Batch 5950/50000 - Loss: 1.5276\n",
            "Epoch 3/4 - Batch 6000/50000 - Loss: 1.1351\n",
            "Epoch 3/4 - Batch 6050/50000 - Loss: 0.6136\n",
            "Epoch 3/4 - Batch 6100/50000 - Loss: 0.2943\n",
            "Epoch 3/4 - Batch 6150/50000 - Loss: 1.8609\n",
            "Epoch 3/4 - Batch 6200/50000 - Loss: 0.7638\n",
            "Epoch 3/4 - Batch 6250/50000 - Loss: 1.5725\n",
            "Epoch 3/4 - Batch 6300/50000 - Loss: 1.2562\n",
            "Epoch 3/4 - Batch 6350/50000 - Loss: 1.0833\n",
            "Epoch 3/4 - Batch 6400/50000 - Loss: 1.2114\n",
            "Epoch 3/4 - Batch 6450/50000 - Loss: 1.4389\n",
            "Epoch 3/4 - Batch 6500/50000 - Loss: 1.1650\n",
            "Epoch 3/4 - Batch 6550/50000 - Loss: 1.7225\n",
            "Epoch 3/4 - Batch 6600/50000 - Loss: 1.6827\n",
            "Epoch 3/4 - Batch 6650/50000 - Loss: 1.2247\n",
            "Epoch 3/4 - Batch 6700/50000 - Loss: 1.4135\n",
            "Epoch 3/4 - Batch 6750/50000 - Loss: 1.6787\n",
            "Epoch 3/4 - Batch 6800/50000 - Loss: 1.4456\n",
            "Epoch 3/4 - Batch 6850/50000 - Loss: 0.7914\n",
            "Epoch 3/4 - Batch 6900/50000 - Loss: 0.8517\n",
            "Epoch 3/4 - Batch 6950/50000 - Loss: 1.5589\n",
            "Epoch 3/4 - Batch 7000/50000 - Loss: 1.6059\n",
            "Epoch 3/4 - Batch 7050/50000 - Loss: 1.5886\n",
            "Epoch 3/4 - Batch 7100/50000 - Loss: 1.3668\n",
            "Epoch 3/4 - Batch 7150/50000 - Loss: 1.6887\n",
            "Epoch 3/4 - Batch 7200/50000 - Loss: 1.2225\n",
            "Epoch 3/4 - Batch 7250/50000 - Loss: 1.2274\n",
            "Epoch 3/4 - Batch 7300/50000 - Loss: 0.7732\n",
            "Epoch 3/4 - Batch 7350/50000 - Loss: 0.7609\n",
            "Epoch 3/4 - Batch 7400/50000 - Loss: 1.1553\n",
            "Epoch 3/4 - Batch 7450/50000 - Loss: 1.7717\n",
            "Epoch 3/4 - Batch 7500/50000 - Loss: 0.8252\n",
            "Epoch 3/4 - Batch 7550/50000 - Loss: 1.3177\n",
            "Epoch 3/4 - Batch 7600/50000 - Loss: 1.6760\n",
            "Epoch 3/4 - Batch 7650/50000 - Loss: 1.1575\n",
            "Epoch 3/4 - Batch 7700/50000 - Loss: 0.7444\n",
            "Epoch 3/4 - Batch 7750/50000 - Loss: 1.4275\n",
            "Epoch 3/4 - Batch 7800/50000 - Loss: 1.4585\n",
            "Epoch 3/4 - Batch 7850/50000 - Loss: 1.2151\n",
            "Epoch 3/4 - Batch 7900/50000 - Loss: 1.5521\n",
            "Epoch 3/4 - Batch 7950/50000 - Loss: 1.7815\n",
            "Epoch 3/4 - Batch 8000/50000 - Loss: 1.5613\n",
            "Epoch 3/4 - Batch 8050/50000 - Loss: 1.0761\n",
            "Epoch 3/4 - Batch 8100/50000 - Loss: 1.2888\n",
            "Epoch 3/4 - Batch 8150/50000 - Loss: 1.4912\n",
            "Epoch 3/4 - Batch 8200/50000 - Loss: 1.3514\n",
            "Epoch 3/4 - Batch 8250/50000 - Loss: 0.5658\n",
            "Epoch 3/4 - Batch 8300/50000 - Loss: 0.3304\n",
            "Epoch 3/4 - Batch 8350/50000 - Loss: 0.9868\n",
            "Epoch 3/4 - Batch 8400/50000 - Loss: 0.7725\n",
            "Epoch 3/4 - Batch 8450/50000 - Loss: 1.2160\n",
            "Epoch 3/4 - Batch 8500/50000 - Loss: 0.7927\n",
            "Epoch 3/4 - Batch 8550/50000 - Loss: 1.4771\n",
            "Epoch 3/4 - Batch 8600/50000 - Loss: 1.4275\n",
            "Epoch 3/4 - Batch 8650/50000 - Loss: 1.5488\n",
            "Epoch 3/4 - Batch 8700/50000 - Loss: 0.9354\n",
            "Epoch 3/4 - Batch 8750/50000 - Loss: 1.6979\n",
            "Epoch 3/4 - Batch 8800/50000 - Loss: 1.3099\n",
            "Epoch 3/4 - Batch 8850/50000 - Loss: 0.9755\n",
            "Epoch 3/4 - Batch 8900/50000 - Loss: 1.1427\n",
            "Epoch 3/4 - Batch 8950/50000 - Loss: 1.9080\n",
            "Epoch 3/4 - Batch 9000/50000 - Loss: 1.0615\n",
            "Epoch 3/4 - Batch 9050/50000 - Loss: 1.3053\n",
            "Epoch 3/4 - Batch 9100/50000 - Loss: 1.2890\n",
            "Epoch 3/4 - Batch 9150/50000 - Loss: 1.6332\n",
            "Epoch 3/4 - Batch 9200/50000 - Loss: 1.6279\n",
            "Epoch 3/4 - Batch 9250/50000 - Loss: 1.2729\n",
            "Epoch 3/4 - Batch 9300/50000 - Loss: 0.6228\n",
            "Epoch 3/4 - Batch 9350/50000 - Loss: 1.2870\n",
            "Epoch 3/4 - Batch 9400/50000 - Loss: 1.1732\n",
            "Epoch 3/4 - Batch 9450/50000 - Loss: 1.1463\n",
            "Epoch 3/4 - Batch 9500/50000 - Loss: 1.3296\n",
            "Epoch 3/4 - Batch 9550/50000 - Loss: 1.9791\n",
            "Epoch 3/4 - Batch 9600/50000 - Loss: 1.0690\n",
            "Epoch 3/4 - Batch 9650/50000 - Loss: 1.2921\n",
            "Epoch 3/4 - Batch 9700/50000 - Loss: 1.2944\n",
            "Epoch 3/4 - Batch 9750/50000 - Loss: 1.2543\n",
            "Epoch 3/4 - Batch 9800/50000 - Loss: 1.3438\n",
            "Epoch 3/4 - Batch 9850/50000 - Loss: 1.3511\n",
            "Epoch 3/4 - Batch 9900/50000 - Loss: 1.3756\n",
            "Epoch 3/4 - Batch 9950/50000 - Loss: 0.9998\n",
            "Epoch 3/4 - Batch 10000/50000 - Loss: 1.8106\n",
            "Epoch 3/4 - Batch 10050/50000 - Loss: 1.5856\n",
            "Epoch 3/4 - Batch 10100/50000 - Loss: 2.0154\n",
            "Epoch 3/4 - Batch 10150/50000 - Loss: 1.6774\n",
            "Epoch 3/4 - Batch 10200/50000 - Loss: 1.5448\n",
            "Epoch 3/4 - Batch 10250/50000 - Loss: 1.1997\n",
            "Epoch 3/4 - Batch 10300/50000 - Loss: 0.9791\n",
            "Epoch 3/4 - Batch 10350/50000 - Loss: 1.8563\n",
            "Epoch 3/4 - Batch 10400/50000 - Loss: 1.4915\n",
            "Epoch 3/4 - Batch 10450/50000 - Loss: 1.6725\n",
            "Epoch 3/4 - Batch 10500/50000 - Loss: 0.8043\n",
            "Epoch 3/4 - Batch 10550/50000 - Loss: 1.8110\n",
            "Epoch 3/4 - Batch 10600/50000 - Loss: 0.5915\n",
            "Epoch 3/4 - Batch 10650/50000 - Loss: 1.2532\n",
            "Epoch 3/4 - Batch 10700/50000 - Loss: 1.4469\n",
            "Epoch 3/4 - Batch 10750/50000 - Loss: 1.3344\n",
            "Epoch 3/4 - Batch 10800/50000 - Loss: 0.8363\n",
            "Epoch 3/4 - Batch 10850/50000 - Loss: 0.6715\n",
            "Epoch 3/4 - Batch 10900/50000 - Loss: 0.9371\n",
            "Epoch 3/4 - Batch 10950/50000 - Loss: 1.3277\n",
            "Epoch 3/4 - Batch 11000/50000 - Loss: 0.6822\n",
            "Epoch 3/4 - Batch 11050/50000 - Loss: 1.4524\n",
            "Epoch 3/4 - Batch 11100/50000 - Loss: 1.2746\n",
            "Epoch 3/4 - Batch 11150/50000 - Loss: 0.9687\n",
            "Epoch 3/4 - Batch 11200/50000 - Loss: 1.2608\n",
            "Epoch 3/4 - Batch 11250/50000 - Loss: 1.6776\n",
            "Epoch 3/4 - Batch 11300/50000 - Loss: 1.1259\n",
            "Epoch 3/4 - Batch 11350/50000 - Loss: 1.1397\n",
            "Epoch 3/4 - Batch 11400/50000 - Loss: 0.8804\n",
            "Epoch 3/4 - Batch 11450/50000 - Loss: 0.9418\n",
            "Epoch 3/4 - Batch 11500/50000 - Loss: 1.0775\n",
            "Epoch 3/4 - Batch 11550/50000 - Loss: 1.1230\n",
            "Epoch 3/4 - Batch 11600/50000 - Loss: 0.6029\n",
            "Epoch 3/4 - Batch 11650/50000 - Loss: 0.8620\n",
            "Epoch 3/4 - Batch 11700/50000 - Loss: 1.4484\n",
            "Epoch 3/4 - Batch 11750/50000 - Loss: 1.2681\n",
            "Epoch 3/4 - Batch 11800/50000 - Loss: 0.9046\n",
            "Epoch 3/4 - Batch 11850/50000 - Loss: 1.1401\n",
            "Epoch 3/4 - Batch 11900/50000 - Loss: 1.5495\n",
            "Epoch 3/4 - Batch 11950/50000 - Loss: 0.4308\n",
            "Epoch 3/4 - Batch 12000/50000 - Loss: 0.9722\n",
            "Epoch 3/4 - Batch 12050/50000 - Loss: 0.7312\n",
            "Epoch 3/4 - Batch 12100/50000 - Loss: 1.4769\n",
            "Epoch 3/4 - Batch 12150/50000 - Loss: 1.0693\n",
            "Epoch 3/4 - Batch 12200/50000 - Loss: 1.4869\n",
            "Epoch 3/4 - Batch 12250/50000 - Loss: 1.0091\n",
            "Epoch 3/4 - Batch 12300/50000 - Loss: 0.3644\n",
            "Epoch 3/4 - Batch 12350/50000 - Loss: 1.2485\n",
            "Epoch 3/4 - Batch 12400/50000 - Loss: 1.6145\n",
            "Epoch 3/4 - Batch 12450/50000 - Loss: 1.8921\n",
            "Epoch 3/4 - Batch 12500/50000 - Loss: 1.4761\n",
            "Epoch 3/4 - Batch 12550/50000 - Loss: 1.0089\n",
            "Epoch 3/4 - Batch 12600/50000 - Loss: 1.3622\n",
            "Epoch 3/4 - Batch 12650/50000 - Loss: 1.6966\n",
            "Epoch 3/4 - Batch 12700/50000 - Loss: 1.4393\n",
            "Epoch 3/4 - Batch 12750/50000 - Loss: 1.1941\n",
            "Epoch 3/4 - Batch 12800/50000 - Loss: 1.3524\n",
            "Epoch 3/4 - Batch 12850/50000 - Loss: 1.2251\n",
            "Epoch 3/4 - Batch 12900/50000 - Loss: 1.1385\n",
            "Epoch 3/4 - Batch 12950/50000 - Loss: 1.3946\n",
            "Epoch 3/4 - Batch 13000/50000 - Loss: 0.7029\n",
            "Epoch 3/4 - Batch 13050/50000 - Loss: 1.5063\n",
            "Epoch 3/4 - Batch 13100/50000 - Loss: 1.3846\n",
            "Epoch 3/4 - Batch 13150/50000 - Loss: 0.9530\n",
            "Epoch 3/4 - Batch 13200/50000 - Loss: 1.2061\n",
            "Epoch 3/4 - Batch 13250/50000 - Loss: 0.9516\n",
            "Epoch 3/4 - Batch 13300/50000 - Loss: 1.0586\n",
            "Epoch 3/4 - Batch 13350/50000 - Loss: 1.3110\n",
            "Epoch 3/4 - Batch 13400/50000 - Loss: 1.3907\n",
            "Epoch 3/4 - Batch 13450/50000 - Loss: 0.9365\n",
            "Epoch 3/4 - Batch 13500/50000 - Loss: 1.9160\n",
            "Epoch 3/4 - Batch 13550/50000 - Loss: 1.6065\n",
            "Epoch 3/4 - Batch 13600/50000 - Loss: 0.9584\n",
            "Epoch 3/4 - Batch 13650/50000 - Loss: 1.0579\n",
            "Epoch 3/4 - Batch 13700/50000 - Loss: 1.0094\n",
            "Epoch 3/4 - Batch 13750/50000 - Loss: 0.6857\n",
            "Epoch 3/4 - Batch 13800/50000 - Loss: 0.9873\n",
            "Epoch 3/4 - Batch 13850/50000 - Loss: 1.3612\n",
            "Epoch 3/4 - Batch 13900/50000 - Loss: 1.6418\n",
            "Epoch 3/4 - Batch 13950/50000 - Loss: 1.1790\n",
            "Epoch 3/4 - Batch 14000/50000 - Loss: 1.3982\n",
            "Epoch 3/4 - Batch 14050/50000 - Loss: 1.5230\n",
            "Epoch 3/4 - Batch 14100/50000 - Loss: 1.4158\n",
            "Epoch 3/4 - Batch 14150/50000 - Loss: 1.6558\n",
            "Epoch 3/4 - Batch 14200/50000 - Loss: 1.2679\n",
            "Epoch 3/4 - Batch 14250/50000 - Loss: 0.5202\n",
            "Epoch 3/4 - Batch 14300/50000 - Loss: 1.3152\n",
            "Epoch 3/4 - Batch 14350/50000 - Loss: 0.5148\n",
            "Epoch 3/4 - Batch 14400/50000 - Loss: 1.3622\n",
            "Epoch 3/4 - Batch 14450/50000 - Loss: 0.4491\n",
            "Epoch 3/4 - Batch 14500/50000 - Loss: 1.2691\n",
            "Epoch 3/4 - Batch 14550/50000 - Loss: 1.3030\n",
            "Epoch 3/4 - Batch 14600/50000 - Loss: 1.7161\n",
            "Epoch 3/4 - Batch 14650/50000 - Loss: 1.3904\n",
            "Epoch 3/4 - Batch 14700/50000 - Loss: 0.7861\n",
            "Epoch 3/4 - Batch 14750/50000 - Loss: 0.6837\n",
            "Epoch 3/4 - Batch 14800/50000 - Loss: 1.4382\n",
            "Epoch 3/4 - Batch 14850/50000 - Loss: 1.6587\n",
            "Epoch 3/4 - Batch 14900/50000 - Loss: 1.7415\n",
            "Epoch 3/4 - Batch 14950/50000 - Loss: 1.5738\n",
            "Epoch 3/4 - Batch 15000/50000 - Loss: 1.1517\n",
            "Epoch 3/4 - Batch 15050/50000 - Loss: 0.5703\n",
            "Epoch 3/4 - Batch 15100/50000 - Loss: 1.1205\n",
            "Epoch 3/4 - Batch 15150/50000 - Loss: 0.6819\n",
            "Epoch 3/4 - Batch 15200/50000 - Loss: 0.9242\n",
            "Epoch 3/4 - Batch 15250/50000 - Loss: 1.4717\n",
            "Epoch 3/4 - Batch 15300/50000 - Loss: 1.4303\n",
            "Epoch 3/4 - Batch 15350/50000 - Loss: 1.9771\n",
            "Epoch 3/4 - Batch 15400/50000 - Loss: 1.7001\n",
            "Epoch 3/4 - Batch 15450/50000 - Loss: 0.4146\n",
            "Epoch 3/4 - Batch 15500/50000 - Loss: 1.1801\n",
            "Epoch 3/4 - Batch 15550/50000 - Loss: 0.5398\n",
            "Epoch 3/4 - Batch 15600/50000 - Loss: 1.1982\n",
            "Epoch 3/4 - Batch 15650/50000 - Loss: 1.8508\n",
            "Epoch 3/4 - Batch 15700/50000 - Loss: 1.5022\n",
            "Epoch 3/4 - Batch 15750/50000 - Loss: 1.3806\n",
            "Epoch 3/4 - Batch 15800/50000 - Loss: 1.1538\n",
            "Epoch 3/4 - Batch 15850/50000 - Loss: 1.8758\n",
            "Epoch 3/4 - Batch 15900/50000 - Loss: 1.0248\n",
            "Epoch 3/4 - Batch 15950/50000 - Loss: 1.1764\n",
            "Epoch 3/4 - Batch 16000/50000 - Loss: 0.5957\n",
            "Epoch 3/4 - Batch 16050/50000 - Loss: 0.7245\n",
            "Epoch 3/4 - Batch 16100/50000 - Loss: 0.8270\n",
            "Epoch 3/4 - Batch 16150/50000 - Loss: 1.0724\n",
            "Epoch 3/4 - Batch 16200/50000 - Loss: 1.1730\n",
            "Epoch 3/4 - Batch 16250/50000 - Loss: 1.3325\n",
            "Epoch 3/4 - Batch 16300/50000 - Loss: 1.0126\n",
            "Epoch 3/4 - Batch 16350/50000 - Loss: 1.6122\n",
            "Epoch 3/4 - Batch 16400/50000 - Loss: 1.6217\n",
            "Epoch 3/4 - Batch 16450/50000 - Loss: 1.6093\n",
            "Epoch 3/4 - Batch 16500/50000 - Loss: 1.4349\n",
            "Epoch 3/4 - Batch 16550/50000 - Loss: 1.2787\n",
            "Epoch 3/4 - Batch 16600/50000 - Loss: 1.8252\n",
            "Epoch 3/4 - Batch 16650/50000 - Loss: 1.1818\n",
            "Epoch 3/4 - Batch 16700/50000 - Loss: 1.1363\n",
            "Epoch 3/4 - Batch 16750/50000 - Loss: 0.9394\n",
            "Epoch 3/4 - Batch 16800/50000 - Loss: 1.3308\n",
            "Epoch 3/4 - Batch 16850/50000 - Loss: 1.4504\n",
            "Epoch 3/4 - Batch 16900/50000 - Loss: 1.1572\n",
            "Epoch 3/4 - Batch 16950/50000 - Loss: 0.8474\n",
            "Epoch 3/4 - Batch 17000/50000 - Loss: 1.4000\n",
            "Epoch 3/4 - Batch 17050/50000 - Loss: 1.3436\n",
            "Epoch 3/4 - Batch 17100/50000 - Loss: 0.9616\n",
            "Epoch 3/4 - Batch 17150/50000 - Loss: 1.3576\n",
            "Epoch 3/4 - Batch 17200/50000 - Loss: 1.2193\n",
            "Epoch 3/4 - Batch 17250/50000 - Loss: 1.1076\n",
            "Epoch 3/4 - Batch 17300/50000 - Loss: 1.0561\n",
            "Epoch 3/4 - Batch 17350/50000 - Loss: 1.7569\n",
            "Epoch 3/4 - Batch 17400/50000 - Loss: 1.5798\n",
            "Epoch 3/4 - Batch 17450/50000 - Loss: 1.4606\n",
            "Epoch 3/4 - Batch 17500/50000 - Loss: 0.9931\n",
            "Epoch 3/4 - Batch 17550/50000 - Loss: 1.4422\n",
            "Epoch 3/4 - Batch 17600/50000 - Loss: 0.9028\n",
            "Epoch 3/4 - Batch 17650/50000 - Loss: 1.0665\n",
            "Epoch 3/4 - Batch 17700/50000 - Loss: 1.1088\n",
            "Epoch 3/4 - Batch 17750/50000 - Loss: 1.3227\n",
            "Epoch 3/4 - Batch 17800/50000 - Loss: 1.0413\n",
            "Epoch 3/4 - Batch 17850/50000 - Loss: 1.5037\n",
            "Epoch 3/4 - Batch 17900/50000 - Loss: 0.8861\n",
            "Epoch 3/4 - Batch 17950/50000 - Loss: 1.4389\n",
            "Epoch 3/4 - Batch 18000/50000 - Loss: 0.8506\n",
            "Epoch 3/4 - Batch 18050/50000 - Loss: 0.9442\n",
            "Epoch 3/4 - Batch 18100/50000 - Loss: 1.0018\n",
            "Epoch 3/4 - Batch 18150/50000 - Loss: 1.3401\n",
            "Epoch 3/4 - Batch 18200/50000 - Loss: 1.6506\n",
            "Epoch 3/4 - Batch 18250/50000 - Loss: 1.3364\n",
            "Epoch 3/4 - Batch 18300/50000 - Loss: 1.1526\n",
            "Epoch 3/4 - Batch 18350/50000 - Loss: 0.6924\n",
            "Epoch 3/4 - Batch 18400/50000 - Loss: 1.1057\n",
            "Epoch 3/4 - Batch 18450/50000 - Loss: 1.6199\n",
            "Epoch 3/4 - Batch 18500/50000 - Loss: 1.5718\n",
            "Epoch 3/4 - Batch 18550/50000 - Loss: 1.3980\n",
            "Epoch 3/4 - Batch 18600/50000 - Loss: 1.3388\n",
            "Epoch 3/4 - Batch 18650/50000 - Loss: 1.4540\n",
            "Epoch 3/4 - Batch 18700/50000 - Loss: 1.2188\n",
            "Epoch 3/4 - Batch 18750/50000 - Loss: 1.0648\n",
            "Epoch 3/4 - Batch 18800/50000 - Loss: 1.4437\n",
            "Epoch 3/4 - Batch 18850/50000 - Loss: 0.9933\n",
            "Epoch 3/4 - Batch 18900/50000 - Loss: 1.7446\n",
            "Epoch 3/4 - Batch 18950/50000 - Loss: 1.1037\n",
            "Epoch 3/4 - Batch 19000/50000 - Loss: 1.4284\n",
            "Epoch 3/4 - Batch 19050/50000 - Loss: 0.8235\n",
            "Epoch 3/4 - Batch 19100/50000 - Loss: 1.5574\n",
            "Epoch 3/4 - Batch 19150/50000 - Loss: 0.9292\n",
            "Epoch 3/4 - Batch 19200/50000 - Loss: 1.1893\n",
            "Epoch 3/4 - Batch 19250/50000 - Loss: 1.5494\n",
            "Epoch 3/4 - Batch 19300/50000 - Loss: 1.8637\n",
            "Epoch 3/4 - Batch 19350/50000 - Loss: 1.5013\n",
            "Epoch 3/4 - Batch 19400/50000 - Loss: 0.5888\n",
            "Epoch 3/4 - Batch 19450/50000 - Loss: 1.7017\n",
            "Epoch 3/4 - Batch 19500/50000 - Loss: 1.4643\n",
            "Epoch 3/4 - Batch 19550/50000 - Loss: 1.4635\n",
            "Epoch 3/4 - Batch 19600/50000 - Loss: 1.0943\n",
            "Epoch 3/4 - Batch 19650/50000 - Loss: 1.2268\n",
            "Epoch 3/4 - Batch 19700/50000 - Loss: 1.3139\n",
            "Epoch 3/4 - Batch 19750/50000 - Loss: 1.7815\n",
            "Epoch 3/4 - Batch 19800/50000 - Loss: 1.1337\n",
            "Epoch 3/4 - Batch 19850/50000 - Loss: 1.0449\n",
            "Epoch 3/4 - Batch 19900/50000 - Loss: 0.9786\n",
            "Epoch 3/4 - Batch 19950/50000 - Loss: 1.2905\n",
            "Epoch 3/4 - Batch 20000/50000 - Loss: 1.3299\n",
            "Epoch 3/4 - Batch 20050/50000 - Loss: 1.3989\n",
            "Epoch 3/4 - Batch 20100/50000 - Loss: 0.7076\n",
            "Epoch 3/4 - Batch 20150/50000 - Loss: 1.6440\n",
            "Epoch 3/4 - Batch 20200/50000 - Loss: 1.0879\n",
            "Epoch 3/4 - Batch 20250/50000 - Loss: 1.8228\n",
            "Epoch 3/4 - Batch 20300/50000 - Loss: 1.4609\n",
            "Epoch 3/4 - Batch 20350/50000 - Loss: 1.6939\n",
            "Epoch 3/4 - Batch 20400/50000 - Loss: 1.7818\n",
            "Epoch 3/4 - Batch 20450/50000 - Loss: 0.5864\n",
            "Epoch 3/4 - Batch 20500/50000 - Loss: 1.7480\n",
            "Epoch 3/4 - Batch 20550/50000 - Loss: 1.1942\n",
            "Epoch 3/4 - Batch 20600/50000 - Loss: 0.7333\n",
            "Epoch 3/4 - Batch 20650/50000 - Loss: 1.3101\n",
            "Epoch 3/4 - Batch 20700/50000 - Loss: 1.6838\n",
            "Epoch 3/4 - Batch 20750/50000 - Loss: 0.9549\n",
            "Epoch 3/4 - Batch 20800/50000 - Loss: 0.9217\n",
            "Epoch 3/4 - Batch 20850/50000 - Loss: 0.9783\n",
            "Epoch 3/4 - Batch 20900/50000 - Loss: 1.2143\n",
            "Epoch 3/4 - Batch 20950/50000 - Loss: 0.6998\n",
            "Epoch 3/4 - Batch 21000/50000 - Loss: 1.7118\n",
            "Epoch 3/4 - Batch 21050/50000 - Loss: 1.5300\n",
            "Epoch 3/4 - Batch 21100/50000 - Loss: 1.4392\n",
            "Epoch 3/4 - Batch 21150/50000 - Loss: 0.9288\n",
            "Epoch 3/4 - Batch 21200/50000 - Loss: 1.0537\n",
            "Epoch 3/4 - Batch 21250/50000 - Loss: 1.4007\n",
            "Epoch 3/4 - Batch 21300/50000 - Loss: 1.2495\n",
            "Epoch 3/4 - Batch 21350/50000 - Loss: 0.4742\n",
            "Epoch 3/4 - Batch 21400/50000 - Loss: 1.3931\n",
            "Epoch 3/4 - Batch 21450/50000 - Loss: 1.2730\n",
            "Epoch 3/4 - Batch 21500/50000 - Loss: 0.4194\n",
            "Epoch 3/4 - Batch 21550/50000 - Loss: 1.2922\n",
            "Epoch 3/4 - Batch 21600/50000 - Loss: 2.0001\n",
            "Epoch 3/4 - Batch 21650/50000 - Loss: 1.3069\n",
            "Epoch 3/4 - Batch 21700/50000 - Loss: 1.3753\n",
            "Epoch 3/4 - Batch 21750/50000 - Loss: 1.6653\n",
            "Epoch 3/4 - Batch 21800/50000 - Loss: 1.1805\n",
            "Epoch 3/4 - Batch 21850/50000 - Loss: 1.2605\n",
            "Epoch 3/4 - Batch 21900/50000 - Loss: 0.9173\n",
            "Epoch 3/4 - Batch 21950/50000 - Loss: 1.1065\n",
            "Epoch 3/4 - Batch 22000/50000 - Loss: 1.7572\n",
            "Epoch 3/4 - Batch 22050/50000 - Loss: 1.5876\n",
            "Epoch 3/4 - Batch 22100/50000 - Loss: 1.3726\n",
            "Epoch 3/4 - Batch 22150/50000 - Loss: 1.5700\n",
            "Epoch 3/4 - Batch 22200/50000 - Loss: 0.9481\n",
            "Epoch 3/4 - Batch 22250/50000 - Loss: 1.8066\n",
            "Epoch 3/4 - Batch 22300/50000 - Loss: 1.5608\n",
            "Epoch 3/4 - Batch 22350/50000 - Loss: 1.8656\n",
            "Epoch 3/4 - Batch 22400/50000 - Loss: 1.6039\n",
            "Epoch 3/4 - Batch 22450/50000 - Loss: 1.2207\n",
            "Epoch 3/4 - Batch 22500/50000 - Loss: 1.3350\n",
            "Epoch 3/4 - Batch 22550/50000 - Loss: 1.1935\n",
            "Epoch 3/4 - Batch 22600/50000 - Loss: 1.0784\n",
            "Epoch 3/4 - Batch 22650/50000 - Loss: 1.2647\n",
            "Epoch 3/4 - Batch 22700/50000 - Loss: 1.6118\n",
            "Epoch 3/4 - Batch 22750/50000 - Loss: 0.8995\n",
            "Epoch 3/4 - Batch 22800/50000 - Loss: 0.6665\n",
            "Epoch 3/4 - Batch 22850/50000 - Loss: 1.5065\n",
            "Epoch 3/4 - Batch 22900/50000 - Loss: 1.1293\n",
            "Epoch 3/4 - Batch 22950/50000 - Loss: 0.9199\n",
            "Epoch 3/4 - Batch 23000/50000 - Loss: 1.0000\n",
            "Epoch 3/4 - Batch 23050/50000 - Loss: 1.1695\n",
            "Epoch 3/4 - Batch 23100/50000 - Loss: 1.3777\n",
            "Epoch 3/4 - Batch 23150/50000 - Loss: 1.8828\n",
            "Epoch 3/4 - Batch 23200/50000 - Loss: 1.1488\n",
            "Epoch 3/4 - Batch 23250/50000 - Loss: 1.6407\n",
            "Epoch 3/4 - Batch 23300/50000 - Loss: 1.2017\n",
            "Epoch 3/4 - Batch 23350/50000 - Loss: 1.1433\n",
            "Epoch 3/4 - Batch 23400/50000 - Loss: 1.7636\n",
            "Epoch 3/4 - Batch 23450/50000 - Loss: 1.0485\n",
            "Epoch 3/4 - Batch 23500/50000 - Loss: 1.0425\n",
            "Epoch 3/4 - Batch 23550/50000 - Loss: 1.4541\n",
            "Epoch 3/4 - Batch 23600/50000 - Loss: 1.1846\n",
            "Epoch 3/4 - Batch 23650/50000 - Loss: 1.4300\n",
            "Epoch 3/4 - Batch 23700/50000 - Loss: 0.9330\n",
            "Epoch 3/4 - Batch 23750/50000 - Loss: 0.7911\n",
            "Epoch 3/4 - Batch 23800/50000 - Loss: 1.3671\n",
            "Epoch 3/4 - Batch 23850/50000 - Loss: 1.1329\n",
            "Epoch 3/4 - Batch 23900/50000 - Loss: 1.0732\n",
            "Epoch 3/4 - Batch 23950/50000 - Loss: 1.3652\n",
            "Epoch 3/4 - Batch 24000/50000 - Loss: 1.5764\n",
            "Epoch 3/4 - Batch 24050/50000 - Loss: 0.7155\n",
            "Epoch 3/4 - Batch 24100/50000 - Loss: 1.3364\n",
            "Epoch 3/4 - Batch 24150/50000 - Loss: 0.9083\n",
            "Epoch 3/4 - Batch 24200/50000 - Loss: 2.0220\n",
            "Epoch 3/4 - Batch 24250/50000 - Loss: 1.6554\n",
            "Epoch 3/4 - Batch 24300/50000 - Loss: 0.6368\n",
            "Epoch 3/4 - Batch 24350/50000 - Loss: 0.6906\n",
            "Epoch 3/4 - Batch 24400/50000 - Loss: 1.4511\n",
            "Epoch 3/4 - Batch 24450/50000 - Loss: 1.2785\n",
            "Epoch 3/4 - Batch 24500/50000 - Loss: 1.5267\n",
            "Epoch 3/4 - Batch 24550/50000 - Loss: 1.1732\n",
            "Epoch 3/4 - Batch 24600/50000 - Loss: 1.7112\n",
            "Epoch 3/4 - Batch 24650/50000 - Loss: 1.1848\n",
            "Epoch 3/4 - Batch 24700/50000 - Loss: 1.6715\n",
            "Epoch 3/4 - Batch 24750/50000 - Loss: 1.4640\n",
            "Epoch 3/4 - Batch 24800/50000 - Loss: 1.8143\n",
            "Epoch 3/4 - Batch 24850/50000 - Loss: 1.1290\n",
            "Epoch 3/4 - Batch 24900/50000 - Loss: 0.6457\n",
            "Epoch 3/4 - Batch 24950/50000 - Loss: 1.2348\n",
            "Epoch 3/4 - Batch 25000/50000 - Loss: 1.6211\n",
            "Epoch 3/4 - Batch 25050/50000 - Loss: 1.5349\n",
            "Epoch 3/4 - Batch 25100/50000 - Loss: 1.4987\n",
            "Epoch 3/4 - Batch 25150/50000 - Loss: 1.2419\n",
            "Epoch 3/4 - Batch 25200/50000 - Loss: 1.6362\n",
            "Epoch 3/4 - Batch 25250/50000 - Loss: 1.3351\n",
            "Epoch 3/4 - Batch 25300/50000 - Loss: 0.7087\n",
            "Epoch 3/4 - Batch 25350/50000 - Loss: 1.4322\n",
            "Epoch 3/4 - Batch 25400/50000 - Loss: 0.7005\n",
            "Epoch 3/4 - Batch 25450/50000 - Loss: 1.0726\n",
            "Epoch 3/4 - Batch 25500/50000 - Loss: 1.5182\n",
            "Epoch 3/4 - Batch 25550/50000 - Loss: 1.2613\n",
            "Epoch 3/4 - Batch 25600/50000 - Loss: 1.2801\n",
            "Epoch 3/4 - Batch 25650/50000 - Loss: 1.2113\n",
            "Epoch 3/4 - Batch 25700/50000 - Loss: 1.0340\n",
            "Epoch 3/4 - Batch 25750/50000 - Loss: 1.1253\n",
            "Epoch 3/4 - Batch 25800/50000 - Loss: 1.1944\n",
            "Epoch 3/4 - Batch 25850/50000 - Loss: 0.5653\n",
            "Epoch 3/4 - Batch 25900/50000 - Loss: 1.7459\n",
            "Epoch 3/4 - Batch 25950/50000 - Loss: 1.2531\n",
            "Epoch 3/4 - Batch 26000/50000 - Loss: 0.9977\n",
            "Epoch 3/4 - Batch 26050/50000 - Loss: 1.4339\n",
            "Epoch 3/4 - Batch 26100/50000 - Loss: 1.5771\n",
            "Epoch 3/4 - Batch 26150/50000 - Loss: 1.2161\n",
            "Epoch 3/4 - Batch 26200/50000 - Loss: 0.5849\n",
            "Epoch 3/4 - Batch 26250/50000 - Loss: 1.7239\n",
            "Epoch 3/4 - Batch 26300/50000 - Loss: 1.2819\n",
            "Epoch 3/4 - Batch 26350/50000 - Loss: 1.0796\n",
            "Epoch 3/4 - Batch 26400/50000 - Loss: 1.3772\n",
            "Epoch 3/4 - Batch 26450/50000 - Loss: 0.9074\n",
            "Epoch 3/4 - Batch 26500/50000 - Loss: 1.8727\n",
            "Epoch 3/4 - Batch 26550/50000 - Loss: 1.0232\n",
            "Epoch 3/4 - Batch 26600/50000 - Loss: 1.1891\n",
            "Epoch 3/4 - Batch 26650/50000 - Loss: 1.2156\n",
            "Epoch 3/4 - Batch 26700/50000 - Loss: 1.4620\n",
            "Epoch 3/4 - Batch 26750/50000 - Loss: 1.4065\n",
            "Epoch 3/4 - Batch 26800/50000 - Loss: 1.2721\n",
            "Epoch 3/4 - Batch 26850/50000 - Loss: 1.2383\n",
            "Epoch 3/4 - Batch 26900/50000 - Loss: 1.8876\n",
            "Epoch 3/4 - Batch 26950/50000 - Loss: 0.8234\n",
            "Epoch 3/4 - Batch 27000/50000 - Loss: 1.2681\n",
            "Epoch 3/4 - Batch 27050/50000 - Loss: 0.4122\n",
            "Epoch 3/4 - Batch 27100/50000 - Loss: 1.5289\n",
            "Epoch 3/4 - Batch 27150/50000 - Loss: 1.4591\n",
            "Epoch 3/4 - Batch 27200/50000 - Loss: 0.7749\n",
            "Epoch 3/4 - Batch 27250/50000 - Loss: 1.5781\n",
            "Epoch 3/4 - Batch 27300/50000 - Loss: 0.8961\n",
            "Epoch 3/4 - Batch 27350/50000 - Loss: 1.1481\n",
            "Epoch 3/4 - Batch 27400/50000 - Loss: 1.1500\n",
            "Epoch 3/4 - Batch 27450/50000 - Loss: 1.7799\n",
            "Epoch 3/4 - Batch 27500/50000 - Loss: 1.5049\n",
            "Epoch 3/4 - Batch 27550/50000 - Loss: 0.9657\n",
            "Epoch 3/4 - Batch 27600/50000 - Loss: 1.5850\n",
            "Epoch 3/4 - Batch 27650/50000 - Loss: 0.8366\n",
            "Epoch 3/4 - Batch 27700/50000 - Loss: 1.1866\n",
            "Epoch 3/4 - Batch 27750/50000 - Loss: 1.3107\n",
            "Epoch 3/4 - Batch 27800/50000 - Loss: 1.7194\n",
            "Epoch 3/4 - Batch 27850/50000 - Loss: 1.0378\n",
            "Epoch 3/4 - Batch 27900/50000 - Loss: 1.7718\n",
            "Epoch 3/4 - Batch 27950/50000 - Loss: 1.3744\n",
            "Epoch 3/4 - Batch 28000/50000 - Loss: 1.5011\n",
            "Epoch 3/4 - Batch 28050/50000 - Loss: 1.0362\n",
            "Epoch 3/4 - Batch 28100/50000 - Loss: 0.9156\n",
            "Epoch 3/4 - Batch 28150/50000 - Loss: 1.6716\n",
            "Epoch 3/4 - Batch 28200/50000 - Loss: 0.8017\n",
            "Epoch 3/4 - Batch 28250/50000 - Loss: 0.9909\n",
            "Epoch 3/4 - Batch 28300/50000 - Loss: 0.8713\n",
            "Epoch 3/4 - Batch 28350/50000 - Loss: 1.3495\n",
            "Epoch 3/4 - Batch 28400/50000 - Loss: 1.9702\n",
            "Epoch 3/4 - Batch 28450/50000 - Loss: 1.4425\n",
            "Epoch 3/4 - Batch 28500/50000 - Loss: 1.4878\n",
            "Epoch 3/4 - Batch 28550/50000 - Loss: 1.2276\n",
            "Epoch 3/4 - Batch 28600/50000 - Loss: 1.4660\n",
            "Epoch 3/4 - Batch 28650/50000 - Loss: 1.1681\n",
            "Epoch 3/4 - Batch 28700/50000 - Loss: 1.0877\n",
            "Epoch 3/4 - Batch 28750/50000 - Loss: 1.3057\n",
            "Epoch 3/4 - Batch 28800/50000 - Loss: 1.3136\n",
            "Epoch 3/4 - Batch 28850/50000 - Loss: 1.5108\n",
            "Epoch 3/4 - Batch 28900/50000 - Loss: 1.7698\n",
            "Epoch 3/4 - Batch 28950/50000 - Loss: 1.3969\n",
            "Epoch 3/4 - Batch 29000/50000 - Loss: 0.6142\n",
            "Epoch 3/4 - Batch 29050/50000 - Loss: 2.0875\n",
            "Epoch 3/4 - Batch 29100/50000 - Loss: 1.4544\n",
            "Epoch 3/4 - Batch 29150/50000 - Loss: 1.5621\n",
            "Epoch 3/4 - Batch 29200/50000 - Loss: 1.2094\n",
            "Epoch 3/4 - Batch 29250/50000 - Loss: 1.1715\n",
            "Epoch 3/4 - Batch 29300/50000 - Loss: 1.3436\n",
            "Epoch 3/4 - Batch 29350/50000 - Loss: 1.0017\n",
            "Epoch 3/4 - Batch 29400/50000 - Loss: 1.2420\n",
            "Epoch 3/4 - Batch 29450/50000 - Loss: 1.0689\n",
            "Epoch 3/4 - Batch 29500/50000 - Loss: 1.2356\n",
            "Epoch 3/4 - Batch 29550/50000 - Loss: 1.2693\n",
            "Epoch 3/4 - Batch 29600/50000 - Loss: 1.1479\n",
            "Epoch 3/4 - Batch 29650/50000 - Loss: 1.6759\n",
            "Epoch 3/4 - Batch 29700/50000 - Loss: 1.6322\n",
            "Epoch 3/4 - Batch 29750/50000 - Loss: 0.6972\n",
            "Epoch 3/4 - Batch 29800/50000 - Loss: 1.3226\n",
            "Epoch 3/4 - Batch 29850/50000 - Loss: 1.2804\n",
            "Epoch 3/4 - Batch 29900/50000 - Loss: 0.5995\n",
            "Epoch 3/4 - Batch 29950/50000 - Loss: 1.3290\n",
            "Epoch 3/4 - Batch 30000/50000 - Loss: 0.5433\n",
            "Epoch 3/4 - Batch 30050/50000 - Loss: 1.4755\n",
            "Epoch 3/4 - Batch 30100/50000 - Loss: 1.5840\n",
            "Epoch 3/4 - Batch 30150/50000 - Loss: 1.4070\n",
            "Epoch 3/4 - Batch 30200/50000 - Loss: 1.6714\n",
            "Epoch 3/4 - Batch 30250/50000 - Loss: 1.4608\n",
            "Epoch 3/4 - Batch 30300/50000 - Loss: 1.3934\n",
            "Epoch 3/4 - Batch 30350/50000 - Loss: 1.9451\n",
            "Epoch 3/4 - Batch 30400/50000 - Loss: 1.4373\n",
            "Epoch 3/4 - Batch 30450/50000 - Loss: 1.1311\n",
            "Epoch 3/4 - Batch 30500/50000 - Loss: 1.8407\n",
            "Epoch 3/4 - Batch 30550/50000 - Loss: 1.9749\n",
            "Epoch 3/4 - Batch 30600/50000 - Loss: 0.8178\n",
            "Epoch 3/4 - Batch 30650/50000 - Loss: 1.0877\n",
            "Epoch 3/4 - Batch 30700/50000 - Loss: 1.4265\n",
            "Epoch 3/4 - Batch 30750/50000 - Loss: 1.8536\n",
            "Epoch 3/4 - Batch 30800/50000 - Loss: 0.7322\n",
            "Epoch 3/4 - Batch 30850/50000 - Loss: 1.0200\n",
            "Epoch 3/4 - Batch 30900/50000 - Loss: 1.5254\n",
            "Epoch 3/4 - Batch 30950/50000 - Loss: 1.3985\n",
            "Epoch 3/4 - Batch 31000/50000 - Loss: 1.4963\n",
            "Epoch 3/4 - Batch 31050/50000 - Loss: 1.7093\n",
            "Epoch 3/4 - Batch 31100/50000 - Loss: 1.6311\n",
            "Epoch 3/4 - Batch 31150/50000 - Loss: 1.7238\n",
            "Epoch 3/4 - Batch 31200/50000 - Loss: 1.1647\n",
            "Epoch 3/4 - Batch 31250/50000 - Loss: 1.9975\n",
            "Epoch 3/4 - Batch 31300/50000 - Loss: 0.8821\n",
            "Epoch 3/4 - Batch 31350/50000 - Loss: 1.6267\n",
            "Epoch 3/4 - Batch 31400/50000 - Loss: 1.3579\n",
            "Epoch 3/4 - Batch 31450/50000 - Loss: 1.4884\n",
            "Epoch 3/4 - Batch 31500/50000 - Loss: 0.8485\n",
            "Epoch 3/4 - Batch 31550/50000 - Loss: 1.3241\n",
            "Epoch 3/4 - Batch 31600/50000 - Loss: 1.6655\n",
            "Epoch 3/4 - Batch 31650/50000 - Loss: 0.9145\n",
            "Epoch 3/4 - Batch 31700/50000 - Loss: 1.9575\n",
            "Epoch 3/4 - Batch 31750/50000 - Loss: 1.1752\n",
            "Epoch 3/4 - Batch 31800/50000 - Loss: 1.0545\n",
            "Epoch 3/4 - Batch 31850/50000 - Loss: 1.3495\n",
            "Epoch 3/4 - Batch 31900/50000 - Loss: 1.6413\n",
            "Epoch 3/4 - Batch 31950/50000 - Loss: 1.1073\n",
            "Epoch 3/4 - Batch 32000/50000 - Loss: 0.6268\n",
            "Epoch 3/4 - Batch 32050/50000 - Loss: 1.0912\n",
            "Epoch 3/4 - Batch 32100/50000 - Loss: 1.6043\n",
            "Epoch 3/4 - Batch 32150/50000 - Loss: 1.2598\n",
            "Epoch 3/4 - Batch 32200/50000 - Loss: 1.1008\n",
            "Epoch 3/4 - Batch 32250/50000 - Loss: 0.6892\n",
            "Epoch 3/4 - Batch 32300/50000 - Loss: 1.7967\n",
            "Epoch 3/4 - Batch 32350/50000 - Loss: 1.4153\n",
            "Epoch 3/4 - Batch 32400/50000 - Loss: 1.5991\n",
            "Epoch 3/4 - Batch 32450/50000 - Loss: 1.5795\n",
            "Epoch 3/4 - Batch 32500/50000 - Loss: 1.3740\n",
            "Epoch 3/4 - Batch 32550/50000 - Loss: 1.3916\n",
            "Epoch 3/4 - Batch 32600/50000 - Loss: 0.7133\n",
            "Epoch 3/4 - Batch 32650/50000 - Loss: 1.5594\n",
            "Epoch 3/4 - Batch 32700/50000 - Loss: 1.0560\n",
            "Epoch 3/4 - Batch 32750/50000 - Loss: 1.2761\n",
            "Epoch 3/4 - Batch 32800/50000 - Loss: 1.2359\n",
            "Epoch 3/4 - Batch 32850/50000 - Loss: 1.1775\n",
            "Epoch 3/4 - Batch 32900/50000 - Loss: 1.7318\n",
            "Epoch 3/4 - Batch 32950/50000 - Loss: 1.1864\n",
            "Epoch 3/4 - Batch 33000/50000 - Loss: 1.0495\n",
            "Epoch 3/4 - Batch 33050/50000 - Loss: 0.7644\n",
            "Epoch 3/4 - Batch 33100/50000 - Loss: 1.1666\n",
            "Epoch 3/4 - Batch 33150/50000 - Loss: 1.4367\n",
            "Epoch 3/4 - Batch 33200/50000 - Loss: 0.9173\n",
            "Epoch 3/4 - Batch 33250/50000 - Loss: 1.0045\n",
            "Epoch 3/4 - Batch 33300/50000 - Loss: 1.0217\n",
            "Epoch 3/4 - Batch 33350/50000 - Loss: 1.2703\n",
            "Epoch 3/4 - Batch 33400/50000 - Loss: 2.2810\n",
            "Epoch 3/4 - Batch 33450/50000 - Loss: 1.0205\n",
            "Epoch 3/4 - Batch 33500/50000 - Loss: 1.1552\n",
            "Epoch 3/4 - Batch 33550/50000 - Loss: 1.0634\n",
            "Epoch 3/4 - Batch 33600/50000 - Loss: 0.6368\n",
            "Epoch 3/4 - Batch 33650/50000 - Loss: 0.9689\n",
            "Epoch 3/4 - Batch 33700/50000 - Loss: 1.2042\n",
            "Epoch 3/4 - Batch 33750/50000 - Loss: 1.8411\n",
            "Epoch 3/4 - Batch 33800/50000 - Loss: 1.5684\n",
            "Epoch 3/4 - Batch 33850/50000 - Loss: 1.6232\n",
            "Epoch 3/4 - Batch 33900/50000 - Loss: 0.4751\n",
            "Epoch 3/4 - Batch 33950/50000 - Loss: 0.9672\n",
            "Epoch 3/4 - Batch 34000/50000 - Loss: 1.7607\n",
            "Epoch 3/4 - Batch 34050/50000 - Loss: 0.9862\n",
            "Epoch 3/4 - Batch 34100/50000 - Loss: 1.5496\n",
            "Epoch 3/4 - Batch 34150/50000 - Loss: 1.4797\n",
            "Epoch 3/4 - Batch 34200/50000 - Loss: 0.8510\n",
            "Epoch 3/4 - Batch 34250/50000 - Loss: 1.7086\n",
            "Epoch 3/4 - Batch 34300/50000 - Loss: 0.8998\n",
            "Epoch 3/4 - Batch 34350/50000 - Loss: 1.2494\n",
            "Epoch 3/4 - Batch 34400/50000 - Loss: 1.5120\n",
            "Epoch 3/4 - Batch 34450/50000 - Loss: 1.2093\n",
            "Epoch 3/4 - Batch 34500/50000 - Loss: 2.0575\n",
            "Epoch 3/4 - Batch 34550/50000 - Loss: 1.6153\n",
            "Epoch 3/4 - Batch 34600/50000 - Loss: 1.0973\n",
            "Epoch 3/4 - Batch 34650/50000 - Loss: 0.9982\n",
            "Epoch 3/4 - Batch 34700/50000 - Loss: 0.8979\n",
            "Epoch 3/4 - Batch 34750/50000 - Loss: 1.3926\n",
            "Epoch 3/4 - Batch 34800/50000 - Loss: 1.2415\n",
            "Epoch 3/4 - Batch 34850/50000 - Loss: 1.1877\n",
            "Epoch 3/4 - Batch 34900/50000 - Loss: 1.1296\n",
            "Epoch 3/4 - Batch 34950/50000 - Loss: 1.5020\n",
            "Epoch 3/4 - Batch 35000/50000 - Loss: 1.4228\n",
            "Epoch 3/4 - Batch 35050/50000 - Loss: 0.9695\n",
            "Epoch 3/4 - Batch 35100/50000 - Loss: 0.8302\n",
            "Epoch 3/4 - Batch 35150/50000 - Loss: 1.3383\n",
            "Epoch 3/4 - Batch 35200/50000 - Loss: 1.5294\n",
            "Epoch 3/4 - Batch 35250/50000 - Loss: 1.1252\n",
            "Epoch 3/4 - Batch 35300/50000 - Loss: 0.9319\n",
            "Epoch 3/4 - Batch 35350/50000 - Loss: 1.6871\n",
            "Epoch 3/4 - Batch 35400/50000 - Loss: 1.2988\n",
            "Epoch 3/4 - Batch 35450/50000 - Loss: 0.6341\n",
            "Epoch 3/4 - Batch 35500/50000 - Loss: 1.1490\n",
            "Epoch 3/4 - Batch 35550/50000 - Loss: 1.7310\n",
            "Epoch 3/4 - Batch 35600/50000 - Loss: 1.9436\n",
            "Epoch 3/4 - Batch 35650/50000 - Loss: 1.0557\n",
            "Epoch 3/4 - Batch 35700/50000 - Loss: 1.0030\n",
            "Epoch 3/4 - Batch 35750/50000 - Loss: 1.1619\n",
            "Epoch 3/4 - Batch 35800/50000 - Loss: 1.5702\n",
            "Epoch 3/4 - Batch 35850/50000 - Loss: 1.2522\n",
            "Epoch 3/4 - Batch 35900/50000 - Loss: 1.4670\n",
            "Epoch 3/4 - Batch 35950/50000 - Loss: 1.3671\n",
            "Epoch 3/4 - Batch 36000/50000 - Loss: 0.8061\n",
            "Epoch 3/4 - Batch 36050/50000 - Loss: 1.2695\n",
            "Epoch 3/4 - Batch 36100/50000 - Loss: 1.0452\n",
            "Epoch 3/4 - Batch 36150/50000 - Loss: 1.4141\n",
            "Epoch 3/4 - Batch 36200/50000 - Loss: 1.4626\n",
            "Epoch 3/4 - Batch 36250/50000 - Loss: 0.8906\n",
            "Epoch 3/4 - Batch 36300/50000 - Loss: 1.7688\n",
            "Epoch 3/4 - Batch 36350/50000 - Loss: 1.2285\n",
            "Epoch 3/4 - Batch 36400/50000 - Loss: 2.1213\n",
            "Epoch 3/4 - Batch 36450/50000 - Loss: 1.4557\n",
            "Epoch 3/4 - Batch 36500/50000 - Loss: 0.8021\n",
            "Epoch 3/4 - Batch 36550/50000 - Loss: 1.7848\n",
            "Epoch 3/4 - Batch 36600/50000 - Loss: 1.3454\n",
            "Epoch 3/4 - Batch 36650/50000 - Loss: 1.0768\n",
            "Epoch 3/4 - Batch 36700/50000 - Loss: 1.3933\n",
            "Epoch 3/4 - Batch 36750/50000 - Loss: 1.1642\n",
            "Epoch 3/4 - Batch 36800/50000 - Loss: 1.1046\n",
            "Epoch 3/4 - Batch 36850/50000 - Loss: 1.2502\n",
            "Epoch 3/4 - Batch 36900/50000 - Loss: 0.6219\n",
            "Epoch 3/4 - Batch 36950/50000 - Loss: 1.8014\n",
            "Epoch 3/4 - Batch 37000/50000 - Loss: 1.4117\n",
            "Epoch 3/4 - Batch 37050/50000 - Loss: 1.6890\n",
            "Epoch 3/4 - Batch 37100/50000 - Loss: 1.4233\n",
            "Epoch 3/4 - Batch 37150/50000 - Loss: 1.9970\n",
            "Epoch 3/4 - Batch 37200/50000 - Loss: 2.0458\n",
            "Epoch 3/4 - Batch 37250/50000 - Loss: 1.1374\n",
            "Epoch 3/4 - Batch 37300/50000 - Loss: 1.3648\n",
            "Epoch 3/4 - Batch 37350/50000 - Loss: 1.8097\n",
            "Epoch 3/4 - Batch 37400/50000 - Loss: 1.6571\n",
            "Epoch 3/4 - Batch 37450/50000 - Loss: 1.4958\n",
            "Epoch 3/4 - Batch 37500/50000 - Loss: 1.0679\n",
            "Epoch 3/4 - Batch 37550/50000 - Loss: 1.4265\n",
            "Epoch 3/4 - Batch 37600/50000 - Loss: 1.2717\n",
            "Epoch 3/4 - Batch 37650/50000 - Loss: 0.8257\n",
            "Epoch 3/4 - Batch 37700/50000 - Loss: 0.6285\n",
            "Epoch 3/4 - Batch 37750/50000 - Loss: 0.5805\n",
            "Epoch 3/4 - Batch 37800/50000 - Loss: 0.7383\n",
            "Epoch 3/4 - Batch 37850/50000 - Loss: 1.6190\n",
            "Epoch 3/4 - Batch 37900/50000 - Loss: 1.4351\n",
            "Epoch 3/4 - Batch 37950/50000 - Loss: 2.1312\n",
            "Epoch 3/4 - Batch 38000/50000 - Loss: 1.8958\n",
            "Epoch 3/4 - Batch 38050/50000 - Loss: 0.8024\n",
            "Epoch 3/4 - Batch 38100/50000 - Loss: 1.6378\n",
            "Epoch 3/4 - Batch 38150/50000 - Loss: 0.7209\n",
            "Epoch 3/4 - Batch 38200/50000 - Loss: 1.1603\n",
            "Epoch 3/4 - Batch 38250/50000 - Loss: 0.8866\n",
            "Epoch 3/4 - Batch 38300/50000 - Loss: 1.2590\n",
            "Epoch 3/4 - Batch 38350/50000 - Loss: 1.1857\n",
            "Epoch 3/4 - Batch 38400/50000 - Loss: 1.7998\n",
            "Epoch 3/4 - Batch 38450/50000 - Loss: 1.1742\n",
            "Epoch 3/4 - Batch 38500/50000 - Loss: 1.0448\n",
            "Epoch 3/4 - Batch 38550/50000 - Loss: 1.7366\n",
            "Epoch 3/4 - Batch 38600/50000 - Loss: 1.7747\n",
            "Epoch 3/4 - Batch 38650/50000 - Loss: 1.1896\n",
            "Epoch 3/4 - Batch 38700/50000 - Loss: 1.8264\n",
            "Epoch 3/4 - Batch 38750/50000 - Loss: 0.8033\n",
            "Epoch 3/4 - Batch 38800/50000 - Loss: 0.8466\n",
            "Epoch 3/4 - Batch 38850/50000 - Loss: 1.9016\n",
            "Epoch 3/4 - Batch 38900/50000 - Loss: 1.4933\n",
            "Epoch 3/4 - Batch 38950/50000 - Loss: 1.6249\n",
            "Epoch 3/4 - Batch 39000/50000 - Loss: 1.6183\n",
            "Epoch 3/4 - Batch 39050/50000 - Loss: 1.4737\n",
            "Epoch 3/4 - Batch 39100/50000 - Loss: 1.0043\n",
            "Epoch 3/4 - Batch 39150/50000 - Loss: 1.3074\n",
            "Epoch 3/4 - Batch 39200/50000 - Loss: 1.1459\n",
            "Epoch 3/4 - Batch 39250/50000 - Loss: 1.6927\n",
            "Epoch 3/4 - Batch 39300/50000 - Loss: 1.6134\n",
            "Epoch 3/4 - Batch 39350/50000 - Loss: 1.0148\n",
            "Epoch 3/4 - Batch 39400/50000 - Loss: 1.2583\n",
            "Epoch 3/4 - Batch 39450/50000 - Loss: 1.7539\n",
            "Epoch 3/4 - Batch 39500/50000 - Loss: 0.7407\n",
            "Epoch 3/4 - Batch 39550/50000 - Loss: 0.8214\n",
            "Epoch 3/4 - Batch 39600/50000 - Loss: 1.5043\n",
            "Epoch 3/4 - Batch 39650/50000 - Loss: 1.1138\n",
            "Epoch 3/4 - Batch 39700/50000 - Loss: 0.8179\n",
            "Epoch 3/4 - Batch 39750/50000 - Loss: 1.7666\n",
            "Epoch 3/4 - Batch 39800/50000 - Loss: 0.7569\n",
            "Epoch 3/4 - Batch 39850/50000 - Loss: 1.4818\n",
            "Epoch 3/4 - Batch 39900/50000 - Loss: 0.7701\n",
            "Epoch 3/4 - Batch 39950/50000 - Loss: 1.4133\n",
            "Epoch 3/4 - Batch 40000/50000 - Loss: 1.1544\n",
            "Epoch 3/4 - Batch 40050/50000 - Loss: 1.1672\n",
            "Epoch 3/4 - Batch 40100/50000 - Loss: 1.2751\n",
            "Epoch 3/4 - Batch 40150/50000 - Loss: 1.0091\n",
            "Epoch 3/4 - Batch 40200/50000 - Loss: 1.7130\n",
            "Epoch 3/4 - Batch 40250/50000 - Loss: 1.3817\n",
            "Epoch 3/4 - Batch 40300/50000 - Loss: 1.4234\n",
            "Epoch 3/4 - Batch 40350/50000 - Loss: 0.5871\n",
            "Epoch 3/4 - Batch 40400/50000 - Loss: 1.4990\n",
            "Epoch 3/4 - Batch 40450/50000 - Loss: 1.1797\n",
            "Epoch 3/4 - Batch 40500/50000 - Loss: 1.5969\n",
            "Epoch 3/4 - Batch 40550/50000 - Loss: 1.3841\n",
            "Epoch 3/4 - Batch 40600/50000 - Loss: 0.8397\n",
            "Epoch 3/4 - Batch 40650/50000 - Loss: 1.5405\n",
            "Epoch 3/4 - Batch 40700/50000 - Loss: 1.4041\n",
            "Epoch 3/4 - Batch 40750/50000 - Loss: 1.0076\n",
            "Epoch 3/4 - Batch 40800/50000 - Loss: 1.6886\n",
            "Epoch 3/4 - Batch 40850/50000 - Loss: 1.1738\n",
            "Epoch 3/4 - Batch 40900/50000 - Loss: 0.9241\n",
            "Epoch 3/4 - Batch 40950/50000 - Loss: 1.6548\n",
            "Epoch 3/4 - Batch 41000/50000 - Loss: 1.6057\n",
            "Epoch 3/4 - Batch 41050/50000 - Loss: 0.9477\n",
            "Epoch 3/4 - Batch 41100/50000 - Loss: 1.4071\n",
            "Epoch 3/4 - Batch 41150/50000 - Loss: 0.6369\n",
            "Epoch 3/4 - Batch 41200/50000 - Loss: 1.4924\n",
            "Epoch 3/4 - Batch 41250/50000 - Loss: 1.1374\n",
            "Epoch 3/4 - Batch 41300/50000 - Loss: 1.4433\n",
            "Epoch 3/4 - Batch 41350/50000 - Loss: 0.9091\n",
            "Epoch 3/4 - Batch 41400/50000 - Loss: 0.8392\n",
            "Epoch 3/4 - Batch 41450/50000 - Loss: 1.5826\n",
            "Epoch 3/4 - Batch 41500/50000 - Loss: 1.0543\n",
            "Epoch 3/4 - Batch 41550/50000 - Loss: 0.8338\n",
            "Epoch 3/4 - Batch 41600/50000 - Loss: 1.6443\n",
            "Epoch 3/4 - Batch 41650/50000 - Loss: 0.7853\n",
            "Epoch 3/4 - Batch 41700/50000 - Loss: 1.2313\n",
            "Epoch 3/4 - Batch 41750/50000 - Loss: 1.1955\n",
            "Epoch 3/4 - Batch 41800/50000 - Loss: 0.9040\n",
            "Epoch 3/4 - Batch 41850/50000 - Loss: 1.2772\n",
            "Epoch 3/4 - Batch 41900/50000 - Loss: 0.9710\n",
            "Epoch 3/4 - Batch 41950/50000 - Loss: 1.3834\n",
            "Epoch 3/4 - Batch 42000/50000 - Loss: 0.8440\n",
            "Epoch 3/4 - Batch 42050/50000 - Loss: 0.4730\n",
            "Epoch 3/4 - Batch 42100/50000 - Loss: 1.2963\n",
            "Epoch 3/4 - Batch 42150/50000 - Loss: 0.9832\n",
            "Epoch 3/4 - Batch 42200/50000 - Loss: 1.4847\n",
            "Epoch 3/4 - Batch 42250/50000 - Loss: 1.3806\n",
            "Epoch 3/4 - Batch 42300/50000 - Loss: 1.0101\n",
            "Epoch 3/4 - Batch 42350/50000 - Loss: 1.4203\n",
            "Epoch 3/4 - Batch 42400/50000 - Loss: 1.1705\n",
            "Epoch 3/4 - Batch 42450/50000 - Loss: 1.0593\n",
            "Epoch 3/4 - Batch 42500/50000 - Loss: 0.9838\n",
            "Epoch 3/4 - Batch 42550/50000 - Loss: 0.4964\n",
            "Epoch 3/4 - Batch 42600/50000 - Loss: 1.4003\n",
            "Epoch 3/4 - Batch 42650/50000 - Loss: 1.7036\n",
            "Epoch 3/4 - Batch 42700/50000 - Loss: 0.9178\n",
            "Epoch 3/4 - Batch 42750/50000 - Loss: 1.7581\n",
            "Epoch 3/4 - Batch 42800/50000 - Loss: 1.4112\n",
            "Epoch 3/4 - Batch 42850/50000 - Loss: 1.1793\n",
            "Epoch 3/4 - Batch 42900/50000 - Loss: 1.0821\n",
            "Epoch 3/4 - Batch 42950/50000 - Loss: 1.2375\n",
            "Epoch 3/4 - Batch 43000/50000 - Loss: 1.0108\n",
            "Epoch 3/4 - Batch 43050/50000 - Loss: 1.0893\n",
            "Epoch 3/4 - Batch 43100/50000 - Loss: 1.6818\n",
            "Epoch 3/4 - Batch 43150/50000 - Loss: 1.7170\n",
            "Epoch 3/4 - Batch 43200/50000 - Loss: 0.9986\n",
            "Epoch 3/4 - Batch 43250/50000 - Loss: 0.6971\n",
            "Epoch 3/4 - Batch 43300/50000 - Loss: 1.6552\n",
            "Epoch 3/4 - Batch 43350/50000 - Loss: 1.7664\n",
            "Epoch 3/4 - Batch 43400/50000 - Loss: 1.0147\n",
            "Epoch 3/4 - Batch 43450/50000 - Loss: 1.3720\n",
            "Epoch 3/4 - Batch 43500/50000 - Loss: 1.1690\n",
            "Epoch 3/4 - Batch 43550/50000 - Loss: 1.6816\n",
            "Epoch 3/4 - Batch 43600/50000 - Loss: 1.0906\n",
            "Epoch 3/4 - Batch 43650/50000 - Loss: 1.1538\n",
            "Epoch 3/4 - Batch 43700/50000 - Loss: 1.5697\n",
            "Epoch 3/4 - Batch 43750/50000 - Loss: 1.4141\n",
            "Epoch 3/4 - Batch 43800/50000 - Loss: 1.7386\n",
            "Epoch 3/4 - Batch 43850/50000 - Loss: 1.1798\n",
            "Epoch 3/4 - Batch 43900/50000 - Loss: 1.7945\n",
            "Epoch 3/4 - Batch 43950/50000 - Loss: 1.5082\n",
            "Epoch 3/4 - Batch 44000/50000 - Loss: 1.0955\n",
            "Epoch 3/4 - Batch 44050/50000 - Loss: 1.2138\n",
            "Epoch 3/4 - Batch 44100/50000 - Loss: 1.0247\n",
            "Epoch 3/4 - Batch 44150/50000 - Loss: 1.4534\n",
            "Epoch 3/4 - Batch 44200/50000 - Loss: 1.0440\n",
            "Epoch 3/4 - Batch 44250/50000 - Loss: 1.8792\n",
            "Epoch 3/4 - Batch 44300/50000 - Loss: 0.4787\n",
            "Epoch 3/4 - Batch 44350/50000 - Loss: 1.6228\n",
            "Epoch 3/4 - Batch 44400/50000 - Loss: 0.7524\n",
            "Epoch 3/4 - Batch 44450/50000 - Loss: 0.8417\n",
            "Epoch 3/4 - Batch 44500/50000 - Loss: 1.7086\n",
            "Epoch 3/4 - Batch 44550/50000 - Loss: 1.2995\n",
            "Epoch 3/4 - Batch 44600/50000 - Loss: 1.2421\n",
            "Epoch 3/4 - Batch 44650/50000 - Loss: 1.1050\n",
            "Epoch 3/4 - Batch 44700/50000 - Loss: 1.5404\n",
            "Epoch 3/4 - Batch 44750/50000 - Loss: 1.0903\n",
            "Epoch 3/4 - Batch 44800/50000 - Loss: 1.7061\n",
            "Epoch 3/4 - Batch 44850/50000 - Loss: 0.9598\n",
            "Epoch 3/4 - Batch 44900/50000 - Loss: 0.4277\n",
            "Epoch 3/4 - Batch 44950/50000 - Loss: 0.7903\n",
            "Epoch 3/4 - Batch 45000/50000 - Loss: 1.5390\n",
            "Epoch 3/4 - Batch 45050/50000 - Loss: 1.3357\n",
            "Epoch 3/4 - Batch 45100/50000 - Loss: 1.1336\n",
            "Epoch 3/4 - Batch 45150/50000 - Loss: 0.7515\n",
            "Epoch 3/4 - Batch 45200/50000 - Loss: 2.0895\n",
            "Epoch 3/4 - Batch 45250/50000 - Loss: 1.2169\n",
            "Epoch 3/4 - Batch 45300/50000 - Loss: 1.8329\n",
            "Epoch 3/4 - Batch 45350/50000 - Loss: 1.8104\n",
            "Epoch 3/4 - Batch 45400/50000 - Loss: 0.6642\n",
            "Epoch 3/4 - Batch 45450/50000 - Loss: 0.8602\n",
            "Epoch 3/4 - Batch 45500/50000 - Loss: 1.6686\n",
            "Epoch 3/4 - Batch 45550/50000 - Loss: 1.7832\n",
            "Epoch 3/4 - Batch 45600/50000 - Loss: 1.8228\n",
            "Epoch 3/4 - Batch 45650/50000 - Loss: 1.7873\n",
            "Epoch 3/4 - Batch 45700/50000 - Loss: 1.1096\n",
            "Epoch 3/4 - Batch 45750/50000 - Loss: 1.2972\n",
            "Epoch 3/4 - Batch 45800/50000 - Loss: 1.1538\n",
            "Epoch 3/4 - Batch 45850/50000 - Loss: 1.6285\n",
            "Epoch 3/4 - Batch 45900/50000 - Loss: 0.8018\n",
            "Epoch 3/4 - Batch 45950/50000 - Loss: 0.6577\n",
            "Epoch 3/4 - Batch 46000/50000 - Loss: 1.8298\n",
            "Epoch 3/4 - Batch 46050/50000 - Loss: 1.3710\n",
            "Epoch 3/4 - Batch 46100/50000 - Loss: 1.5139\n",
            "Epoch 3/4 - Batch 46150/50000 - Loss: 1.3025\n",
            "Epoch 3/4 - Batch 46200/50000 - Loss: 1.3565\n",
            "Epoch 3/4 - Batch 46250/50000 - Loss: 1.0238\n",
            "Epoch 3/4 - Batch 46300/50000 - Loss: 1.3092\n",
            "Epoch 3/4 - Batch 46350/50000 - Loss: 1.1641\n",
            "Epoch 3/4 - Batch 46400/50000 - Loss: 0.8212\n",
            "Epoch 3/4 - Batch 46450/50000 - Loss: 1.2345\n",
            "Epoch 3/4 - Batch 46500/50000 - Loss: 1.3427\n",
            "Epoch 3/4 - Batch 46550/50000 - Loss: 1.3586\n",
            "Epoch 3/4 - Batch 46600/50000 - Loss: 1.2404\n",
            "Epoch 3/4 - Batch 46650/50000 - Loss: 0.4804\n",
            "Epoch 3/4 - Batch 46700/50000 - Loss: 1.3735\n",
            "Epoch 3/4 - Batch 46750/50000 - Loss: 0.2930\n",
            "Epoch 3/4 - Batch 46800/50000 - Loss: 0.5678\n",
            "Epoch 3/4 - Batch 46850/50000 - Loss: 1.1457\n",
            "Epoch 3/4 - Batch 46900/50000 - Loss: 1.3050\n",
            "Epoch 3/4 - Batch 46950/50000 - Loss: 0.8728\n",
            "Epoch 3/4 - Batch 47000/50000 - Loss: 1.3606\n",
            "Epoch 3/4 - Batch 47050/50000 - Loss: 0.9640\n",
            "Epoch 3/4 - Batch 47100/50000 - Loss: 0.9480\n",
            "Epoch 3/4 - Batch 47150/50000 - Loss: 1.3529\n",
            "Epoch 3/4 - Batch 47200/50000 - Loss: 1.0960\n",
            "Epoch 3/4 - Batch 47250/50000 - Loss: 1.4699\n",
            "Epoch 3/4 - Batch 47300/50000 - Loss: 1.3085\n",
            "Epoch 3/4 - Batch 47350/50000 - Loss: 1.0781\n",
            "Epoch 3/4 - Batch 47400/50000 - Loss: 0.5805\n",
            "Epoch 3/4 - Batch 47450/50000 - Loss: 1.4192\n",
            "Epoch 3/4 - Batch 47500/50000 - Loss: 1.2932\n",
            "Epoch 3/4 - Batch 47550/50000 - Loss: 1.0692\n",
            "Epoch 3/4 - Batch 47600/50000 - Loss: 1.5131\n",
            "Epoch 3/4 - Batch 47650/50000 - Loss: 1.6375\n",
            "Epoch 3/4 - Batch 47700/50000 - Loss: 1.3431\n",
            "Epoch 3/4 - Batch 47750/50000 - Loss: 1.2556\n",
            "Epoch 3/4 - Batch 47800/50000 - Loss: 1.0369\n",
            "Epoch 3/4 - Batch 47850/50000 - Loss: 1.5921\n",
            "Epoch 3/4 - Batch 47900/50000 - Loss: 0.9697\n",
            "Epoch 3/4 - Batch 47950/50000 - Loss: 1.2652\n",
            "Epoch 3/4 - Batch 48000/50000 - Loss: 1.3212\n",
            "Epoch 3/4 - Batch 48050/50000 - Loss: 0.7808\n",
            "Epoch 3/4 - Batch 48100/50000 - Loss: 1.3133\n",
            "Epoch 3/4 - Batch 48150/50000 - Loss: 1.4278\n",
            "Epoch 3/4 - Batch 48200/50000 - Loss: 0.8154\n",
            "Epoch 3/4 - Batch 48250/50000 - Loss: 1.0503\n",
            "Epoch 3/4 - Batch 48300/50000 - Loss: 1.5074\n",
            "Epoch 3/4 - Batch 48350/50000 - Loss: 0.7219\n",
            "Epoch 3/4 - Batch 48400/50000 - Loss: 1.1937\n",
            "Epoch 3/4 - Batch 48450/50000 - Loss: 1.4061\n",
            "Epoch 3/4 - Batch 48500/50000 - Loss: 1.2956\n",
            "Epoch 3/4 - Batch 48550/50000 - Loss: 1.5976\n",
            "Epoch 3/4 - Batch 48600/50000 - Loss: 0.4710\n",
            "Epoch 3/4 - Batch 48650/50000 - Loss: 0.8868\n",
            "Epoch 3/4 - Batch 48700/50000 - Loss: 1.1744\n",
            "Epoch 3/4 - Batch 48750/50000 - Loss: 0.8646\n",
            "Epoch 3/4 - Batch 48800/50000 - Loss: 0.8561\n",
            "Epoch 3/4 - Batch 48850/50000 - Loss: 1.3400\n",
            "Epoch 3/4 - Batch 48900/50000 - Loss: 1.0910\n",
            "Epoch 3/4 - Batch 48950/50000 - Loss: 1.2407\n",
            "Epoch 3/4 - Batch 49000/50000 - Loss: 0.5148\n",
            "Epoch 3/4 - Batch 49050/50000 - Loss: 1.7684\n",
            "Epoch 3/4 - Batch 49100/50000 - Loss: 0.6047\n",
            "Epoch 3/4 - Batch 49150/50000 - Loss: 1.3115\n",
            "Epoch 3/4 - Batch 49200/50000 - Loss: 1.1464\n",
            "Epoch 3/4 - Batch 49250/50000 - Loss: 1.3810\n",
            "Epoch 3/4 - Batch 49300/50000 - Loss: 1.2554\n",
            "Epoch 3/4 - Batch 49350/50000 - Loss: 1.5975\n",
            "Epoch 3/4 - Batch 49400/50000 - Loss: 1.4265\n",
            "Epoch 3/4 - Batch 49450/50000 - Loss: 1.5143\n",
            "Epoch 3/4 - Batch 49500/50000 - Loss: 1.6558\n",
            "Epoch 3/4 - Batch 49550/50000 - Loss: 0.5087\n",
            "Epoch 3/4 - Batch 49600/50000 - Loss: 1.4582\n",
            "Epoch 3/4 - Batch 49650/50000 - Loss: 1.9087\n",
            "Epoch 3/4 - Batch 49700/50000 - Loss: 1.1410\n",
            "Epoch 3/4 - Batch 49750/50000 - Loss: 1.1042\n",
            "Epoch 3/4 - Batch 49800/50000 - Loss: 1.8869\n",
            "Epoch 3/4 - Batch 49850/50000 - Loss: 1.1125\n",
            "Epoch 3/4 - Batch 49900/50000 - Loss: 1.2639\n",
            "Epoch 3/4 - Batch 49950/50000 - Loss: 1.0886\n",
            "Epoch 3/4 - Average loss: 1.2516 - Duration: 26884.50s\n",
            "Epoch 4/4 - Batch 0/50000 - Loss: 1.2521\n",
            "Epoch 4/4 - Batch 50/50000 - Loss: 1.5750\n",
            "Epoch 4/4 - Batch 100/50000 - Loss: 1.9873\n",
            "Epoch 4/4 - Batch 150/50000 - Loss: 0.9971\n",
            "Epoch 4/4 - Batch 200/50000 - Loss: 1.3790\n",
            "Epoch 4/4 - Batch 250/50000 - Loss: 1.9219\n",
            "Epoch 4/4 - Batch 300/50000 - Loss: 1.3675\n",
            "Epoch 4/4 - Batch 350/50000 - Loss: 1.6769\n",
            "Epoch 4/4 - Batch 400/50000 - Loss: 1.4706\n",
            "Epoch 4/4 - Batch 450/50000 - Loss: 1.4647\n",
            "Epoch 4/4 - Batch 500/50000 - Loss: 0.6661\n",
            "Epoch 4/4 - Batch 550/50000 - Loss: 1.6369\n",
            "Epoch 4/4 - Batch 600/50000 - Loss: 0.7738\n",
            "Epoch 4/4 - Batch 650/50000 - Loss: 0.7579\n",
            "Epoch 4/4 - Batch 700/50000 - Loss: 1.1445\n",
            "Epoch 4/4 - Batch 750/50000 - Loss: 1.1034\n",
            "Epoch 4/4 - Batch 800/50000 - Loss: 1.3464\n",
            "Epoch 4/4 - Batch 850/50000 - Loss: 1.4369\n",
            "Epoch 4/4 - Batch 900/50000 - Loss: 0.8942\n",
            "Epoch 4/4 - Batch 950/50000 - Loss: 0.7038\n",
            "Epoch 4/4 - Batch 1000/50000 - Loss: 0.6843\n",
            "Epoch 4/4 - Batch 1050/50000 - Loss: 0.7453\n",
            "Epoch 4/4 - Batch 1100/50000 - Loss: 1.4280\n",
            "Epoch 4/4 - Batch 1150/50000 - Loss: 1.2303\n",
            "Epoch 4/4 - Batch 1200/50000 - Loss: 0.7486\n",
            "Epoch 4/4 - Batch 1250/50000 - Loss: 1.4039\n",
            "Epoch 4/4 - Batch 1300/50000 - Loss: 1.5819\n",
            "Epoch 4/4 - Batch 1350/50000 - Loss: 0.9191\n",
            "Epoch 4/4 - Batch 1400/50000 - Loss: 0.6081\n",
            "Epoch 4/4 - Batch 1450/50000 - Loss: 0.8779\n",
            "Epoch 4/4 - Batch 1500/50000 - Loss: 0.8829\n",
            "Epoch 4/4 - Batch 1550/50000 - Loss: 1.2639\n",
            "Epoch 4/4 - Batch 1600/50000 - Loss: 0.9319\n",
            "Epoch 4/4 - Batch 1650/50000 - Loss: 1.5799\n",
            "Epoch 4/4 - Batch 1700/50000 - Loss: 0.9850\n",
            "Epoch 4/4 - Batch 1750/50000 - Loss: 0.8980\n",
            "Epoch 4/4 - Batch 1800/50000 - Loss: 1.3042\n",
            "Epoch 4/4 - Batch 1850/50000 - Loss: 0.7979\n",
            "Epoch 4/4 - Batch 1900/50000 - Loss: 1.4587\n",
            "Epoch 4/4 - Batch 1950/50000 - Loss: 1.5618\n",
            "Epoch 4/4 - Batch 2000/50000 - Loss: 0.8224\n",
            "Epoch 4/4 - Batch 2050/50000 - Loss: 0.5300\n",
            "Epoch 4/4 - Batch 2100/50000 - Loss: 1.4294\n",
            "Epoch 4/4 - Batch 2150/50000 - Loss: 1.1124\n",
            "Epoch 4/4 - Batch 2200/50000 - Loss: 1.3424\n",
            "Epoch 4/4 - Batch 2250/50000 - Loss: 0.6812\n",
            "Epoch 4/4 - Batch 2300/50000 - Loss: 1.2787\n",
            "Epoch 4/4 - Batch 2350/50000 - Loss: 0.8844\n",
            "Epoch 4/4 - Batch 2400/50000 - Loss: 0.9509\n",
            "Epoch 4/4 - Batch 2450/50000 - Loss: 1.0472\n",
            "Epoch 4/4 - Batch 2500/50000 - Loss: 0.7321\n",
            "Epoch 4/4 - Batch 2550/50000 - Loss: 0.8018\n",
            "Epoch 4/4 - Batch 2600/50000 - Loss: 1.2510\n",
            "Epoch 4/4 - Batch 2650/50000 - Loss: 0.5693\n",
            "Epoch 4/4 - Batch 2700/50000 - Loss: 1.0155\n",
            "Epoch 4/4 - Batch 2750/50000 - Loss: 1.5760\n",
            "Epoch 4/4 - Batch 2800/50000 - Loss: 1.1946\n",
            "Epoch 4/4 - Batch 2850/50000 - Loss: 0.9311\n",
            "Epoch 4/4 - Batch 2900/50000 - Loss: 1.6477\n",
            "Epoch 4/4 - Batch 2950/50000 - Loss: 1.2904\n",
            "Epoch 4/4 - Batch 3000/50000 - Loss: 1.4594\n",
            "Epoch 4/4 - Batch 3050/50000 - Loss: 1.7708\n",
            "Epoch 4/4 - Batch 3100/50000 - Loss: 0.9699\n",
            "Epoch 4/4 - Batch 3150/50000 - Loss: 1.6739\n",
            "Epoch 4/4 - Batch 3200/50000 - Loss: 1.0544\n",
            "Epoch 4/4 - Batch 3250/50000 - Loss: 1.1539\n",
            "Epoch 4/4 - Batch 3300/50000 - Loss: 1.0176\n",
            "Epoch 4/4 - Batch 3350/50000 - Loss: 0.6851\n",
            "Epoch 4/4 - Batch 3400/50000 - Loss: 1.5613\n",
            "Epoch 4/4 - Batch 3450/50000 - Loss: 1.1841\n",
            "Epoch 4/4 - Batch 3500/50000 - Loss: 1.7485\n",
            "Epoch 4/4 - Batch 3550/50000 - Loss: 0.8817\n",
            "Epoch 4/4 - Batch 3600/50000 - Loss: 1.3864\n",
            "Epoch 4/4 - Batch 3650/50000 - Loss: 1.0687\n",
            "Epoch 4/4 - Batch 3700/50000 - Loss: 1.0672\n",
            "Epoch 4/4 - Batch 3750/50000 - Loss: 0.8264\n",
            "Epoch 4/4 - Batch 3800/50000 - Loss: 1.4279\n",
            "Epoch 4/4 - Batch 3850/50000 - Loss: 1.1317\n",
            "Epoch 4/4 - Batch 3900/50000 - Loss: 1.5879\n",
            "Epoch 4/4 - Batch 3950/50000 - Loss: 1.1608\n",
            "Epoch 4/4 - Batch 4000/50000 - Loss: 1.5267\n",
            "Epoch 4/4 - Batch 4050/50000 - Loss: 1.5104\n",
            "Epoch 4/4 - Batch 4100/50000 - Loss: 0.9287\n",
            "Epoch 4/4 - Batch 4150/50000 - Loss: 1.8322\n",
            "Epoch 4/4 - Batch 4200/50000 - Loss: 1.3788\n",
            "Epoch 4/4 - Batch 4250/50000 - Loss: 1.2458\n",
            "Epoch 4/4 - Batch 4300/50000 - Loss: 1.4959\n",
            "Epoch 4/4 - Batch 4350/50000 - Loss: 1.4402\n",
            "Epoch 4/4 - Batch 4400/50000 - Loss: 1.1920\n",
            "Epoch 4/4 - Batch 4450/50000 - Loss: 1.5002\n",
            "Epoch 4/4 - Batch 4500/50000 - Loss: 1.3696\n",
            "Epoch 4/4 - Batch 4550/50000 - Loss: 1.4444\n",
            "Epoch 4/4 - Batch 4600/50000 - Loss: 1.5715\n",
            "Epoch 4/4 - Batch 4650/50000 - Loss: 0.6521\n",
            "Epoch 4/4 - Batch 4700/50000 - Loss: 1.0775\n",
            "Epoch 4/4 - Batch 4750/50000 - Loss: 0.7032\n",
            "Epoch 4/4 - Batch 4800/50000 - Loss: 1.2744\n",
            "Epoch 4/4 - Batch 4850/50000 - Loss: 1.4574\n",
            "Epoch 4/4 - Batch 4900/50000 - Loss: 2.0540\n",
            "Epoch 4/4 - Batch 4950/50000 - Loss: 0.9184\n",
            "Epoch 4/4 - Batch 5000/50000 - Loss: 1.3726\n",
            "Epoch 4/4 - Batch 5050/50000 - Loss: 0.9613\n",
            "Epoch 4/4 - Batch 5100/50000 - Loss: 1.0097\n",
            "Epoch 4/4 - Batch 5150/50000 - Loss: 1.4092\n",
            "Epoch 4/4 - Batch 5200/50000 - Loss: 2.0978\n",
            "Epoch 4/4 - Batch 5250/50000 - Loss: 1.1228\n",
            "Epoch 4/4 - Batch 5300/50000 - Loss: 1.2623\n",
            "Epoch 4/4 - Batch 5350/50000 - Loss: 1.6399\n",
            "Epoch 4/4 - Batch 5400/50000 - Loss: 0.6157\n",
            "Epoch 4/4 - Batch 5450/50000 - Loss: 1.3825\n",
            "Epoch 4/4 - Batch 5500/50000 - Loss: 1.2154\n",
            "Epoch 4/4 - Batch 5550/50000 - Loss: 0.7866\n",
            "Epoch 4/4 - Batch 5600/50000 - Loss: 0.7074\n",
            "Epoch 4/4 - Batch 5650/50000 - Loss: 0.9340\n",
            "Epoch 4/4 - Batch 5700/50000 - Loss: 1.5117\n",
            "Epoch 4/4 - Batch 5750/50000 - Loss: 1.0923\n",
            "Epoch 4/4 - Batch 5800/50000 - Loss: 0.8228\n",
            "Epoch 4/4 - Batch 5850/50000 - Loss: 1.5286\n",
            "Epoch 4/4 - Batch 5900/50000 - Loss: 1.1678\n",
            "Epoch 4/4 - Batch 5950/50000 - Loss: 1.0245\n",
            "Epoch 4/4 - Batch 6000/50000 - Loss: 0.6416\n",
            "Epoch 4/4 - Batch 6050/50000 - Loss: 0.5482\n",
            "Epoch 4/4 - Batch 6100/50000 - Loss: 1.3115\n",
            "Epoch 4/4 - Batch 6150/50000 - Loss: 0.7561\n",
            "Epoch 4/4 - Batch 6200/50000 - Loss: 1.2166\n",
            "Epoch 4/4 - Batch 6250/50000 - Loss: 1.1983\n",
            "Epoch 4/4 - Batch 6300/50000 - Loss: 1.2162\n",
            "Epoch 4/4 - Batch 6350/50000 - Loss: 0.9040\n",
            "Epoch 4/4 - Batch 6400/50000 - Loss: 1.5023\n",
            "Epoch 4/4 - Batch 6450/50000 - Loss: 1.3824\n",
            "Epoch 4/4 - Batch 6500/50000 - Loss: 0.4749\n",
            "Epoch 4/4 - Batch 6550/50000 - Loss: 1.2577\n",
            "Epoch 4/4 - Batch 6600/50000 - Loss: 0.8684\n",
            "Epoch 4/4 - Batch 6650/50000 - Loss: 0.8803\n",
            "Epoch 4/4 - Batch 6700/50000 - Loss: 1.7077\n",
            "Epoch 4/4 - Batch 6750/50000 - Loss: 1.5521\n",
            "Epoch 4/4 - Batch 6800/50000 - Loss: 0.9699\n",
            "Epoch 4/4 - Batch 6850/50000 - Loss: 1.3790\n",
            "Epoch 4/4 - Batch 6900/50000 - Loss: 1.0188\n",
            "Epoch 4/4 - Batch 6950/50000 - Loss: 0.9170\n",
            "Epoch 4/4 - Batch 7000/50000 - Loss: 1.5639\n",
            "Epoch 4/4 - Batch 7050/50000 - Loss: 1.2576\n",
            "Epoch 4/4 - Batch 7100/50000 - Loss: 1.7096\n",
            "Epoch 4/4 - Batch 7150/50000 - Loss: 0.9369\n",
            "Epoch 4/4 - Batch 7200/50000 - Loss: 1.1456\n",
            "Epoch 4/4 - Batch 7250/50000 - Loss: 1.2327\n",
            "Epoch 4/4 - Batch 7300/50000 - Loss: 1.5220\n",
            "Epoch 4/4 - Batch 7350/50000 - Loss: 0.8350\n",
            "Epoch 4/4 - Batch 7400/50000 - Loss: 0.9904\n",
            "Epoch 4/4 - Batch 7450/50000 - Loss: 0.9529\n",
            "Epoch 4/4 - Batch 7500/50000 - Loss: 1.5614\n",
            "Epoch 4/4 - Batch 7550/50000 - Loss: 0.9733\n",
            "Epoch 4/4 - Batch 7600/50000 - Loss: 0.7238\n",
            "Epoch 4/4 - Batch 7650/50000 - Loss: 0.9500\n",
            "Epoch 4/4 - Batch 7700/50000 - Loss: 0.4870\n",
            "Epoch 4/4 - Batch 7750/50000 - Loss: 1.5788\n",
            "Epoch 4/4 - Batch 7800/50000 - Loss: 1.2195\n",
            "Epoch 4/4 - Batch 7850/50000 - Loss: 1.1529\n",
            "Epoch 4/4 - Batch 7900/50000 - Loss: 1.6941\n",
            "Epoch 4/4 - Batch 7950/50000 - Loss: 0.7781\n",
            "Epoch 4/4 - Batch 8000/50000 - Loss: 1.3196\n",
            "Epoch 4/4 - Batch 8050/50000 - Loss: 1.7066\n",
            "Epoch 4/4 - Batch 8100/50000 - Loss: 1.5082\n",
            "Epoch 4/4 - Batch 8150/50000 - Loss: 1.1874\n",
            "Epoch 4/4 - Batch 8200/50000 - Loss: 1.5229\n",
            "Epoch 4/4 - Batch 8250/50000 - Loss: 1.0916\n",
            "Epoch 4/4 - Batch 8300/50000 - Loss: 1.5738\n",
            "Epoch 4/4 - Batch 8350/50000 - Loss: 1.5493\n",
            "Epoch 4/4 - Batch 8400/50000 - Loss: 0.8685\n",
            "Epoch 4/4 - Batch 8450/50000 - Loss: 1.4621\n",
            "Epoch 4/4 - Batch 8500/50000 - Loss: 1.7603\n",
            "Epoch 4/4 - Batch 8550/50000 - Loss: 1.4917\n",
            "Epoch 4/4 - Batch 8600/50000 - Loss: 1.1117\n",
            "Epoch 4/4 - Batch 8650/50000 - Loss: 1.4566\n",
            "Epoch 4/4 - Batch 8700/50000 - Loss: 1.1093\n",
            "Epoch 4/4 - Batch 8750/50000 - Loss: 1.4014\n",
            "Epoch 4/4 - Batch 8800/50000 - Loss: 1.1538\n",
            "Epoch 4/4 - Batch 8850/50000 - Loss: 1.6801\n",
            "Epoch 4/4 - Batch 8900/50000 - Loss: 1.5564\n",
            "Epoch 4/4 - Batch 8950/50000 - Loss: 1.7473\n",
            "Epoch 4/4 - Batch 9000/50000 - Loss: 1.4940\n",
            "Epoch 4/4 - Batch 9050/50000 - Loss: 1.1820\n",
            "Epoch 4/4 - Batch 9100/50000 - Loss: 1.2955\n",
            "Epoch 4/4 - Batch 9150/50000 - Loss: 1.0079\n",
            "Epoch 4/4 - Batch 9200/50000 - Loss: 1.3637\n",
            "Epoch 4/4 - Batch 9250/50000 - Loss: 0.8972\n",
            "Epoch 4/4 - Batch 9300/50000 - Loss: 0.9221\n",
            "Epoch 4/4 - Batch 9350/50000 - Loss: 0.8611\n",
            "Epoch 4/4 - Batch 9400/50000 - Loss: 0.9652\n",
            "Epoch 4/4 - Batch 9450/50000 - Loss: 1.4413\n",
            "Epoch 4/4 - Batch 9500/50000 - Loss: 1.0901\n",
            "Epoch 4/4 - Batch 9550/50000 - Loss: 0.9222\n",
            "Epoch 4/4 - Batch 9600/50000 - Loss: 1.3106\n",
            "Epoch 4/4 - Batch 9650/50000 - Loss: 1.3392\n",
            "Epoch 4/4 - Batch 9700/50000 - Loss: 1.0152\n",
            "Epoch 4/4 - Batch 9750/50000 - Loss: 1.0506\n",
            "Epoch 4/4 - Batch 9800/50000 - Loss: 0.8940\n",
            "Epoch 4/4 - Batch 9850/50000 - Loss: 1.4890\n",
            "Epoch 4/4 - Batch 9900/50000 - Loss: 0.7140\n",
            "Epoch 4/4 - Batch 9950/50000 - Loss: 1.0700\n",
            "Epoch 4/4 - Batch 10000/50000 - Loss: 0.7055\n",
            "Epoch 4/4 - Batch 10050/50000 - Loss: 1.2911\n",
            "Epoch 4/4 - Batch 10100/50000 - Loss: 1.1311\n",
            "Epoch 4/4 - Batch 10150/50000 - Loss: 0.9226\n",
            "Epoch 4/4 - Batch 10200/50000 - Loss: 1.8056\n",
            "Epoch 4/4 - Batch 10250/50000 - Loss: 1.1311\n",
            "Epoch 4/4 - Batch 10300/50000 - Loss: 1.6760\n",
            "Epoch 4/4 - Batch 10350/50000 - Loss: 1.5334\n",
            "Epoch 4/4 - Batch 10400/50000 - Loss: 1.5712\n",
            "Epoch 4/4 - Batch 10450/50000 - Loss: 1.6333\n",
            "Epoch 4/4 - Batch 10500/50000 - Loss: 1.3431\n",
            "Epoch 4/4 - Batch 10550/50000 - Loss: 0.9825\n",
            "Epoch 4/4 - Batch 10600/50000 - Loss: 1.6309\n",
            "Epoch 4/4 - Batch 10650/50000 - Loss: 1.1609\n",
            "Epoch 4/4 - Batch 10700/50000 - Loss: 1.6705\n",
            "Epoch 4/4 - Batch 10750/50000 - Loss: 0.8594\n",
            "Epoch 4/4 - Batch 10800/50000 - Loss: 0.8867\n",
            "Epoch 4/4 - Batch 10850/50000 - Loss: 1.8614\n",
            "Epoch 4/4 - Batch 10900/50000 - Loss: 1.7825\n",
            "Epoch 4/4 - Batch 10950/50000 - Loss: 0.4173\n",
            "Epoch 4/4 - Batch 11000/50000 - Loss: 1.1516\n",
            "Epoch 4/4 - Batch 11050/50000 - Loss: 1.5448\n",
            "Epoch 4/4 - Batch 11100/50000 - Loss: 0.8932\n",
            "Epoch 4/4 - Batch 11150/50000 - Loss: 0.7953\n",
            "Epoch 4/4 - Batch 11200/50000 - Loss: 0.8052\n",
            "Epoch 4/4 - Batch 11250/50000 - Loss: 1.1915\n",
            "Epoch 4/4 - Batch 11300/50000 - Loss: 0.8776\n",
            "Epoch 4/4 - Batch 11350/50000 - Loss: 0.9350\n",
            "Epoch 4/4 - Batch 11400/50000 - Loss: 1.7211\n",
            "Epoch 4/4 - Batch 11450/50000 - Loss: 1.3070\n",
            "Epoch 4/4 - Batch 11500/50000 - Loss: 1.5410\n",
            "Epoch 4/4 - Batch 11550/50000 - Loss: 2.0398\n",
            "Epoch 4/4 - Batch 11600/50000 - Loss: 0.9115\n",
            "Epoch 4/4 - Batch 11650/50000 - Loss: 1.2418\n",
            "Epoch 4/4 - Batch 11700/50000 - Loss: 1.2725\n",
            "Epoch 4/4 - Batch 11750/50000 - Loss: 1.9040\n",
            "Epoch 4/4 - Batch 11800/50000 - Loss: 1.6892\n",
            "Epoch 4/4 - Batch 11850/50000 - Loss: 1.2828\n",
            "Epoch 4/4 - Batch 11900/50000 - Loss: 0.9217\n",
            "Epoch 4/4 - Batch 11950/50000 - Loss: 1.2286\n",
            "Epoch 4/4 - Batch 12000/50000 - Loss: 1.3979\n",
            "Epoch 4/4 - Batch 12050/50000 - Loss: 0.5767\n",
            "Epoch 4/4 - Batch 12100/50000 - Loss: 1.7860\n",
            "Epoch 4/4 - Batch 12150/50000 - Loss: 1.3675\n",
            "Epoch 4/4 - Batch 12200/50000 - Loss: 1.6532\n",
            "Epoch 4/4 - Batch 12250/50000 - Loss: 1.1544\n",
            "Epoch 4/4 - Batch 12300/50000 - Loss: 1.7178\n",
            "Epoch 4/4 - Batch 12350/50000 - Loss: 1.5388\n",
            "Epoch 4/4 - Batch 12400/50000 - Loss: 1.1984\n",
            "Epoch 4/4 - Batch 12450/50000 - Loss: 1.3852\n",
            "Epoch 4/4 - Batch 12500/50000 - Loss: 0.9533\n",
            "Epoch 4/4 - Batch 12550/50000 - Loss: 1.6190\n",
            "Epoch 4/4 - Batch 12600/50000 - Loss: 1.2764\n",
            "Epoch 4/4 - Batch 12650/50000 - Loss: 1.1097\n",
            "Epoch 4/4 - Batch 12700/50000 - Loss: 1.5046\n",
            "Epoch 4/4 - Batch 12750/50000 - Loss: 1.3679\n",
            "Epoch 4/4 - Batch 12800/50000 - Loss: 1.1612\n",
            "Epoch 4/4 - Batch 12850/50000 - Loss: 0.3048\n",
            "Epoch 4/4 - Batch 12900/50000 - Loss: 1.0859\n",
            "Epoch 4/4 - Batch 12950/50000 - Loss: 1.7509\n",
            "Epoch 4/4 - Batch 13000/50000 - Loss: 1.4245\n",
            "Epoch 4/4 - Batch 13050/50000 - Loss: 1.2889\n",
            "Epoch 4/4 - Batch 13100/50000 - Loss: 1.4561\n",
            "Epoch 4/4 - Batch 13150/50000 - Loss: 0.9757\n",
            "Epoch 4/4 - Batch 13200/50000 - Loss: 0.9497\n",
            "Epoch 4/4 - Batch 13250/50000 - Loss: 1.0764\n",
            "Epoch 4/4 - Batch 13300/50000 - Loss: 1.1953\n",
            "Epoch 4/4 - Batch 13350/50000 - Loss: 1.3834\n",
            "Epoch 4/4 - Batch 13400/50000 - Loss: 1.9993\n",
            "Epoch 4/4 - Batch 13450/50000 - Loss: 0.8477\n",
            "Epoch 4/4 - Batch 13500/50000 - Loss: 1.6290\n",
            "Epoch 4/4 - Batch 13550/50000 - Loss: 1.1454\n",
            "Epoch 4/4 - Batch 13600/50000 - Loss: 0.8939\n",
            "Epoch 4/4 - Batch 13650/50000 - Loss: 1.5749\n",
            "Epoch 4/4 - Batch 13700/50000 - Loss: 1.1368\n",
            "Epoch 4/4 - Batch 13750/50000 - Loss: 1.4066\n",
            "Epoch 4/4 - Batch 13800/50000 - Loss: 0.8916\n",
            "Epoch 4/4 - Batch 13850/50000 - Loss: 0.9904\n",
            "Epoch 4/4 - Batch 13900/50000 - Loss: 0.8520\n",
            "Epoch 4/4 - Batch 13950/50000 - Loss: 1.4645\n",
            "Epoch 4/4 - Batch 14000/50000 - Loss: 1.2228\n",
            "Epoch 4/4 - Batch 14050/50000 - Loss: 1.8842\n",
            "Epoch 4/4 - Batch 14100/50000 - Loss: 0.6028\n",
            "Epoch 4/4 - Batch 14150/50000 - Loss: 1.2825\n",
            "Epoch 4/4 - Batch 14200/50000 - Loss: 1.4165\n",
            "Epoch 4/4 - Batch 14250/50000 - Loss: 1.2411\n",
            "Epoch 4/4 - Batch 14300/50000 - Loss: 0.8023\n",
            "Epoch 4/4 - Batch 14350/50000 - Loss: 0.3541\n",
            "Epoch 4/4 - Batch 14400/50000 - Loss: 1.0733\n",
            "Epoch 4/4 - Batch 14450/50000 - Loss: 1.6391\n",
            "Epoch 4/4 - Batch 14500/50000 - Loss: 1.3653\n",
            "Epoch 4/4 - Batch 14550/50000 - Loss: 1.2358\n",
            "Epoch 4/4 - Batch 14600/50000 - Loss: 1.4109\n",
            "Epoch 4/4 - Batch 14650/50000 - Loss: 1.6473\n",
            "Epoch 4/4 - Batch 14700/50000 - Loss: 1.0823\n",
            "Epoch 4/4 - Batch 14750/50000 - Loss: 1.0808\n",
            "Epoch 4/4 - Batch 14800/50000 - Loss: 1.2716\n",
            "Epoch 4/4 - Batch 14850/50000 - Loss: 1.5522\n",
            "Epoch 4/4 - Batch 14900/50000 - Loss: 1.1829\n",
            "Epoch 4/4 - Batch 14950/50000 - Loss: 1.2998\n",
            "Epoch 4/4 - Batch 15000/50000 - Loss: 0.8933\n",
            "Epoch 4/4 - Batch 15050/50000 - Loss: 0.9190\n",
            "Epoch 4/4 - Batch 15100/50000 - Loss: 0.7457\n",
            "Epoch 4/4 - Batch 15150/50000 - Loss: 0.9081\n",
            "Epoch 4/4 - Batch 15200/50000 - Loss: 1.1970\n",
            "Epoch 4/4 - Batch 15250/50000 - Loss: 1.2098\n",
            "Epoch 4/4 - Batch 15300/50000 - Loss: 1.2583\n",
            "Epoch 4/4 - Batch 15350/50000 - Loss: 1.9066\n",
            "Epoch 4/4 - Batch 15400/50000 - Loss: 0.9346\n",
            "Epoch 4/4 - Batch 15450/50000 - Loss: 1.3808\n",
            "Epoch 4/4 - Batch 15500/50000 - Loss: 0.9527\n",
            "Epoch 4/4 - Batch 15550/50000 - Loss: 1.4942\n",
            "Epoch 4/4 - Batch 15600/50000 - Loss: 0.9236\n",
            "Epoch 4/4 - Batch 15650/50000 - Loss: 1.4648\n",
            "Epoch 4/4 - Batch 15700/50000 - Loss: 1.3090\n",
            "Epoch 4/4 - Batch 15750/50000 - Loss: 1.0794\n",
            "Epoch 4/4 - Batch 15800/50000 - Loss: 0.8448\n",
            "Epoch 4/4 - Batch 15850/50000 - Loss: 1.4523\n",
            "Epoch 4/4 - Batch 15900/50000 - Loss: 0.9309\n",
            "Epoch 4/4 - Batch 15950/50000 - Loss: 0.8772\n",
            "Epoch 4/4 - Batch 16000/50000 - Loss: 1.3234\n",
            "Epoch 4/4 - Batch 16050/50000 - Loss: 1.3768\n",
            "Epoch 4/4 - Batch 16100/50000 - Loss: 0.6276\n",
            "Epoch 4/4 - Batch 16150/50000 - Loss: 1.5204\n",
            "Epoch 4/4 - Batch 16200/50000 - Loss: 1.1413\n",
            "Epoch 4/4 - Batch 16250/50000 - Loss: 0.7572\n",
            "Epoch 4/4 - Batch 16300/50000 - Loss: 1.2699\n",
            "Epoch 4/4 - Batch 16350/50000 - Loss: 1.5910\n",
            "Epoch 4/4 - Batch 16400/50000 - Loss: 1.0191\n",
            "Epoch 4/4 - Batch 16450/50000 - Loss: 0.7322\n",
            "Epoch 4/4 - Batch 16500/50000 - Loss: 1.2442\n",
            "Epoch 4/4 - Batch 16550/50000 - Loss: 1.4169\n",
            "Epoch 4/4 - Batch 16600/50000 - Loss: 1.0746\n",
            "Epoch 4/4 - Batch 16650/50000 - Loss: 0.9778\n",
            "Epoch 4/4 - Batch 16700/50000 - Loss: 0.9403\n",
            "Epoch 4/4 - Batch 16750/50000 - Loss: 1.1086\n",
            "Epoch 4/4 - Batch 16800/50000 - Loss: 1.3499\n",
            "Epoch 4/4 - Batch 16850/50000 - Loss: 1.2339\n",
            "Epoch 4/4 - Batch 16900/50000 - Loss: 0.3830\n",
            "Epoch 4/4 - Batch 16950/50000 - Loss: 1.6494\n",
            "Epoch 4/4 - Batch 17000/50000 - Loss: 0.8261\n",
            "Epoch 4/4 - Batch 17050/50000 - Loss: 1.2687\n",
            "Epoch 4/4 - Batch 17100/50000 - Loss: 1.7059\n",
            "Epoch 4/4 - Batch 17150/50000 - Loss: 1.0344\n",
            "Epoch 4/4 - Batch 17200/50000 - Loss: 0.5774\n",
            "Epoch 4/4 - Batch 17250/50000 - Loss: 0.8753\n",
            "Epoch 4/4 - Batch 17300/50000 - Loss: 2.0069\n",
            "Epoch 4/4 - Batch 17350/50000 - Loss: 1.7253\n",
            "Epoch 4/4 - Batch 17400/50000 - Loss: 1.0277\n",
            "Epoch 4/4 - Batch 17450/50000 - Loss: 1.8159\n",
            "Epoch 4/4 - Batch 17500/50000 - Loss: 1.3486\n",
            "Epoch 4/4 - Batch 17550/50000 - Loss: 1.7624\n",
            "Epoch 4/4 - Batch 17600/50000 - Loss: 1.4884\n",
            "Epoch 4/4 - Batch 17650/50000 - Loss: 1.4611\n",
            "Epoch 4/4 - Batch 17700/50000 - Loss: 0.8876\n",
            "Epoch 4/4 - Batch 17750/50000 - Loss: 1.3231\n",
            "Epoch 4/4 - Batch 17800/50000 - Loss: 1.5778\n",
            "Epoch 4/4 - Batch 17850/50000 - Loss: 0.7041\n",
            "Epoch 4/4 - Batch 17900/50000 - Loss: 1.6813\n",
            "Epoch 4/4 - Batch 17950/50000 - Loss: 0.8943\n",
            "Epoch 4/4 - Batch 18000/50000 - Loss: 1.3497\n",
            "Epoch 4/4 - Batch 18050/50000 - Loss: 1.1124\n",
            "Epoch 4/4 - Batch 18100/50000 - Loss: 0.9058\n",
            "Epoch 4/4 - Batch 18150/50000 - Loss: 0.8552\n",
            "Epoch 4/4 - Batch 18200/50000 - Loss: 1.6849\n",
            "Epoch 4/4 - Batch 18250/50000 - Loss: 0.8891\n",
            "Epoch 4/4 - Batch 18300/50000 - Loss: 0.6953\n",
            "Epoch 4/4 - Batch 18350/50000 - Loss: 1.0113\n",
            "Epoch 4/4 - Batch 18400/50000 - Loss: 1.0882\n",
            "Epoch 4/4 - Batch 18450/50000 - Loss: 0.7732\n",
            "Epoch 4/4 - Batch 18500/50000 - Loss: 1.9363\n",
            "Epoch 4/4 - Batch 18550/50000 - Loss: 1.7042\n",
            "Epoch 4/4 - Batch 18600/50000 - Loss: 1.2596\n",
            "Epoch 4/4 - Batch 18650/50000 - Loss: 1.5950\n",
            "Epoch 4/4 - Batch 18700/50000 - Loss: 1.1878\n",
            "Epoch 4/4 - Batch 18750/50000 - Loss: 1.6890\n",
            "Epoch 4/4 - Batch 18800/50000 - Loss: 1.0351\n",
            "Epoch 4/4 - Batch 18850/50000 - Loss: 1.2468\n",
            "Epoch 4/4 - Batch 18900/50000 - Loss: 1.3819\n",
            "Epoch 4/4 - Batch 18950/50000 - Loss: 1.4288\n",
            "Epoch 4/4 - Batch 19000/50000 - Loss: 1.7548\n",
            "Epoch 4/4 - Batch 19050/50000 - Loss: 0.7621\n",
            "Epoch 4/4 - Batch 19100/50000 - Loss: 1.2891\n",
            "Epoch 4/4 - Batch 19150/50000 - Loss: 0.9878\n",
            "Epoch 4/4 - Batch 19200/50000 - Loss: 0.8607\n",
            "Epoch 4/4 - Batch 19250/50000 - Loss: 0.4910\n",
            "Epoch 4/4 - Batch 19300/50000 - Loss: 1.4792\n",
            "Epoch 4/4 - Batch 19350/50000 - Loss: 1.5311\n",
            "Epoch 4/4 - Batch 19400/50000 - Loss: 0.8971\n",
            "Epoch 4/4 - Batch 19450/50000 - Loss: 1.0858\n",
            "Epoch 4/4 - Batch 19500/50000 - Loss: 1.3868\n",
            "Epoch 4/4 - Batch 19550/50000 - Loss: 0.6917\n",
            "Epoch 4/4 - Batch 19600/50000 - Loss: 1.0868\n",
            "Epoch 4/4 - Batch 19650/50000 - Loss: 1.1638\n",
            "Epoch 4/4 - Batch 19700/50000 - Loss: 0.6567\n",
            "Epoch 4/4 - Batch 19750/50000 - Loss: 1.2023\n",
            "Epoch 4/4 - Batch 19800/50000 - Loss: 1.4539\n",
            "Epoch 4/4 - Batch 19850/50000 - Loss: 0.9246\n",
            "Epoch 4/4 - Batch 19900/50000 - Loss: 1.2557\n",
            "Epoch 4/4 - Batch 19950/50000 - Loss: 1.0465\n",
            "Epoch 4/4 - Batch 20000/50000 - Loss: 1.6553\n",
            "Epoch 4/4 - Batch 20050/50000 - Loss: 1.3338\n",
            "Epoch 4/4 - Batch 20100/50000 - Loss: 1.3475\n",
            "Epoch 4/4 - Batch 20150/50000 - Loss: 1.4609\n",
            "Epoch 4/4 - Batch 20200/50000 - Loss: 0.8171\n",
            "Epoch 4/4 - Batch 20250/50000 - Loss: 1.0699\n",
            "Epoch 4/4 - Batch 20300/50000 - Loss: 0.8950\n",
            "Epoch 4/4 - Batch 20350/50000 - Loss: 1.7179\n",
            "Epoch 4/4 - Batch 20400/50000 - Loss: 0.9208\n",
            "Epoch 4/4 - Batch 20450/50000 - Loss: 1.6103\n",
            "Epoch 4/4 - Batch 20500/50000 - Loss: 1.4984\n",
            "Epoch 4/4 - Batch 20550/50000 - Loss: 0.9726\n",
            "Epoch 4/4 - Batch 20600/50000 - Loss: 1.7621\n",
            "Epoch 4/4 - Batch 20650/50000 - Loss: 1.2132\n",
            "Epoch 4/4 - Batch 20700/50000 - Loss: 1.1829\n",
            "Epoch 4/4 - Batch 20750/50000 - Loss: 1.1279\n",
            "Epoch 4/4 - Batch 20800/50000 - Loss: 0.8788\n",
            "Epoch 4/4 - Batch 20850/50000 - Loss: 1.0644\n",
            "Epoch 4/4 - Batch 20900/50000 - Loss: 1.9618\n",
            "Epoch 4/4 - Batch 20950/50000 - Loss: 1.1058\n",
            "Epoch 4/4 - Batch 21000/50000 - Loss: 1.4677\n",
            "Epoch 4/4 - Batch 21050/50000 - Loss: 0.7650\n",
            "Epoch 4/4 - Batch 21100/50000 - Loss: 0.7945\n",
            "Epoch 4/4 - Batch 21150/50000 - Loss: 0.8727\n",
            "Epoch 4/4 - Batch 21200/50000 - Loss: 1.1628\n",
            "Epoch 4/4 - Batch 21250/50000 - Loss: 0.7161\n",
            "Epoch 4/4 - Batch 21300/50000 - Loss: 1.3847\n",
            "Epoch 4/4 - Batch 21350/50000 - Loss: 1.1505\n",
            "Epoch 4/4 - Batch 21400/50000 - Loss: 1.8479\n",
            "Epoch 4/4 - Batch 21450/50000 - Loss: 1.4456\n",
            "Epoch 4/4 - Batch 21500/50000 - Loss: 0.9243\n",
            "Epoch 4/4 - Batch 21550/50000 - Loss: 1.7581\n",
            "Epoch 4/4 - Batch 21600/50000 - Loss: 0.7472\n",
            "Epoch 4/4 - Batch 21650/50000 - Loss: 1.1165\n",
            "Epoch 4/4 - Batch 21700/50000 - Loss: 1.1488\n",
            "Epoch 4/4 - Batch 21750/50000 - Loss: 0.8488\n",
            "Epoch 4/4 - Batch 21800/50000 - Loss: 1.9376\n",
            "Epoch 4/4 - Batch 21850/50000 - Loss: 1.3285\n",
            "Epoch 4/4 - Batch 21900/50000 - Loss: 0.5807\n",
            "Epoch 4/4 - Batch 21950/50000 - Loss: 0.9140\n",
            "Epoch 4/4 - Batch 22000/50000 - Loss: 1.2588\n",
            "Epoch 4/4 - Batch 22050/50000 - Loss: 1.6357\n",
            "Epoch 4/4 - Batch 22100/50000 - Loss: 1.4624\n",
            "Epoch 4/4 - Batch 22150/50000 - Loss: 0.9838\n",
            "Epoch 4/4 - Batch 22200/50000 - Loss: 0.9684\n",
            "Epoch 4/4 - Batch 22250/50000 - Loss: 1.1211\n",
            "Epoch 4/4 - Batch 22300/50000 - Loss: 0.7025\n",
            "Epoch 4/4 - Batch 22350/50000 - Loss: 1.1989\n",
            "Epoch 4/4 - Batch 22400/50000 - Loss: 1.3434\n",
            "Epoch 4/4 - Batch 22450/50000 - Loss: 1.5184\n",
            "Epoch 4/4 - Batch 22500/50000 - Loss: 1.1581\n",
            "Epoch 4/4 - Batch 22550/50000 - Loss: 0.8054\n",
            "Epoch 4/4 - Batch 22600/50000 - Loss: 1.5011\n",
            "Epoch 4/4 - Batch 22650/50000 - Loss: 1.7345\n",
            "Epoch 4/4 - Batch 22700/50000 - Loss: 1.5792\n",
            "Epoch 4/4 - Batch 22750/50000 - Loss: 1.1646\n",
            "Epoch 4/4 - Batch 22800/50000 - Loss: 1.5830\n",
            "Epoch 4/4 - Batch 22850/50000 - Loss: 0.8633\n",
            "Epoch 4/4 - Batch 22900/50000 - Loss: 1.4816\n",
            "Epoch 4/4 - Batch 22950/50000 - Loss: 0.7680\n",
            "Epoch 4/4 - Batch 23000/50000 - Loss: 1.6841\n",
            "Epoch 4/4 - Batch 23050/50000 - Loss: 0.5902\n",
            "Epoch 4/4 - Batch 23100/50000 - Loss: 0.4753\n",
            "Epoch 4/4 - Batch 23150/50000 - Loss: 0.8417\n",
            "Epoch 4/4 - Batch 23200/50000 - Loss: 1.3022\n",
            "Epoch 4/4 - Batch 23250/50000 - Loss: 1.9030\n",
            "Epoch 4/4 - Batch 23300/50000 - Loss: 1.5056\n",
            "Epoch 4/4 - Batch 23350/50000 - Loss: 0.8053\n",
            "Epoch 4/4 - Batch 23400/50000 - Loss: 1.2054\n",
            "Epoch 4/4 - Batch 23450/50000 - Loss: 1.1497\n",
            "Epoch 4/4 - Batch 23500/50000 - Loss: 1.2778\n",
            "Epoch 4/4 - Batch 23550/50000 - Loss: 1.1823\n",
            "Epoch 4/4 - Batch 23600/50000 - Loss: 1.5976\n",
            "Epoch 4/4 - Batch 23650/50000 - Loss: 1.5846\n",
            "Epoch 4/4 - Batch 23700/50000 - Loss: 1.2906\n",
            "Epoch 4/4 - Batch 23750/50000 - Loss: 0.9910\n",
            "Epoch 4/4 - Batch 23800/50000 - Loss: 1.0349\n",
            "Epoch 4/4 - Batch 23850/50000 - Loss: 1.4040\n",
            "Epoch 4/4 - Batch 23900/50000 - Loss: 0.9481\n",
            "Epoch 4/4 - Batch 23950/50000 - Loss: 0.4847\n",
            "Epoch 4/4 - Batch 24000/50000 - Loss: 1.3529\n",
            "Epoch 4/4 - Batch 24050/50000 - Loss: 1.0331\n",
            "Epoch 4/4 - Batch 24100/50000 - Loss: 1.1429\n",
            "Epoch 4/4 - Batch 24150/50000 - Loss: 1.1009\n",
            "Epoch 4/4 - Batch 24200/50000 - Loss: 1.7137\n",
            "Epoch 4/4 - Batch 24250/50000 - Loss: 1.0762\n",
            "Epoch 4/4 - Batch 24300/50000 - Loss: 1.6493\n",
            "Epoch 4/4 - Batch 24350/50000 - Loss: 1.3704\n",
            "Epoch 4/4 - Batch 24400/50000 - Loss: 1.8905\n",
            "Epoch 4/4 - Batch 24450/50000 - Loss: 1.7541\n",
            "Epoch 4/4 - Batch 24500/50000 - Loss: 0.8172\n",
            "Epoch 4/4 - Batch 24550/50000 - Loss: 1.3207\n",
            "Epoch 4/4 - Batch 24600/50000 - Loss: 1.3061\n",
            "Epoch 4/4 - Batch 24650/50000 - Loss: 1.3096\n",
            "Epoch 4/4 - Batch 24700/50000 - Loss: 1.1030\n",
            "Epoch 4/4 - Batch 24750/50000 - Loss: 1.4275\n",
            "Epoch 4/4 - Batch 24800/50000 - Loss: 0.9527\n",
            "Epoch 4/4 - Batch 24850/50000 - Loss: 1.0208\n",
            "Epoch 4/4 - Batch 24900/50000 - Loss: 1.1908\n",
            "Epoch 4/4 - Batch 24950/50000 - Loss: 0.8362\n",
            "Epoch 4/4 - Batch 25000/50000 - Loss: 0.4710\n",
            "Epoch 4/4 - Batch 25050/50000 - Loss: 1.4503\n",
            "Epoch 4/4 - Batch 25100/50000 - Loss: 1.0254\n",
            "Epoch 4/4 - Batch 25150/50000 - Loss: 1.7232\n",
            "Epoch 4/4 - Batch 25200/50000 - Loss: 1.4674\n",
            "Epoch 4/4 - Batch 25250/50000 - Loss: 0.6528\n",
            "Epoch 4/4 - Batch 25300/50000 - Loss: 1.3821\n",
            "Epoch 4/4 - Batch 25350/50000 - Loss: 1.2791\n",
            "Epoch 4/4 - Batch 25400/50000 - Loss: 0.7618\n",
            "Epoch 4/4 - Batch 25450/50000 - Loss: 1.3452\n",
            "Epoch 4/4 - Batch 25500/50000 - Loss: 1.0587\n",
            "Epoch 4/4 - Batch 25550/50000 - Loss: 1.1835\n",
            "Epoch 4/4 - Batch 25600/50000 - Loss: 0.8841\n",
            "Epoch 4/4 - Batch 25650/50000 - Loss: 0.8986\n",
            "Epoch 4/4 - Batch 25700/50000 - Loss: 1.2914\n",
            "Epoch 4/4 - Batch 25750/50000 - Loss: 1.5157\n",
            "Epoch 4/4 - Batch 25800/50000 - Loss: 1.3507\n",
            "Epoch 4/4 - Batch 25850/50000 - Loss: 1.7138\n",
            "Epoch 4/4 - Batch 25900/50000 - Loss: 1.9743\n",
            "Epoch 4/4 - Batch 25950/50000 - Loss: 1.2740\n",
            "Epoch 4/4 - Batch 26000/50000 - Loss: 1.9520\n",
            "Epoch 4/4 - Batch 26050/50000 - Loss: 1.1233\n",
            "Epoch 4/4 - Batch 26100/50000 - Loss: 1.5917\n",
            "Epoch 4/4 - Batch 26150/50000 - Loss: 1.2378\n",
            "Epoch 4/4 - Batch 26200/50000 - Loss: 1.7573\n",
            "Epoch 4/4 - Batch 26250/50000 - Loss: 0.4930\n",
            "Epoch 4/4 - Batch 26300/50000 - Loss: 1.6445\n",
            "Epoch 4/4 - Batch 26350/50000 - Loss: 1.4780\n",
            "Epoch 4/4 - Batch 26400/50000 - Loss: 1.6889\n",
            "Epoch 4/4 - Batch 26450/50000 - Loss: 1.8858\n",
            "Epoch 4/4 - Batch 26500/50000 - Loss: 1.2618\n",
            "Epoch 4/4 - Batch 26550/50000 - Loss: 0.7568\n",
            "Epoch 4/4 - Batch 26600/50000 - Loss: 1.2494\n",
            "Epoch 4/4 - Batch 26650/50000 - Loss: 0.8436\n",
            "Epoch 4/4 - Batch 26700/50000 - Loss: 1.2939\n",
            "Epoch 4/4 - Batch 26750/50000 - Loss: 1.1492\n",
            "Epoch 4/4 - Batch 26800/50000 - Loss: 1.7527\n",
            "Epoch 4/4 - Batch 26850/50000 - Loss: 0.8962\n",
            "Epoch 4/4 - Batch 26900/50000 - Loss: 0.7257\n",
            "Epoch 4/4 - Batch 26950/50000 - Loss: 1.1952\n",
            "Epoch 4/4 - Batch 27000/50000 - Loss: 1.5079\n",
            "Epoch 4/4 - Batch 27050/50000 - Loss: 1.9169\n",
            "Epoch 4/4 - Batch 27100/50000 - Loss: 1.6062\n",
            "Epoch 4/4 - Batch 27150/50000 - Loss: 0.4366\n",
            "Epoch 4/4 - Batch 27200/50000 - Loss: 1.3052\n",
            "Epoch 4/4 - Batch 27250/50000 - Loss: 1.2816\n",
            "Epoch 4/4 - Batch 27300/50000 - Loss: 0.5919\n",
            "Epoch 4/4 - Batch 27350/50000 - Loss: 1.3475\n",
            "Epoch 4/4 - Batch 27400/50000 - Loss: 1.1342\n",
            "Epoch 4/4 - Batch 27450/50000 - Loss: 1.2715\n",
            "Epoch 4/4 - Batch 27500/50000 - Loss: 1.2353\n",
            "Epoch 4/4 - Batch 27550/50000 - Loss: 0.7054\n",
            "Epoch 4/4 - Batch 27600/50000 - Loss: 1.4366\n",
            "Epoch 4/4 - Batch 27650/50000 - Loss: 1.2177\n",
            "Epoch 4/4 - Batch 27700/50000 - Loss: 0.8076\n",
            "Epoch 4/4 - Batch 27750/50000 - Loss: 1.0682\n",
            "Epoch 4/4 - Batch 27800/50000 - Loss: 1.2654\n",
            "Epoch 4/4 - Batch 27850/50000 - Loss: 1.5545\n",
            "Epoch 4/4 - Batch 27900/50000 - Loss: 1.5108\n",
            "Epoch 4/4 - Batch 27950/50000 - Loss: 1.0503\n",
            "Epoch 4/4 - Batch 28000/50000 - Loss: 1.0032\n",
            "Epoch 4/4 - Batch 28050/50000 - Loss: 1.3340\n",
            "Epoch 4/4 - Batch 28100/50000 - Loss: 1.7853\n",
            "Epoch 4/4 - Batch 28150/50000 - Loss: 1.3202\n",
            "Epoch 4/4 - Batch 28200/50000 - Loss: 1.7052\n",
            "Epoch 4/4 - Batch 28250/50000 - Loss: 1.7689\n",
            "Epoch 4/4 - Batch 28300/50000 - Loss: 1.7327\n",
            "Epoch 4/4 - Batch 28350/50000 - Loss: 0.7466\n",
            "Epoch 4/4 - Batch 28400/50000 - Loss: 1.5853\n",
            "Epoch 4/4 - Batch 28450/50000 - Loss: 0.5808\n",
            "Epoch 4/4 - Batch 28500/50000 - Loss: 1.4863\n",
            "Epoch 4/4 - Batch 28550/50000 - Loss: 0.9732\n",
            "Epoch 4/4 - Batch 28600/50000 - Loss: 1.4041\n",
            "Epoch 4/4 - Batch 28650/50000 - Loss: 1.1866\n",
            "Epoch 4/4 - Batch 28700/50000 - Loss: 1.0724\n",
            "Epoch 4/4 - Batch 28750/50000 - Loss: 1.0197\n",
            "Epoch 4/4 - Batch 28800/50000 - Loss: 1.3359\n",
            "Epoch 4/4 - Batch 28850/50000 - Loss: 1.1037\n",
            "Epoch 4/4 - Batch 28900/50000 - Loss: 1.1914\n",
            "Epoch 4/4 - Batch 28950/50000 - Loss: 0.7276\n",
            "Epoch 4/4 - Batch 29000/50000 - Loss: 1.3223\n",
            "Epoch 4/4 - Batch 29050/50000 - Loss: 1.4241\n",
            "Epoch 4/4 - Batch 29100/50000 - Loss: 0.9708\n",
            "Epoch 4/4 - Batch 29150/50000 - Loss: 1.1900\n",
            "Epoch 4/4 - Batch 29200/50000 - Loss: 1.3998\n",
            "Epoch 4/4 - Batch 29250/50000 - Loss: 0.9269\n",
            "Epoch 4/4 - Batch 29300/50000 - Loss: 0.7247\n",
            "Epoch 4/4 - Batch 29350/50000 - Loss: 1.4724\n",
            "Epoch 4/4 - Batch 29400/50000 - Loss: 2.1870\n",
            "Epoch 4/4 - Batch 29450/50000 - Loss: 1.0937\n",
            "Epoch 4/4 - Batch 29500/50000 - Loss: 1.3262\n",
            "Epoch 4/4 - Batch 29550/50000 - Loss: 0.9433\n",
            "Epoch 4/4 - Batch 29600/50000 - Loss: 1.1935\n",
            "Epoch 4/4 - Batch 29650/50000 - Loss: 1.8785\n",
            "Epoch 4/4 - Batch 29700/50000 - Loss: 1.8294\n",
            "Epoch 4/4 - Batch 29750/50000 - Loss: 1.2109\n",
            "Epoch 4/4 - Batch 29800/50000 - Loss: 1.0633\n",
            "Epoch 4/4 - Batch 29850/50000 - Loss: 1.5381\n",
            "Epoch 4/4 - Batch 29900/50000 - Loss: 1.4366\n",
            "Epoch 4/4 - Batch 29950/50000 - Loss: 1.4310\n",
            "Epoch 4/4 - Batch 30000/50000 - Loss: 1.7727\n",
            "Epoch 4/4 - Batch 30050/50000 - Loss: 1.3461\n",
            "Epoch 4/4 - Batch 30100/50000 - Loss: 0.9823\n",
            "Epoch 4/4 - Batch 30150/50000 - Loss: 1.0223\n",
            "Epoch 4/4 - Batch 30200/50000 - Loss: 1.0849\n",
            "Epoch 4/4 - Batch 30250/50000 - Loss: 1.3080\n",
            "Epoch 4/4 - Batch 30300/50000 - Loss: 1.6904\n",
            "Epoch 4/4 - Batch 30350/50000 - Loss: 1.3805\n",
            "Epoch 4/4 - Batch 30400/50000 - Loss: 0.6589\n",
            "Epoch 4/4 - Batch 30450/50000 - Loss: 1.3789\n",
            "Epoch 4/4 - Batch 30500/50000 - Loss: 1.0968\n",
            "Epoch 4/4 - Batch 30550/50000 - Loss: 1.6782\n",
            "Epoch 4/4 - Batch 30600/50000 - Loss: 1.8097\n",
            "Epoch 4/4 - Batch 30650/50000 - Loss: 1.6010\n",
            "Epoch 4/4 - Batch 30700/50000 - Loss: 1.5638\n",
            "Epoch 4/4 - Batch 30750/50000 - Loss: 0.7634\n",
            "Epoch 4/4 - Batch 30800/50000 - Loss: 1.5740\n",
            "Epoch 4/4 - Batch 30850/50000 - Loss: 1.2875\n",
            "Epoch 4/4 - Batch 30900/50000 - Loss: 1.8376\n",
            "Epoch 4/4 - Batch 30950/50000 - Loss: 1.0691\n",
            "Epoch 4/4 - Batch 31000/50000 - Loss: 1.0698\n",
            "Epoch 4/4 - Batch 31050/50000 - Loss: 0.6733\n",
            "Epoch 4/4 - Batch 31100/50000 - Loss: 1.4379\n",
            "Epoch 4/4 - Batch 31150/50000 - Loss: 0.5518\n",
            "Epoch 4/4 - Batch 31200/50000 - Loss: 1.3211\n",
            "Epoch 4/4 - Batch 31250/50000 - Loss: 1.3005\n",
            "Epoch 4/4 - Batch 31300/50000 - Loss: 0.4355\n",
            "Epoch 4/4 - Batch 31350/50000 - Loss: 1.8622\n",
            "Epoch 4/4 - Batch 31400/50000 - Loss: 1.3438\n",
            "Epoch 4/4 - Batch 31450/50000 - Loss: 1.3127\n",
            "Epoch 4/4 - Batch 31500/50000 - Loss: 1.7796\n",
            "Epoch 4/4 - Batch 31550/50000 - Loss: 1.2612\n",
            "Epoch 4/4 - Batch 31600/50000 - Loss: 0.6745\n",
            "Epoch 4/4 - Batch 31650/50000 - Loss: 1.0346\n",
            "Epoch 4/4 - Batch 31700/50000 - Loss: 1.7033\n",
            "Epoch 4/4 - Batch 31750/50000 - Loss: 1.0029\n",
            "Epoch 4/4 - Batch 31800/50000 - Loss: 1.7060\n",
            "Epoch 4/4 - Batch 31850/50000 - Loss: 1.2512\n",
            "Epoch 4/4 - Batch 31900/50000 - Loss: 1.8706\n",
            "Epoch 4/4 - Batch 31950/50000 - Loss: 1.5131\n",
            "Epoch 4/4 - Batch 32000/50000 - Loss: 1.8538\n",
            "Epoch 4/4 - Batch 32050/50000 - Loss: 1.2630\n",
            "Epoch 4/4 - Batch 32100/50000 - Loss: 1.3793\n",
            "Epoch 4/4 - Batch 32150/50000 - Loss: 1.3083\n",
            "Epoch 4/4 - Batch 32200/50000 - Loss: 1.2644\n",
            "Epoch 4/4 - Batch 32250/50000 - Loss: 0.6457\n",
            "Epoch 4/4 - Batch 32300/50000 - Loss: 0.7676\n",
            "Epoch 4/4 - Batch 32350/50000 - Loss: 0.5846\n",
            "Epoch 4/4 - Batch 32400/50000 - Loss: 1.1954\n",
            "Epoch 4/4 - Batch 32450/50000 - Loss: 0.9374\n",
            "Epoch 4/4 - Batch 32500/50000 - Loss: 1.6468\n",
            "Epoch 4/4 - Batch 32550/50000 - Loss: 1.9699\n",
            "Epoch 4/4 - Batch 32600/50000 - Loss: 0.9101\n",
            "Epoch 4/4 - Batch 32650/50000 - Loss: 1.5474\n",
            "Epoch 4/4 - Batch 32700/50000 - Loss: 1.3834\n",
            "Epoch 4/4 - Batch 32750/50000 - Loss: 0.9921\n",
            "Epoch 4/4 - Batch 32800/50000 - Loss: 1.2922\n",
            "Epoch 4/4 - Batch 32850/50000 - Loss: 1.4783\n",
            "Epoch 4/4 - Batch 32900/50000 - Loss: 0.7430\n",
            "Epoch 4/4 - Batch 32950/50000 - Loss: 0.6046\n",
            "Epoch 4/4 - Batch 33000/50000 - Loss: 0.8606\n",
            "Epoch 4/4 - Batch 33050/50000 - Loss: 1.4394\n",
            "Epoch 4/4 - Batch 33100/50000 - Loss: 1.3369\n",
            "Epoch 4/4 - Batch 33150/50000 - Loss: 0.7961\n",
            "Epoch 4/4 - Batch 33200/50000 - Loss: 1.2973\n",
            "Epoch 4/4 - Batch 33250/50000 - Loss: 1.4235\n",
            "Epoch 4/4 - Batch 33300/50000 - Loss: 1.1913\n",
            "Epoch 4/4 - Batch 33350/50000 - Loss: 1.2189\n",
            "Epoch 4/4 - Batch 33400/50000 - Loss: 1.4568\n",
            "Epoch 4/4 - Batch 33450/50000 - Loss: 0.9356\n",
            "Epoch 4/4 - Batch 33500/50000 - Loss: 1.0335\n",
            "Epoch 4/4 - Batch 33550/50000 - Loss: 1.3077\n",
            "Epoch 4/4 - Batch 33600/50000 - Loss: 0.3964\n",
            "Epoch 4/4 - Batch 33650/50000 - Loss: 0.9978\n",
            "Epoch 4/4 - Batch 33700/50000 - Loss: 1.4908\n",
            "Epoch 4/4 - Batch 33750/50000 - Loss: 1.0260\n",
            "Epoch 4/4 - Batch 33800/50000 - Loss: 1.0689\n",
            "Epoch 4/4 - Batch 33850/50000 - Loss: 1.5749\n",
            "Epoch 4/4 - Batch 33900/50000 - Loss: 1.3543\n",
            "Epoch 4/4 - Batch 33950/50000 - Loss: 1.3232\n",
            "Epoch 4/4 - Batch 34000/50000 - Loss: 0.9209\n",
            "Epoch 4/4 - Batch 34050/50000 - Loss: 0.5816\n",
            "Epoch 4/4 - Batch 34100/50000 - Loss: 1.1143\n",
            "Epoch 4/4 - Batch 34150/50000 - Loss: 1.4741\n",
            "Epoch 4/4 - Batch 34200/50000 - Loss: 0.4519\n",
            "Epoch 4/4 - Batch 34250/50000 - Loss: 1.0439\n",
            "Epoch 4/4 - Batch 34300/50000 - Loss: 1.8414\n",
            "Epoch 4/4 - Batch 34350/50000 - Loss: 0.9996\n",
            "Epoch 4/4 - Batch 34400/50000 - Loss: 0.7623\n",
            "Epoch 4/4 - Batch 34450/50000 - Loss: 1.0667\n",
            "Epoch 4/4 - Batch 34500/50000 - Loss: 1.8307\n",
            "Epoch 4/4 - Batch 34550/50000 - Loss: 1.0466\n",
            "Epoch 4/4 - Batch 34600/50000 - Loss: 1.0432\n",
            "Epoch 4/4 - Batch 34650/50000 - Loss: 0.2742\n",
            "Epoch 4/4 - Batch 34700/50000 - Loss: 1.0117\n",
            "Epoch 4/4 - Batch 34750/50000 - Loss: 1.7671\n",
            "Epoch 4/4 - Batch 34800/50000 - Loss: 1.4299\n",
            "Epoch 4/4 - Batch 34850/50000 - Loss: 1.0311\n",
            "Epoch 4/4 - Batch 34900/50000 - Loss: 0.4650\n",
            "Epoch 4/4 - Batch 34950/50000 - Loss: 1.6418\n",
            "Epoch 4/4 - Batch 35000/50000 - Loss: 1.3366\n",
            "Epoch 4/4 - Batch 35050/50000 - Loss: 0.8957\n",
            "Epoch 4/4 - Batch 35100/50000 - Loss: 1.7423\n",
            "Epoch 4/4 - Batch 35150/50000 - Loss: 0.8794\n",
            "Epoch 4/4 - Batch 35200/50000 - Loss: 0.7385\n",
            "Epoch 4/4 - Batch 35250/50000 - Loss: 0.4277\n",
            "Epoch 4/4 - Batch 35300/50000 - Loss: 0.5874\n",
            "Epoch 4/4 - Batch 35350/50000 - Loss: 1.3108\n",
            "Epoch 4/4 - Batch 35400/50000 - Loss: 1.2169\n",
            "Epoch 4/4 - Batch 35450/50000 - Loss: 0.9208\n",
            "Epoch 4/4 - Batch 35500/50000 - Loss: 0.8926\n",
            "Epoch 4/4 - Batch 35550/50000 - Loss: 0.8822\n",
            "Epoch 4/4 - Batch 35600/50000 - Loss: 0.7821\n",
            "Epoch 4/4 - Batch 35650/50000 - Loss: 0.9413\n",
            "Epoch 4/4 - Batch 35700/50000 - Loss: 1.5447\n",
            "Epoch 4/4 - Batch 35750/50000 - Loss: 1.0071\n",
            "Epoch 4/4 - Batch 35800/50000 - Loss: 1.5559\n",
            "Epoch 4/4 - Batch 35850/50000 - Loss: 1.0330\n",
            "Epoch 4/4 - Batch 35900/50000 - Loss: 1.1564\n",
            "Epoch 4/4 - Batch 35950/50000 - Loss: 1.3265\n",
            "Epoch 4/4 - Batch 36000/50000 - Loss: 0.9531\n",
            "Epoch 4/4 - Batch 36050/50000 - Loss: 1.9515\n",
            "Epoch 4/4 - Batch 36100/50000 - Loss: 1.5612\n",
            "Epoch 4/4 - Batch 36150/50000 - Loss: 1.1444\n",
            "Epoch 4/4 - Batch 36200/50000 - Loss: 2.1710\n",
            "Epoch 4/4 - Batch 36250/50000 - Loss: 0.8451\n",
            "Epoch 4/4 - Batch 36300/50000 - Loss: 1.1161\n",
            "Epoch 4/4 - Batch 36350/50000 - Loss: 0.9873\n",
            "Epoch 4/4 - Batch 36400/50000 - Loss: 1.5555\n",
            "Epoch 4/4 - Batch 36450/50000 - Loss: 1.1688\n",
            "Epoch 4/4 - Batch 36500/50000 - Loss: 0.9789\n",
            "Epoch 4/4 - Batch 36550/50000 - Loss: 1.8128\n",
            "Epoch 4/4 - Batch 36600/50000 - Loss: 1.4687\n",
            "Epoch 4/4 - Batch 36650/50000 - Loss: 1.5510\n",
            "Epoch 4/4 - Batch 36700/50000 - Loss: 1.0194\n",
            "Epoch 4/4 - Batch 36750/50000 - Loss: 1.1403\n",
            "Epoch 4/4 - Batch 36800/50000 - Loss: 1.4140\n",
            "Epoch 4/4 - Batch 36850/50000 - Loss: 1.3459\n",
            "Epoch 4/4 - Batch 36900/50000 - Loss: 1.8366\n",
            "Epoch 4/4 - Batch 36950/50000 - Loss: 0.5998\n",
            "Epoch 4/4 - Batch 37000/50000 - Loss: 0.9049\n",
            "Epoch 4/4 - Batch 37050/50000 - Loss: 1.4445\n",
            "Epoch 4/4 - Batch 37100/50000 - Loss: 1.1687\n",
            "Epoch 4/4 - Batch 37150/50000 - Loss: 1.3804\n",
            "Epoch 4/4 - Batch 37200/50000 - Loss: 1.3224\n",
            "Epoch 4/4 - Batch 37250/50000 - Loss: 0.7017\n",
            "Epoch 4/4 - Batch 37300/50000 - Loss: 1.3727\n",
            "Epoch 4/4 - Batch 37350/50000 - Loss: 0.9998\n",
            "Epoch 4/4 - Batch 37400/50000 - Loss: 0.8691\n",
            "Epoch 4/4 - Batch 37450/50000 - Loss: 1.4794\n",
            "Epoch 4/4 - Batch 37500/50000 - Loss: 1.7275\n",
            "Epoch 4/4 - Batch 37550/50000 - Loss: 1.4785\n",
            "Epoch 4/4 - Batch 37600/50000 - Loss: 1.3202\n",
            "Epoch 4/4 - Batch 37650/50000 - Loss: 1.4132\n",
            "Epoch 4/4 - Batch 37700/50000 - Loss: 1.1483\n",
            "Epoch 4/4 - Batch 37750/50000 - Loss: 1.7204\n",
            "Epoch 4/4 - Batch 37800/50000 - Loss: 1.2170\n",
            "Epoch 4/4 - Batch 37850/50000 - Loss: 1.0032\n",
            "Epoch 4/4 - Batch 37900/50000 - Loss: 0.8387\n",
            "Epoch 4/4 - Batch 37950/50000 - Loss: 1.2481\n",
            "Epoch 4/4 - Batch 38000/50000 - Loss: 1.1872\n",
            "Epoch 4/4 - Batch 38050/50000 - Loss: 0.5953\n",
            "Epoch 4/4 - Batch 38100/50000 - Loss: 0.9850\n",
            "Epoch 4/4 - Batch 38150/50000 - Loss: 2.0584\n",
            "Epoch 4/4 - Batch 38200/50000 - Loss: 1.1202\n",
            "Epoch 4/4 - Batch 38250/50000 - Loss: 1.0573\n",
            "Epoch 4/4 - Batch 38300/50000 - Loss: 1.5922\n",
            "Epoch 4/4 - Batch 38350/50000 - Loss: 1.6767\n",
            "Epoch 4/4 - Batch 38400/50000 - Loss: 1.0886\n",
            "Epoch 4/4 - Batch 38450/50000 - Loss: 0.8243\n",
            "Epoch 4/4 - Batch 38500/50000 - Loss: 0.3571\n",
            "Epoch 4/4 - Batch 38550/50000 - Loss: 0.9663\n",
            "Epoch 4/4 - Batch 38600/50000 - Loss: 0.6649\n",
            "Epoch 4/4 - Batch 38650/50000 - Loss: 0.9002\n",
            "Epoch 4/4 - Batch 38700/50000 - Loss: 0.6584\n",
            "Epoch 4/4 - Batch 38750/50000 - Loss: 1.6448\n",
            "Epoch 4/4 - Batch 38800/50000 - Loss: 1.0332\n",
            "Epoch 4/4 - Batch 38850/50000 - Loss: 1.1507\n",
            "Epoch 4/4 - Batch 38900/50000 - Loss: 1.0045\n",
            "Epoch 4/4 - Batch 38950/50000 - Loss: 1.4493\n",
            "Epoch 4/4 - Batch 39000/50000 - Loss: 1.4072\n",
            "Epoch 4/4 - Batch 39050/50000 - Loss: 1.3432\n",
            "Epoch 4/4 - Batch 39100/50000 - Loss: 1.0774\n",
            "Epoch 4/4 - Batch 39150/50000 - Loss: 1.2652\n",
            "Epoch 4/4 - Batch 39200/50000 - Loss: 1.3710\n",
            "Epoch 4/4 - Batch 39250/50000 - Loss: 0.4058\n",
            "Epoch 4/4 - Batch 39300/50000 - Loss: 1.5005\n",
            "Epoch 4/4 - Batch 39350/50000 - Loss: 0.6137\n",
            "Epoch 4/4 - Batch 39400/50000 - Loss: 0.8457\n",
            "Epoch 4/4 - Batch 39450/50000 - Loss: 0.7152\n",
            "Epoch 4/4 - Batch 39500/50000 - Loss: 0.7592\n",
            "Epoch 4/4 - Batch 39550/50000 - Loss: 0.9976\n",
            "Epoch 4/4 - Batch 39600/50000 - Loss: 0.9516\n",
            "Epoch 4/4 - Batch 39650/50000 - Loss: 1.2313\n",
            "Epoch 4/4 - Batch 39700/50000 - Loss: 1.0158\n",
            "Epoch 4/4 - Batch 39750/50000 - Loss: 0.8429\n",
            "Epoch 4/4 - Batch 39800/50000 - Loss: 1.4107\n",
            "Epoch 4/4 - Batch 39850/50000 - Loss: 0.9846\n",
            "Epoch 4/4 - Batch 39900/50000 - Loss: 1.1115\n",
            "Epoch 4/4 - Batch 39950/50000 - Loss: 0.9967\n",
            "Epoch 4/4 - Batch 40000/50000 - Loss: 1.3421\n",
            "Epoch 4/4 - Batch 40050/50000 - Loss: 1.4292\n",
            "Epoch 4/4 - Batch 40100/50000 - Loss: 1.8994\n",
            "Epoch 4/4 - Batch 40150/50000 - Loss: 1.2762\n",
            "Epoch 4/4 - Batch 40200/50000 - Loss: 1.1830\n",
            "Epoch 4/4 - Batch 40250/50000 - Loss: 1.4836\n",
            "Epoch 4/4 - Batch 40300/50000 - Loss: 1.1489\n",
            "Epoch 4/4 - Batch 40350/50000 - Loss: 1.0867\n",
            "Epoch 4/4 - Batch 40400/50000 - Loss: 1.1200\n",
            "Epoch 4/4 - Batch 40450/50000 - Loss: 1.2265\n",
            "Epoch 4/4 - Batch 40500/50000 - Loss: 1.4737\n",
            "Epoch 4/4 - Batch 40550/50000 - Loss: 1.2267\n",
            "Epoch 4/4 - Batch 40600/50000 - Loss: 1.3624\n",
            "Epoch 4/4 - Batch 40650/50000 - Loss: 0.7394\n",
            "Epoch 4/4 - Batch 40700/50000 - Loss: 1.6112\n",
            "Epoch 4/4 - Batch 40750/50000 - Loss: 1.6682\n",
            "Epoch 4/4 - Batch 40800/50000 - Loss: 1.7762\n",
            "Epoch 4/4 - Batch 40850/50000 - Loss: 0.8924\n",
            "Epoch 4/4 - Batch 40900/50000 - Loss: 1.4638\n",
            "Epoch 4/4 - Batch 40950/50000 - Loss: 1.1919\n",
            "Epoch 4/4 - Batch 41000/50000 - Loss: 1.3405\n",
            "Epoch 4/4 - Batch 41050/50000 - Loss: 1.0046\n",
            "Epoch 4/4 - Batch 41100/50000 - Loss: 0.7567\n",
            "Epoch 4/4 - Batch 41150/50000 - Loss: 1.2064\n",
            "Epoch 4/4 - Batch 41200/50000 - Loss: 1.0172\n",
            "Epoch 4/4 - Batch 41250/50000 - Loss: 1.3134\n",
            "Epoch 4/4 - Batch 41300/50000 - Loss: 1.6751\n",
            "Epoch 4/4 - Batch 41350/50000 - Loss: 1.5171\n",
            "Epoch 4/4 - Batch 41400/50000 - Loss: 0.5861\n",
            "Epoch 4/4 - Batch 41450/50000 - Loss: 1.2079\n",
            "Epoch 4/4 - Batch 41500/50000 - Loss: 0.6024\n",
            "Epoch 4/4 - Batch 41550/50000 - Loss: 1.3915\n",
            "Epoch 4/4 - Batch 41600/50000 - Loss: 0.5321\n",
            "Epoch 4/4 - Batch 41650/50000 - Loss: 1.3036\n",
            "Epoch 4/4 - Batch 41700/50000 - Loss: 1.6081\n",
            "Epoch 4/4 - Batch 41750/50000 - Loss: 1.0811\n",
            "Epoch 4/4 - Batch 41800/50000 - Loss: 0.6766\n",
            "Epoch 4/4 - Batch 41850/50000 - Loss: 1.5718\n",
            "Epoch 4/4 - Batch 41900/50000 - Loss: 0.9827\n",
            "Epoch 4/4 - Batch 41950/50000 - Loss: 1.1922\n",
            "Epoch 4/4 - Batch 42000/50000 - Loss: 0.8424\n",
            "Epoch 4/4 - Batch 42050/50000 - Loss: 1.4301\n",
            "Epoch 4/4 - Batch 42100/50000 - Loss: 1.3759\n",
            "Epoch 4/4 - Batch 42150/50000 - Loss: 1.4624\n",
            "Epoch 4/4 - Batch 42200/50000 - Loss: 0.6592\n",
            "Epoch 4/4 - Batch 42250/50000 - Loss: 1.2110\n",
            "Epoch 4/4 - Batch 42300/50000 - Loss: 1.2965\n",
            "Epoch 4/4 - Batch 42350/50000 - Loss: 0.5981\n",
            "Epoch 4/4 - Batch 42400/50000 - Loss: 1.2332\n",
            "Epoch 4/4 - Batch 42450/50000 - Loss: 1.2209\n",
            "Epoch 4/4 - Batch 42500/50000 - Loss: 0.9285\n",
            "Epoch 4/4 - Batch 42550/50000 - Loss: 1.8757\n",
            "Epoch 4/4 - Batch 42600/50000 - Loss: 1.7231\n",
            "Epoch 4/4 - Batch 42650/50000 - Loss: 0.7011\n",
            "Epoch 4/4 - Batch 42700/50000 - Loss: 0.9953\n",
            "Epoch 4/4 - Batch 42750/50000 - Loss: 0.8630\n",
            "Epoch 4/4 - Batch 42800/50000 - Loss: 1.7553\n",
            "Epoch 4/4 - Batch 42850/50000 - Loss: 1.2305\n",
            "Epoch 4/4 - Batch 42900/50000 - Loss: 2.0367\n",
            "Epoch 4/4 - Batch 42950/50000 - Loss: 1.1277\n",
            "Epoch 4/4 - Batch 43000/50000 - Loss: 0.9475\n",
            "Epoch 4/4 - Batch 43050/50000 - Loss: 1.3339\n",
            "Epoch 4/4 - Batch 43100/50000 - Loss: 1.1871\n",
            "Epoch 4/4 - Batch 43150/50000 - Loss: 0.8560\n",
            "Epoch 4/4 - Batch 43200/50000 - Loss: 1.1551\n",
            "Epoch 4/4 - Batch 43250/50000 - Loss: 0.7409\n",
            "Epoch 4/4 - Batch 43300/50000 - Loss: 1.1726\n",
            "Epoch 4/4 - Batch 43350/50000 - Loss: 1.2862\n",
            "Epoch 4/4 - Batch 43400/50000 - Loss: 1.3392\n",
            "Epoch 4/4 - Batch 43450/50000 - Loss: 0.7640\n",
            "Epoch 4/4 - Batch 43500/50000 - Loss: 0.3871\n",
            "Epoch 4/4 - Batch 43550/50000 - Loss: 0.6375\n",
            "Epoch 4/4 - Batch 43600/50000 - Loss: 1.6861\n",
            "Epoch 4/4 - Batch 43650/50000 - Loss: 1.0503\n",
            "Epoch 4/4 - Batch 43700/50000 - Loss: 0.9997\n",
            "Epoch 4/4 - Batch 43750/50000 - Loss: 1.5453\n",
            "Epoch 4/4 - Batch 43800/50000 - Loss: 1.4680\n",
            "Epoch 4/4 - Batch 43850/50000 - Loss: 1.3306\n",
            "Epoch 4/4 - Batch 43900/50000 - Loss: 1.4452\n",
            "Epoch 4/4 - Batch 43950/50000 - Loss: 2.2610\n",
            "Epoch 4/4 - Batch 44000/50000 - Loss: 1.3672\n",
            "Epoch 4/4 - Batch 44050/50000 - Loss: 1.1431\n",
            "Epoch 4/4 - Batch 44100/50000 - Loss: 1.3291\n",
            "Epoch 4/4 - Batch 44150/50000 - Loss: 1.4991\n",
            "Epoch 4/4 - Batch 44200/50000 - Loss: 1.6045\n",
            "Epoch 4/4 - Batch 44250/50000 - Loss: 1.7079\n",
            "Epoch 4/4 - Batch 44300/50000 - Loss: 0.7753\n",
            "Epoch 4/4 - Batch 44350/50000 - Loss: 0.7787\n",
            "Epoch 4/4 - Batch 44400/50000 - Loss: 0.7021\n",
            "Epoch 4/4 - Batch 44450/50000 - Loss: 0.7713\n",
            "Epoch 4/4 - Batch 44500/50000 - Loss: 1.8028\n",
            "Epoch 4/4 - Batch 44550/50000 - Loss: 0.5174\n",
            "Epoch 4/4 - Batch 44600/50000 - Loss: 0.5294\n",
            "Epoch 4/4 - Batch 44650/50000 - Loss: 0.9210\n",
            "Epoch 4/4 - Batch 44700/50000 - Loss: 1.4921\n",
            "Epoch 4/4 - Batch 44750/50000 - Loss: 0.8980\n",
            "Epoch 4/4 - Batch 44800/50000 - Loss: 0.5942\n",
            "Epoch 4/4 - Batch 44850/50000 - Loss: 1.0677\n",
            "Epoch 4/4 - Batch 44900/50000 - Loss: 1.1573\n",
            "Epoch 4/4 - Batch 44950/50000 - Loss: 1.2368\n",
            "Epoch 4/4 - Batch 45000/50000 - Loss: 1.0738\n",
            "Epoch 4/4 - Batch 45050/50000 - Loss: 1.4470\n",
            "Epoch 4/4 - Batch 45100/50000 - Loss: 0.9712\n",
            "Epoch 4/4 - Batch 45150/50000 - Loss: 1.3393\n",
            "Epoch 4/4 - Batch 45200/50000 - Loss: 0.9647\n",
            "Epoch 4/4 - Batch 45250/50000 - Loss: 0.7923\n",
            "Epoch 4/4 - Batch 45300/50000 - Loss: 0.5144\n",
            "Epoch 4/4 - Batch 45350/50000 - Loss: 1.8259\n",
            "Epoch 4/4 - Batch 45400/50000 - Loss: 1.3301\n",
            "Epoch 4/4 - Batch 45450/50000 - Loss: 1.2527\n",
            "Epoch 4/4 - Batch 45500/50000 - Loss: 1.0546\n",
            "Epoch 4/4 - Batch 45550/50000 - Loss: 1.0268\n",
            "Epoch 4/4 - Batch 45600/50000 - Loss: 1.2369\n",
            "Epoch 4/4 - Batch 45650/50000 - Loss: 1.4356\n",
            "Epoch 4/4 - Batch 45700/50000 - Loss: 1.2285\n",
            "Epoch 4/4 - Batch 45750/50000 - Loss: 0.9593\n",
            "Epoch 4/4 - Batch 45800/50000 - Loss: 1.2289\n",
            "Epoch 4/4 - Batch 45850/50000 - Loss: 1.5161\n",
            "Epoch 4/4 - Batch 45900/50000 - Loss: 1.2087\n",
            "Epoch 4/4 - Batch 45950/50000 - Loss: 1.2887\n",
            "Epoch 4/4 - Batch 46000/50000 - Loss: 1.0759\n",
            "Epoch 4/4 - Batch 46050/50000 - Loss: 0.9397\n",
            "Epoch 4/4 - Batch 46100/50000 - Loss: 1.6565\n",
            "Epoch 4/4 - Batch 46150/50000 - Loss: 1.5250\n",
            "Epoch 4/4 - Batch 46200/50000 - Loss: 0.9912\n",
            "Epoch 4/4 - Batch 46250/50000 - Loss: 1.0318\n",
            "Epoch 4/4 - Batch 46300/50000 - Loss: 1.5732\n",
            "Epoch 4/4 - Batch 46350/50000 - Loss: 1.1679\n",
            "Epoch 4/4 - Batch 46400/50000 - Loss: 1.1500\n",
            "Epoch 4/4 - Batch 46450/50000 - Loss: 0.8741\n",
            "Epoch 4/4 - Batch 46500/50000 - Loss: 0.8142\n",
            "Epoch 4/4 - Batch 46550/50000 - Loss: 1.1949\n",
            "Epoch 4/4 - Batch 46600/50000 - Loss: 0.9734\n",
            "Epoch 4/4 - Batch 46650/50000 - Loss: 1.6142\n",
            "Epoch 4/4 - Batch 46700/50000 - Loss: 0.7959\n",
            "Epoch 4/4 - Batch 46750/50000 - Loss: 1.0976\n",
            "Epoch 4/4 - Batch 46800/50000 - Loss: 1.0715\n",
            "Epoch 4/4 - Batch 46850/50000 - Loss: 0.4327\n",
            "Epoch 4/4 - Batch 46900/50000 - Loss: 1.5187\n",
            "Epoch 4/4 - Batch 46950/50000 - Loss: 1.4707\n",
            "Epoch 4/4 - Batch 47000/50000 - Loss: 1.8856\n",
            "Epoch 4/4 - Batch 47050/50000 - Loss: 0.7185\n",
            "Epoch 4/4 - Batch 47100/50000 - Loss: 1.6631\n",
            "Epoch 4/4 - Batch 47150/50000 - Loss: 1.2179\n",
            "Epoch 4/4 - Batch 47200/50000 - Loss: 1.5509\n",
            "Epoch 4/4 - Batch 47250/50000 - Loss: 1.3127\n",
            "Epoch 4/4 - Batch 47300/50000 - Loss: 0.8431\n",
            "Epoch 4/4 - Batch 47350/50000 - Loss: 1.3802\n",
            "Epoch 4/4 - Batch 47400/50000 - Loss: 1.2382\n",
            "Epoch 4/4 - Batch 47450/50000 - Loss: 1.4364\n",
            "Epoch 4/4 - Batch 47500/50000 - Loss: 1.7095\n",
            "Epoch 4/4 - Batch 47550/50000 - Loss: 0.9606\n",
            "Epoch 4/4 - Batch 47600/50000 - Loss: 1.6821\n",
            "Epoch 4/4 - Batch 47650/50000 - Loss: 0.9070\n",
            "Epoch 4/4 - Batch 47700/50000 - Loss: 0.8644\n",
            "Epoch 4/4 - Batch 47750/50000 - Loss: 1.2612\n",
            "Epoch 4/4 - Batch 47800/50000 - Loss: 1.5171\n",
            "Epoch 4/4 - Batch 47850/50000 - Loss: 0.6497\n",
            "Epoch 4/4 - Batch 47900/50000 - Loss: 0.5969\n",
            "Epoch 4/4 - Batch 47950/50000 - Loss: 1.4843\n",
            "Epoch 4/4 - Batch 48000/50000 - Loss: 1.4140\n",
            "Epoch 4/4 - Batch 48050/50000 - Loss: 1.3668\n",
            "Epoch 4/4 - Batch 48100/50000 - Loss: 1.4707\n",
            "Epoch 4/4 - Batch 48150/50000 - Loss: 2.1217\n",
            "Epoch 4/4 - Batch 48200/50000 - Loss: 1.0825\n",
            "Epoch 4/4 - Batch 48250/50000 - Loss: 0.5191\n",
            "Epoch 4/4 - Batch 48300/50000 - Loss: 1.8167\n",
            "Epoch 4/4 - Batch 48350/50000 - Loss: 1.2919\n",
            "Epoch 4/4 - Batch 48400/50000 - Loss: 1.8808\n",
            "Epoch 4/4 - Batch 48450/50000 - Loss: 1.1995\n",
            "Epoch 4/4 - Batch 48500/50000 - Loss: 0.8049\n",
            "Epoch 4/4 - Batch 48550/50000 - Loss: 1.6142\n",
            "Epoch 4/4 - Batch 48600/50000 - Loss: 1.4871\n",
            "Epoch 4/4 - Batch 48650/50000 - Loss: 1.4064\n",
            "Epoch 4/4 - Batch 48700/50000 - Loss: 0.8298\n",
            "Epoch 4/4 - Batch 48750/50000 - Loss: 1.7520\n",
            "Epoch 4/4 - Batch 48800/50000 - Loss: 1.6497\n",
            "Epoch 4/4 - Batch 48850/50000 - Loss: 0.7892\n",
            "Epoch 4/4 - Batch 48900/50000 - Loss: 1.8535\n",
            "Epoch 4/4 - Batch 48950/50000 - Loss: 1.2905\n",
            "Epoch 4/4 - Batch 49000/50000 - Loss: 0.7843\n",
            "Epoch 4/4 - Batch 49050/50000 - Loss: 1.0992\n",
            "Epoch 4/4 - Batch 49100/50000 - Loss: 0.5030\n",
            "Epoch 4/4 - Batch 49150/50000 - Loss: 1.3208\n",
            "Epoch 4/4 - Batch 49200/50000 - Loss: 1.4397\n",
            "Epoch 4/4 - Batch 49250/50000 - Loss: 0.8501\n",
            "Epoch 4/4 - Batch 49300/50000 - Loss: 1.3801\n",
            "Epoch 4/4 - Batch 49350/50000 - Loss: 1.6799\n",
            "Epoch 4/4 - Batch 49400/50000 - Loss: 0.8834\n",
            "Epoch 4/4 - Batch 49450/50000 - Loss: 0.9955\n",
            "Epoch 4/4 - Batch 49500/50000 - Loss: 0.7971\n",
            "Epoch 4/4 - Batch 49550/50000 - Loss: 1.2765\n",
            "Epoch 4/4 - Batch 49600/50000 - Loss: 1.2042\n",
            "Epoch 4/4 - Batch 49650/50000 - Loss: 1.0897\n",
            "Epoch 4/4 - Batch 49700/50000 - Loss: 0.6318\n",
            "Epoch 4/4 - Batch 49750/50000 - Loss: 1.2097\n",
            "Epoch 4/4 - Batch 49800/50000 - Loss: 1.2159\n",
            "Epoch 4/4 - Batch 49850/50000 - Loss: 0.6159\n",
            "Epoch 4/4 - Batch 49900/50000 - Loss: 1.8142\n",
            "Epoch 4/4 - Batch 49950/50000 - Loss: 1.5713\n",
            "Epoch 4/4 - Average loss: 1.2028 - Duration: 26873.89s\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    batch_times = []\n",
        "    start_time = datetime.datetime.now()\n",
        "\n",
        "    for i, batch in enumerate(train_loader):\n",
        "        batch_start = datetime.datetime.now()\n",
        "\n",
        "\n",
        "        # Move each element of the batch to the device.\n",
        "        # input_ids_batch, attention_mask_batch, labels_batch = [x.to(device) for x in batch]\n",
        "        input_ids_batch, attention_mask_batch, labels_batch = [x.to(device, non_blocking=True) for x in batch]\n",
        "\n",
        "        # Create a position_ids tensor: shape [batch_size, seq_len]\n",
        "        seq_len = input_ids_batch.size(1)\n",
        "        position_ids = torch.arange(seq_len, device=device).unsqueeze(0).repeat(input_ids_batch.size(0), 1)\n",
        "\n",
        "        # Forward pass: compute the loss.\n",
        "        outputs = model(\n",
        "            input_ids=input_ids_batch,\n",
        "            attention_mask=attention_mask_batch,\n",
        "            position_ids=position_ids,\n",
        "            labels=labels_batch\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        # total_loss += loss.item()\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track metrics\n",
        "        total_loss += loss.item()\n",
        "        batch_end = datetime.datetime.now()\n",
        "        batch_times.append((batch_end - batch_start).total_seconds())\n",
        "\n",
        "        # Print progress\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Batch {i}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Compute epoch metrics\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    end_time = datetime.datetime.now()\n",
        "    epoch_duration = (end_time - start_time).total_seconds()\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Average loss: {avg_loss:.4f} - Duration: {epoch_duration:.2f}s\")\n",
        "\n",
        "    # Record epoch metrics\n",
        "    tracker.record_epoch_metrics(\n",
        "        epoch=epoch+1,\n",
        "        loss=avg_loss,\n",
        "        batch_times=batch_times,\n",
        "        epoch_duration=epoch_duration,\n",
        "        timestamp=datetime.datetime.now().isoformat()\n",
        "    )\n",
        "\n",
        "    # Record privacy budget if using differential privacy\n",
        "    if hasattr(model, \"remove_hooks\"):\n",
        "        epsilon = privacy_engine.accountant.get_epsilon(delta=1e-5)\n",
        "        print(f\"Achieved privacy budget: Œµ = {epsilon:.2f}\")\n",
        "        tracker.record_privacy_budget(epsilon=epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sjccWWMIFZi"
      },
      "source": [
        "## Model saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNz9DicrIGdx",
        "outputId": "33c1ff03-679f-4011-8811-40a4148ca933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer saved to ./finetuned_model_dp\n"
          ]
        }
      ],
      "source": [
        "# Remove DP hooks if present\n",
        "if hasattr(model, \"remove_hooks\"):\n",
        "    model.remove_hooks()\n",
        "    model = model._module  # Unwrap the model\n",
        "\n",
        "# # Remove DP hooks to restore the underlying model.\n",
        "# model.remove_hooks()\n",
        "# model = model._module  # Unwrap the model.\n",
        "\n",
        "# Define model type based on whether differential privacy was used\n",
        "# model_type = \"with_dp\" if hasattr(privacy_engine, \"accountant\") else \"without_dp\"\n",
        "model_type = \"without_dp\"\n",
        "\n",
        "# Specify the directory where you want to save your fine-tuned model\n",
        "save_directory = \"./finetuned_model_dp\"\n",
        "\n",
        "# Save the model weights and configuration\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "# Save the tokenizer (this ensures that any custom tokens are preserved)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "# Record model info\n",
        "tracker.save_model_info(\n",
        "    model_path=save_directory,\n",
        "    model_type=model_type,\n",
        "    tokenizer_info={\n",
        "        \"vocab_size\": len(tokenizer),\n",
        "        \"model_max_length\": tokenizer.model_max_length,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(f\"Model and tokenizer saved to {save_directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3pAtkLcIIDl"
      },
      "source": [
        "## Generate 10k rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wVadwnTWpCu4"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Where the pretrained model is saved\n",
        "USING_DP = hasattr(model, \"remove_hooks\")\n",
        "SAVE_DIRECTORY = \".\"\n",
        "TEST_JSONL = \"test.jsonl\"\n",
        "GENERATED_OUTPUT_FILE = \"generated_sequences_with_dp.jsonl\" if USING_DP else \"generated_sequences_no_dp.jsonl\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcfNbOcSqDSZ",
        "outputId": "3346822d-6889-4182-c877-2f0fe625cb72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "USING_DP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U90XGXQzpG25"
      },
      "source": [
        "### Load test.jsonl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84OtZRQSpI84",
        "outputId": "089823e2-0941-4ab2-fceb-f7ea20aabf1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 10000 lines.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "formatted_strings = []\n",
        "\n",
        "with open(TEST_JSONL, \"r\") as f:\n",
        "    for j, line in enumerate(f):\n",
        "        if j <= 10000:\n",
        "            j+=1\n",
        "        data = json.loads(line.strip())\n",
        "        # Extract values\n",
        "        product_title = data['Product Title']\n",
        "        product_category = data['Product Categories']\n",
        "        review_rating = data['Rating']\n",
        "        review_title = data['Review Title']\n",
        "        review = data['Review']\n",
        "\n",
        "        # Format the string as per the required format\n",
        "        formatted_string = f'System prompt : Given the Product Title, Product Category, Review Rating and Review Title, you are required to generate the Review | Product Title: {product_title} | Product Category: {product_category} | Review Rating: {review_rating} | Review Title: {review_title} | Review: {review}'\n",
        "\n",
        "\n",
        "        # Add the formatted string to the list\n",
        "        formatted_strings.append(formatted_string)\n",
        "\n",
        "print(f\"Processed {len(formatted_strings)} lines.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJm9C7S8pLJ9",
        "outputId": "39b5a6d5-01a9-4308-df74-04534badb924"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'System prompt': 'Given the Rating and Title, you are required to generate the review',\n",
              " 'Rating': 3,\n",
              " 'Review Title': 'Everything except the battery is perfect',\n",
              " 'Review': 'Arrived 4 days ahead of schedule. Touch screen, facial ID, camera all work great!<br /><br />Phone was fully unlocked as advertised.<br /><br />I popped my SIM card out of my old phone into this one and it starred working immediately.<br /><br />Only complaint I have is the battery life.<br /><br />Battery might last 2 hrs on full charge. Once battery hits 15% it dies.',\n",
              " 'Product Title': 'Apple iPhone X, US Version, 256GB, Silver - AT&T (Renewed)',\n",
              " 'Product Categories': 'Cell Phones & Accessories'}"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "f87Vq4hRpLN0",
        "outputId": "92b41418-e4d1-4237-c42f-178761613b39"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"System prompt : Given the Product Title, Product Category, Review Rating and Review Title, you are required to generate the Review | Product Title: Case for Galaxy Note 9,Cutebe Shockproof Series Hard PC+ TPU Bumper Protective Case for Samsung Galaxy Note 9 Crystal | Product Category: Cell Phones & Accessories | Review Rating: 4 | Review Title: Not a bad price for protection and cuteness | Review: Looks and works great. It was a little little on the loose fitting side but now it's fine. I've dropped my phone quite a bit and my phone has come out fine.\""
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formatted_strings[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac3X21ZWpRXn"
      },
      "source": [
        "### Generate 10k synthetic rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw5xB7XcpLSg",
        "outputId": "2b6357d0-f80e-4fb5-ccbe-c0c11557e0d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 1 (prompts 0 to 99). Time taken: 37.20 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 2 (prompts 100 to 199). Time taken: 36.54 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 3 (prompts 200 to 299). Time taken: 36.47 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 4 (prompts 300 to 399). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 5 (prompts 400 to 499). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 6 (prompts 500 to 599). Time taken: 36.49 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 7 (prompts 600 to 699). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 8 (prompts 700 to 799). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 9 (prompts 800 to 899). Time taken: 36.49 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 10 (prompts 900 to 999). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 11 (prompts 1000 to 1099). Time taken: 36.48 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 12 (prompts 1100 to 1199). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 13 (prompts 1200 to 1299). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 14 (prompts 1300 to 1399). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 15 (prompts 1400 to 1499). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 16 (prompts 1500 to 1599). Time taken: 36.54 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 17 (prompts 1600 to 1699). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 18 (prompts 1700 to 1799). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 19 (prompts 1800 to 1899). Time taken: 36.54 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 20 (prompts 1900 to 1999). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 21 (prompts 2000 to 2099). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 22 (prompts 2100 to 2199). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 23 (prompts 2200 to 2299). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 24 (prompts 2300 to 2399). Time taken: 36.45 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 25 (prompts 2400 to 2499). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 26 (prompts 2500 to 2599). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 27 (prompts 2600 to 2699). Time taken: 36.46 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 28 (prompts 2700 to 2799). Time taken: 36.46 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 29 (prompts 2800 to 2899). Time taken: 36.47 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 30 (prompts 2900 to 2999). Time taken: 36.54 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 31 (prompts 3000 to 3099). Time taken: 36.48 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 32 (prompts 3100 to 3199). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 33 (prompts 3200 to 3299). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 34 (prompts 3300 to 3399). Time taken: 36.48 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 35 (prompts 3400 to 3499). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 36 (prompts 3500 to 3599). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 37 (prompts 3600 to 3699). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 38 (prompts 3700 to 3799). Time taken: 36.48 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 39 (prompts 3800 to 3899). Time taken: 36.56 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 40 (prompts 3900 to 3999). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 41 (prompts 4000 to 4099). Time taken: 36.54 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 42 (prompts 4100 to 4199). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 43 (prompts 4200 to 4299). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 44 (prompts 4300 to 4399). Time taken: 36.54 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 45 (prompts 4400 to 4499). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 46 (prompts 4500 to 4599). Time taken: 36.47 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 47 (prompts 4600 to 4699). Time taken: 36.54 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 48 (prompts 4700 to 4799). Time taken: 36.54 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 49 (prompts 4800 to 4899). Time taken: 36.49 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 50 (prompts 4900 to 4999). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 51 (prompts 5000 to 5099). Time taken: 36.47 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 52 (prompts 5100 to 5199). Time taken: 36.56 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 53 (prompts 5200 to 5299). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 54 (prompts 5300 to 5399). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 55 (prompts 5400 to 5499). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 56 (prompts 5500 to 5599). Time taken: 36.54 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 57 (prompts 5600 to 5699). Time taken: 36.49 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 58 (prompts 5700 to 5799). Time taken: 36.47 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 59 (prompts 5800 to 5899). Time taken: 36.48 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 60 (prompts 5900 to 5999). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 61 (prompts 6000 to 6099). Time taken: 36.50 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 62 (prompts 6100 to 6199). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 63 (prompts 6200 to 6299). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 64 (prompts 6300 to 6399). Time taken: 36.46 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 65 (prompts 6400 to 6499). Time taken: 36.51 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 66 (prompts 6500 to 6599). Time taken: 36.47 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 67 (prompts 6600 to 6699). Time taken: 36.51 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 68 (prompts 6700 to 6799). Time taken: 36.49 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 69 (prompts 6800 to 6899). Time taken: 36.55 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 70 (prompts 6900 to 6999). Time taken: 36.43 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 71 (prompts 7000 to 7099). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 72 (prompts 7100 to 7199). Time taken: 36.46 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 73 (prompts 7200 to 7299). Time taken: 36.44 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 74 (prompts 7300 to 7399). Time taken: 36.47 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 75 (prompts 7400 to 7499). Time taken: 36.44 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 76 (prompts 7500 to 7599). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 77 (prompts 7600 to 7699). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 78 (prompts 7700 to 7799). Time taken: 36.51 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 79 (prompts 7800 to 7899). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 80 (prompts 7900 to 7999). Time taken: 36.46 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 81 (prompts 8000 to 8099). Time taken: 36.51 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 82 (prompts 8100 to 8199). Time taken: 36.51 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 83 (prompts 8200 to 8299). Time taken: 36.48 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 84 (prompts 8300 to 8399). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 85 (prompts 8400 to 8499). Time taken: 36.49 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 86 (prompts 8500 to 8599). Time taken: 36.51 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 87 (prompts 8600 to 8699). Time taken: 36.45 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 88 (prompts 8700 to 8799). Time taken: 36.51 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 89 (prompts 8800 to 8899). Time taken: 36.48 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 90 (prompts 8900 to 8999). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 91 (prompts 9000 to 9099). Time taken: 36.50 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 92 (prompts 9100 to 9199). Time taken: 36.51 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 93 (prompts 9200 to 9299). Time taken: 36.44 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 94 (prompts 9300 to 9399). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 95 (prompts 9400 to 9499). Time taken: 36.54 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 96 (prompts 9500 to 9599). Time taken: 36.49 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 97 (prompts 9600 to 9699). Time taken: 36.52 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 98 (prompts 9700 to 9799). Time taken: 36.53 seconds.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed batch 99 (prompts 9800 to 9899). Time taken: 36.52 seconds.\n",
            "Processed batch 100 (prompts 9900 to 9999). Time taken: 36.51 seconds.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 100\n",
        "formatted_prompts = formatted_strings\n",
        "\n",
        "# Process prompts in batches\n",
        "num_prompts = len(formatted_prompts)\n",
        "for batch_start in range(0, num_prompts, batch_size):\n",
        "    batch_prompts = formatted_prompts[batch_start : batch_start + batch_size]\n",
        "\n",
        "    batch_start_time = time.time()\n",
        "\n",
        "    # Tokenize the entire batch\n",
        "    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128, padding_side='left')\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "    # Generate text for the batch\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(**inputs, max_length=256, do_sample=True, top_k=50)\n",
        "\n",
        "    # Decode the generated sequences for each prompt\n",
        "    batch_generated_texts = [tokenizer.decode(ids, skip_special_tokens=True) for ids in generated_ids]\n",
        "\n",
        "    batch_end_time = time.time()\n",
        "    batch_time = batch_end_time - batch_start_time\n",
        "\n",
        "    # Write the generated outputs in JSONL format\n",
        "    with open(GENERATED_OUTPUT_FILE, \"a\") as outfile:\n",
        "        for text in batch_generated_texts:\n",
        "            json_line = json.dumps({\"generated_text\": text})\n",
        "            outfile.write(json_line + \"\\n\")\n",
        "\n",
        "    print(f\"Processed batch {(batch_start // batch_size) + 1} (prompts {batch_start} to {batch_start+len(batch_prompts)-1}). Time taken: {batch_time:.2f} seconds.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KwPM3hdJr1ez",
        "g8WJhCIZMuRB",
        "ykEN9tloMw_h",
        "M8h8bWh_HRTv",
        "Yda7cPXHH9kl",
        "9sjccWWMIFZi"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00ad50c8385e4668a738fdefe804228f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cfe32bbcd41488380fd1924cf305b62",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_28833a6fa9574d2ab4ec82cecc892edc",
            "value": "model-00004-of-00004.safetensors:‚Äá100%"
          }
        },
        "057a126c0de04e42a1ed7a7d975adf16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffc9dbd25da340b780d09e14350035be",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e928a58f3c0d4200965bea1e40762ae0",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "075d6e788b884c29b1929a010cd22fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07872cc7fac245979001bcb3754e6e79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0798ac45931c4fb38e9024528fc77785": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f3c54a5b304defa099f430441d9110": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08856f97715343dc867641e9d7392730": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d232134533b4eed956e92df0a1c98cb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0dfe321ed9364364ba6905aaf72e9ea4",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "090eb951c8f3498b89212dc642ffc4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09467288745940ddb53fcfc0b93f5b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_057a126c0de04e42a1ed7a7d975adf16",
              "IPY_MODEL_2cfd135788584846ad1adac7663482f2",
              "IPY_MODEL_d2f3d2691add4b28a23c53b0c8044af7"
            ],
            "layout": "IPY_MODEL_e965786dec22495aba27210ee512cdec"
          }
        },
        "0dfe321ed9364364ba6905aaf72e9ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e4ef0bbfd0c4250a20c35a9fcbd5c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12e26657a64348c3860e3c2a67868c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1311e597fa9747098955586a6af10550": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed06a41255b4e15b8d707bfb721456c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_662eccf0fe1646519348111af5a73a16",
            "value": "‚Äá4.92G/4.92G‚Äá[00:22&lt;00:00,‚Äá208MB/s]"
          }
        },
        "1317b8fd5ea34693be094a61034f0e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a9a4fc5aa934872a94d7e98f5745918",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f59f3b7789bb4b969af2192b3f15335a",
            "value": "‚Äá50.5k/50.5k‚Äá[00:00&lt;00:00,‚Äá3.82MB/s]"
          }
        },
        "1330cf548d604f918e010676ad3740fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "159622db470d488db31c752942e1ceeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1751bb94cd154674996801a739e63245": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b62d12448053451d967005e796f09c26",
              "IPY_MODEL_e12e01741783479f9919e4fa0f537424",
              "IPY_MODEL_368f7202da7b4dce986927287c717d01"
            ],
            "layout": "IPY_MODEL_ddf7c361b62e4d22baf237d8e8cdbbf2"
          }
        },
        "1779224db2d347ec815f656743157aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d776cf383d1d411ab9bff591df143bac",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_474fc34d424e40869b974b81f2e1d0df",
            "value": "config.json:‚Äá100%"
          }
        },
        "17c3113c521f46a19d88403b9e37b420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58c8ea5811d34c8899497d334f153c09",
              "IPY_MODEL_b294b513e91b41dc912d9d5e9d006a29",
              "IPY_MODEL_1311e597fa9747098955586a6af10550"
            ],
            "layout": "IPY_MODEL_77f293d88faf4333969cfe9f4d6d9a38"
          }
        },
        "1a1e943a9461409d820662f46e04f1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0927d127926408a81430747a2ee34a2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_945ff29cf6014cd4bfef200bea414989",
            "value": "model-00001-of-00004.safetensors:‚Äá100%"
          }
        },
        "1cfe32bbcd41488380fd1924cf305b62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e68d697faad422995f56a4b1231640b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08856f97715343dc867641e9d7392730",
              "IPY_MODEL_45a7314ff5c14fa88bf8eea0ef759dbc",
              "IPY_MODEL_c86d9bc78ec34709a9c24eba5e56f95b"
            ],
            "layout": "IPY_MODEL_21e02b288ec94dafaa545da03ac371b8"
          }
        },
        "1ea92d2837294f2dbd31d88ae0f5fea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21e02b288ec94dafaa545da03ac371b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22de85be808b43d6a210cfa411fadbcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbb28be080c04aba84dd050c72de2c03",
            "max": 4976698672,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79f3c297e3cc4eb39f53266e9ddbfb8f",
            "value": 4976698672
          }
        },
        "26004715aa20400f9b1965e56a8418d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28833a6fa9574d2ab4ec82cecc892edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2975e275cadf469a9a427d5f0d3b6142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa12fb2726147198ca5cf8a04921c52",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ac0d928dd59c4400ba340792b4f44840",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "2c2cc18ff6604a028268c41e557fe12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cfd135788584846ad1adac7663482f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb76adf40b2a43f292c24ac46b3c7518",
            "max": 73,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_801a01c2bc344de99c40b34c12dc0e7f",
            "value": 73
          }
        },
        "32c150dbed93432a90db55125f74d520": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36281df0bfb14c0a81336271b7516bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_877849f87fc94a35b2567adbed7e58e1",
              "IPY_MODEL_f26e022370ab4174bb05639504fcd221",
              "IPY_MODEL_a6b806a2d4a5402dac01cfbcbaa33364"
            ],
            "layout": "IPY_MODEL_eaf3e54fc28b41ba84a02022e26a62a9"
          }
        },
        "368f7202da7b4dce986927287c717d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_887013fb2d5f47e9a20c355319dd97a5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8921cb6faf4d413ab8a54a9afc413355",
            "value": "‚Äá5.00G/5.00G‚Äá[00:23&lt;00:00,‚Äá235MB/s]"
          }
        },
        "3a3063e206624ab4b424e284f6fb350b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a9a4fc5aa934872a94d7e98f5745918": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ea0a5c165db429bb3145fdc192ae34b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ed06a41255b4e15b8d707bfb721456c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa5c366af0c4e108cdfb915bba878bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ff77a878aff4d49b27af32047c31c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41640bb6dbdf4acdb7c0dc1a3f66f3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4578534bff984ff1a6760e7d1ab5cd67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45a7314ff5c14fa88bf8eea0ef759dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e9f4256f99d434ebbc2c9761e1f8424",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51a51e9c33164e74b7dd7cc28486d46a",
            "value": 4
          }
        },
        "46917ebd09cc44c4b96a5450632e8486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f3c54a5b304defa099f430441d9110",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c97f8c539892482393e6965fb191dcd2",
            "value": "‚Äá4.98G/4.98G‚Äá[00:22&lt;00:00,‚Äá225MB/s]"
          }
        },
        "474fc34d424e40869b974b81f2e1d0df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a4323a25599478d889ca960d5ea4e29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b30e5dcffa94670add6c5e7b773812b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b901fa1d37f4631bcdc043e3519b16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2975e275cadf469a9a427d5f0d3b6142",
              "IPY_MODEL_96cd3680ac9141b69a54ec0680a72001",
              "IPY_MODEL_9f1a9f2488474dad8d09727d5af26c18"
            ],
            "layout": "IPY_MODEL_7f1d705f93d74509b9d579b7eec52842"
          }
        },
        "4bf9efeebced409984f72ca1cda80998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4bfc05edeece455c858b6fd6afe22b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50ad28a135e040bdb89afd7cee0333fc",
              "IPY_MODEL_ff3d084d82ed43eab2dcec75f2651764",
              "IPY_MODEL_1317b8fd5ea34693be094a61034f0e4d"
            ],
            "layout": "IPY_MODEL_a0a6916123c54852a0acf1dd0d84390f"
          }
        },
        "4cd068a5c4794a99abf4170939f134dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e71efeed87b4bca883ae5b4e603278b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ff8abfc37ea4cd3bc4dc1d6b880d614": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50ad28a135e040bdb89afd7cee0333fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07872cc7fac245979001bcb3754e6e79",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_12e26657a64348c3860e3c2a67868c8b",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "51a51e9c33164e74b7dd7cc28486d46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53d39981363b4ae083a06da21340234e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5662c3eeaf79406195ba25e9c581c313": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e1e286b4af545e1977c2040e9149000",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_090eb951c8f3498b89212dc642ffc4e4",
            "value": "‚Äá23.9k/23.9k‚Äá[00:00&lt;00:00,‚Äá1.91MB/s]"
          }
        },
        "573fe4b0356b432fbad37254983a2834": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5820bfb33022468da26874aabe1c1e58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58bb559ee62c43c28ad770d164f3fc56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c8ea5811d34c8899497d334f153c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b88b5a17d6d542efbcce3f77c3be46a4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0e4ef0bbfd0c4250a20c35a9fcbd5c0a",
            "value": "model-00003-of-00004.safetensors:‚Äá100%"
          }
        },
        "5a7a1c991c644d8c8301a8bd60683afb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e1e286b4af545e1977c2040e9149000": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "662eccf0fe1646519348111af5a73a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6da2fc2720034b049a11b87145836d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eacf1c8112db45c187b21656a178cc41",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_075d6e788b884c29b1929a010cd22fff",
            "value": "‚Äá1.17G/1.17G‚Äá[00:05&lt;00:00,‚Äá235MB/s]"
          }
        },
        "702ab9f05f6142e9819cc25f1944d07b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7311fbe2fdc44a58a788a617d4378649": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a3063e206624ab4b424e284f6fb350b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4ff8abfc37ea4cd3bc4dc1d6b880d614",
            "value": "model.safetensors.index.json:‚Äá100%"
          }
        },
        "744808745933465da57d8c3301cb8d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_949ad6b2fe4d4185856fc03d3c05f37b",
            "max": 9085658,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ea92d2837294f2dbd31d88ae0f5fea6",
            "value": 9085658
          }
        },
        "77f293d88faf4333969cfe9f4d6d9a38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79c97fcf4da2407dadf7e08b40f2a679": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a1e943a9461409d820662f46e04f1fd",
              "IPY_MODEL_22de85be808b43d6a210cfa411fadbcf",
              "IPY_MODEL_46917ebd09cc44c4b96a5450632e8486"
            ],
            "layout": "IPY_MODEL_3fa5c366af0c4e108cdfb915bba878bc"
          }
        },
        "79f3c297e3cc4eb39f53266e9ddbfb8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d232134533b4eed956e92df0a1c98cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd47dd7f3f844e4ad99946823c680ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7a1c991c644d8c8301a8bd60683afb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1330cf548d604f918e010676ad3740fc",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "7e9f4256f99d434ebbc2c9761e1f8424": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f1d705f93d74509b9d579b7eec52842": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "801a01c2bc344de99c40b34c12dc0e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80a0c67773e24de097c3c0f70760c887": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81f2dc9ba86740aa8bd3f00af63fb5f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82a49cf12f4243d09603ec44558eb1d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8518115a881e49d291493fd86c5ea3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "877849f87fc94a35b2567adbed7e58e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0798ac45931c4fb38e9024528fc77785",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_41640bb6dbdf4acdb7c0dc1a3f66f3ef",
            "value": "Downloading‚Äáshards:‚Äá100%"
          }
        },
        "87a9336b909445049735140d4ff41a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91fb6f27e67944c79dc5d9f03fb5dd8e",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bf9efeebced409984f72ca1cda80998",
            "value": 23950
          }
        },
        "887013fb2d5f47e9a20c355319dd97a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8921cb6faf4d413ab8a54a9afc413355": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eaa7a2f68c14465be82d6a4cac9f79e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9128daef14204ec69b757d57d7b4aa4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91fb6f27e67944c79dc5d9f03fb5dd8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945ff29cf6014cd4bfef200bea414989": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "949ad6b2fe4d4185856fc03d3c05f37b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96cd3680ac9141b69a54ec0680a72001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c150dbed93432a90db55125f74d520",
            "max": 185,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce2ee2eb3be547deadb3ec6358dd0174",
            "value": 185
          }
        },
        "981270c7fe49493a8faf8b39539286ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53d39981363b4ae083a06da21340234e",
            "max": 826,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ff77a878aff4d49b27af32047c31c70",
            "value": 826
          }
        },
        "9f1a9f2488474dad8d09727d5af26c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2fbd258dd9a4f50863bd0baf3c85f48",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_afd766107e54446faadbb5d3753361fb",
            "value": "‚Äá185/185‚Äá[00:00&lt;00:00,‚Äá16.3kB/s]"
          }
        },
        "a06a504bf4174aafa868c80ec30b6689": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ea0a5c165db429bb3145fdc192ae34b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4e71efeed87b4bca883ae5b4e603278b",
            "value": "‚Äá9.09M/9.09M‚Äá[00:00&lt;00:00,‚Äá33.1MB/s]"
          }
        },
        "a0a6916123c54852a0acf1dd0d84390f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6b806a2d4a5402dac01cfbcbaa33364": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_702ab9f05f6142e9819cc25f1944d07b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bcb8af7c875f40fcbb981e2fde04996c",
            "value": "‚Äá4/4‚Äá[01:13&lt;00:00,‚Äá15.90s/it]"
          }
        },
        "ac0d928dd59c4400ba340792b4f44840": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afd766107e54446faadbb5d3753361fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b294b513e91b41dc912d9d5e9d006a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_573fe4b0356b432fbad37254983a2834",
            "max": 4915916176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82a49cf12f4243d09603ec44558eb1d7",
            "value": 4915916176
          }
        },
        "b62d12448053451d967005e796f09c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cd068a5c4794a99abf4170939f134dc",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_81f2dc9ba86740aa8bd3f00af63fb5f2",
            "value": "model-00002-of-00004.safetensors:‚Äá100%"
          }
        },
        "b6e3ad7c93b04389b3a0a75357591929": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dd47dd7f3f844e4ad99946823c680ab",
              "IPY_MODEL_744808745933465da57d8c3301cb8d60",
              "IPY_MODEL_a06a504bf4174aafa868c80ec30b6689"
            ],
            "layout": "IPY_MODEL_c2d11d04e4f04375acea4d0748828879"
          }
        },
        "b747619d671e4d95891c3e8c16a707f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8887cf900a64f67a1b38053ef6db70e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b88b5a17d6d542efbcce3f77c3be46a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b89ffdce53df49338b1019dec0ac6b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1779224db2d347ec815f656743157aba",
              "IPY_MODEL_981270c7fe49493a8faf8b39539286ab",
              "IPY_MODEL_baf9315acc8d412a8adfa459fbb2ccca"
            ],
            "layout": "IPY_MODEL_5820bfb33022468da26874aabe1c1e58"
          }
        },
        "b982345174a8431086ae8a0a4a7d8e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7311fbe2fdc44a58a788a617d4378649",
              "IPY_MODEL_87a9336b909445049735140d4ff41a9c",
              "IPY_MODEL_5662c3eeaf79406195ba25e9c581c313"
            ],
            "layout": "IPY_MODEL_b8887cf900a64f67a1b38053ef6db70e"
          }
        },
        "bae3d80ce49e49eea486d4ad36a2b602": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58bb559ee62c43c28ad770d164f3fc56",
            "max": 1168138808,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b30e5dcffa94670add6c5e7b773812b",
            "value": 1168138808
          }
        },
        "baf9315acc8d412a8adfa459fbb2ccca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b747619d671e4d95891c3e8c16a707f5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8518115a881e49d291493fd86c5ea3ac",
            "value": "‚Äá826/826‚Äá[00:00&lt;00:00,‚Äá75.3kB/s]"
          }
        },
        "bb76adf40b2a43f292c24ac46b3c7518": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb8af7c875f40fcbb981e2fde04996c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be24ab4395b94205a189872d09d45283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00ad50c8385e4668a738fdefe804228f",
              "IPY_MODEL_bae3d80ce49e49eea486d4ad36a2b602",
              "IPY_MODEL_6da2fc2720034b049a11b87145836d8a"
            ],
            "layout": "IPY_MODEL_dc3f099e28f34caab5f4c6138bcb1ac8"
          }
        },
        "c21f7ce864a5420db3e8886a7db39358": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2d11d04e4f04375acea4d0748828879": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c86d9bc78ec34709a9c24eba5e56f95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4578534bff984ff1a6760e7d1ab5cd67",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_80a0c67773e24de097c3c0f70760c887",
            "value": "‚Äá4/4‚Äá[00:10&lt;00:00,‚Äá‚Äá2.32s/it]"
          }
        },
        "c97f8c539892482393e6965fb191dcd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbb28be080c04aba84dd050c72de2c03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce2ee2eb3be547deadb3ec6358dd0174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2f3d2691add4b28a23c53b0c8044af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c21f7ce864a5420db3e8886a7db39358",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e6ba8c3dd072436fb007fdf610cf45da",
            "value": "‚Äá73.0/73.0‚Äá[00:00&lt;00:00,‚Äá5.88kB/s]"
          }
        },
        "d2fbd258dd9a4f50863bd0baf3c85f48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d776cf383d1d411ab9bff591df143bac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc3f099e28f34caab5f4c6138bcb1ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddf7c361b62e4d22baf237d8e8cdbbf2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e12e01741783479f9919e4fa0f537424": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_159622db470d488db31c752942e1ceeb",
            "max": 4999802720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9128daef14204ec69b757d57d7b4aa4e",
            "value": 4999802720
          }
        },
        "e6ba8c3dd072436fb007fdf610cf45da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e928a58f3c0d4200965bea1e40762ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e965786dec22495aba27210ee512cdec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eacf1c8112db45c187b21656a178cc41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf3e54fc28b41ba84a02022e26a62a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0927d127926408a81430747a2ee34a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f26e022370ab4174bb05639504fcd221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26004715aa20400f9b1965e56a8418d3",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c2cc18ff6604a028268c41e557fe12d",
            "value": 4
          }
        },
        "f59f3b7789bb4b969af2192b3f15335a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faa12fb2726147198ca5cf8a04921c52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff3d084d82ed43eab2dcec75f2651764": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a4323a25599478d889ca960d5ea4e29",
            "max": 50500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8eaa7a2f68c14465be82d6a4cac9f79e",
            "value": 50500
          }
        },
        "ffc9dbd25da340b780d09e14350035be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
