{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements and dependencies\n"
      ],
      "metadata": {
        "id": "KwPM3hdJr1ez"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZof-WuyHdF2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install opacus\n",
        "# !pip install -U bitsandbytes transformers accelerate\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pynvml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8Ga73J2NITU",
        "outputId": "c896fba2-6c5f-47b3-b2f1-8fc46b8c72ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (12.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pynvml) (12.570.86)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCRKTux3HJuH",
        "outputId": "69d883b7-fe6e-462d-a632-a623fc0528ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy version: 1.26.4\n",
            "Using device: cuda\n",
            "GPU Device: NVIDIA L4\n",
            "Available GPU memory: 22.17 GB\n"
          ]
        }
      ],
      "source": [
        "from random import sample\n",
        "import numpy as np\n",
        "print(\"NumPy version:\", np.__version__)  # Should print \"1.23.5\"\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.amp import autocast, GradScaler  # Import automatic mixed precision tools\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from opacus import PrivacyEngine\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "\n",
        "# Set up device - prioritize GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Print GPU info if available\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSOP969tMhsE"
      },
      "outputs": [],
      "source": [
        "## Clear GPU cache and storage\n",
        "torch.cuda.empty_cache()  # Frees unused memory\n",
        "torch.cuda.ipc_collect()  # Collects shared memory used in multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "06uZqEV3rGAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve token securely\n",
        "hf_token = userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "if hf_token:\n",
        "    login(token=hf_token)\n",
        "    print(\"Logged in successfully!\")\n",
        "else:\n",
        "    print(\"Hugging Face token not found. Please set it using `userdata.set`.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5eyCXarG33",
        "outputId": "78217f0d-b514-4b81-c292-4b524013b6ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU and GPU util functions"
      ],
      "metadata": {
        "id": "g8WJhCIZMuRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import torch\n",
        "\n",
        "try:\n",
        "    from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo, nvmlDeviceGetUtilizationRates, nvmlSystemGetDriverVersion, nvmlDeviceGetName, nvmlShutdown\n",
        "    nvmlInit()\n",
        "    NVML_AVAILABLE = True\n",
        "except ImportError:\n",
        "    NVML_AVAILABLE = False\n",
        "\n",
        "def get_cpu_stats():\n",
        "    \"\"\" Get CPU usage stats \"\"\"\n",
        "    cpu_usage = psutil.cpu_percent(interval=1)  # Get CPU usage %\n",
        "    cpu_freq = psutil.cpu_freq().current if psutil.cpu_freq() else \"Unknown\"  # CPU Frequency\n",
        "    num_cores = psutil.cpu_count(logical=False)  # Physical Cores\n",
        "    num_threads = psutil.cpu_count(logical=True)  # Logical Cores\n",
        "    print(f\"CPU Usage: {cpu_usage}%\")\n",
        "    print(f\"CPU Frequency: {cpu_freq} MHz\")\n",
        "    print(f\"Physical Cores: {num_cores}\")\n",
        "    print(f\"Logical Cores: {num_threads}\")\n",
        "\n",
        "def get_ram_stats():\n",
        "    \"\"\" Get system RAM stats \"\"\"\n",
        "    ram = psutil.virtual_memory()\n",
        "    print(\"Total RAM:\", round(ram.total / 1e9, 2), \"GB\")\n",
        "    print(\"Available RAM:\", round(ram.available / 1e9, 2), \"GB\")\n",
        "    print(\"Used RAM:\", round(ram.used / 1e9, 2), \"GB\")\n",
        "    print(\"RAM Usage:\", ram.percent, \"%\")\n",
        "\n",
        "def get_gpu_stats():\n",
        "    \"\"\" Get GPU stats if available \"\"\"\n",
        "    if not NVML_AVAILABLE:\n",
        "        return {\"Error\": \"pynvml not installed. Run: pip install nvidia-ml-py3\"}\n",
        "\n",
        "    num_gpus = torch.cuda.device_count()\n",
        "\n",
        "    for i in range(num_gpus):\n",
        "        handle = nvmlDeviceGetHandleByIndex(i)\n",
        "        mem_info = nvmlDeviceGetMemoryInfo(handle)\n",
        "        utilization = nvmlDeviceGetUtilizationRates(handle)\n",
        "\n",
        "        print(f\"GPU {i} - {nvmlDeviceGetName(handle)}\")\n",
        "        print(f\"Driver Version: {nvmlSystemGetDriverVersion()}\")\n",
        "        print(f\"Total VRAM: {round(mem_info.total / 1e9, 2)} GB\")\n",
        "        print(f\"Used VRAM: {round(mem_info.used / 1e9, 2)} GB\")\n",
        "        print(f\"Free VRAM: {round(mem_info.free / 1e9, 2)} GB\")\n",
        "        print(f\"GPU Usage: {utilization.gpu}%\")\n",
        "        print()\n",
        "\n",
        "    nvmlShutdown()  # Clean up NVML\n",
        "\n",
        "# Run and print system stats\n",
        "\n",
        "print(\"\\nðŸ”¹ CPU Stats:\", )\n",
        "print(\"\\nðŸ”¹ RAM Stats:\", )\n",
        "print(\"\\nðŸ”¹ GPU Stats:\", )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebizwy4ZMnlk",
        "outputId": "9966120c-1d5c-4a1c-d690-09020bc7649e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ CPU Stats:\n",
            "\n",
            "ðŸ”¹ RAM Stats:\n",
            "\n",
            "ðŸ”¹ GPU Stats:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU & GPU specs"
      ],
      "metadata": {
        "id": "ykEN9tloMw_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_cpu_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SymnXtWfM024",
        "outputId": "1198c2c9-7c0a-4931-d4bb-eb43e4d7a322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Usage: 1.0%\n",
            "CPU Frequency: 2200.2180000000003 MHz\n",
            "Physical Cores: 4\n",
            "Logical Cores: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ram_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXzbNF9UM1-a",
        "outputId": "1044e331-3ce2-47c5-bd6d-9aaa385e098e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total RAM: 33.67 GB\n",
            "Available RAM: 31.59 GB\n",
            "Used RAM: 1.59 GB\n",
            "RAM Usage: 6.2 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_gpu_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBp4-KgEM3CQ",
        "outputId": "5bd0bd95-75f4-4bab-a316-afb68079e097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0 - NVIDIA L4\n",
            "Driver Version: 535.104.05\n",
            "Total VRAM: 24.15 GB\n",
            "Used VRAM: 0.36 GB\n",
            "Free VRAM: 23.8 GB\n",
            "GPU Usage: 0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkAUFwP4HM5p"
      },
      "source": [
        "## Model Loading and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "1907ac972b6d4f0297b214d61579e0e9",
            "37cacc72e923417fa1c1b3de0e62eb12",
            "f5f5a764b9804b2bba539b7d5da10f8e",
            "13be1480f43e4561b56dca7638369163",
            "f4a41351ab1947608e88ddf919620388",
            "7c68409228e24b1d897ae163679b4855",
            "77a7759ea5074fcabd6b9e157f0cf429",
            "23049770af8442a189b35b99fc2ae6ae",
            "567a0c15fd1f4edf9188697a27945131",
            "b903bca9e37f4e6884167a4a9598a68b",
            "ace4390e2ea447999d67e42bf2ac9d12"
          ]
        },
        "id": "TPZT02dfHLb5",
        "outputId": "d2c893d1-4167-4ae0-92d4-26b5a72d55fe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1907ac972b6d4f0297b214d61579e0e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pad, token doesnt exists, using EOS token\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(128256, 4096)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Load Pretrained Model and Tokenizer\n",
        "# model_name = \"EleutherAI/gpt-neo-2.7B\"\n",
        "# model_name = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n",
        "model_name = \"meta-llama/Llama-3.1-8B\"\n",
        "\n",
        "# This line downloads (if needed) and initializes a tokenizer using the identifier stored in model_name.\n",
        "# The tokenizer converts text into a numerical format (tokens) that the model can process,\n",
        "# and it also handles the reverse process (converting tokens back to human-readable text).\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# This line loads a pre-trained causal language model (such as GPT-style models) using the same model identifier.\n",
        "# It retrieves the model architecture and its pre-trained weights so you can use it for tasks like text generation.\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,       # Loads model in FP16\n",
        "    device_map=\"auto\"                # Automatically distributes model across devices if needed\n",
        ")\n",
        "\n",
        "# !! NEW\n",
        "# Freeze all model parameters (ensuring no gradients are computed for the base model)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Ensure a pad token exists (set to eos token if not present).\n",
        "# 1. Check for the padding token id. If none, use the eos_token as the padding token\n",
        "if tokenizer.pad_token_id is None:\n",
        "    print(\"pad, token doesnt exists, using EOS token\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Adjusts the model's token embedding matrix to match the size of the tokenizer's vocabulary.\n",
        "# This is important because adding or changing tokens (like defining a pad token)\n",
        "# may change the size of the vocabulary, and the model's embedding layer needs to reflect that change.\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8h8bWh_HRTv"
      },
      "source": [
        "## LoRA Configuration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get all the intermediate layer config of the model\n",
        "# for name, module in model.named_modules():\n",
        "#     print(name, \":\", module)"
      ],
      "metadata": {
        "id": "PKP9YMKBdIpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZffBS3pRHUrK",
        "outputId": "62eb07ec-8853-499d-d34d-f959da869bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA applied. Trainable parameters:\n",
            "trainable params: 16,252,928 || all params: 8,046,514,176 || trainable%: 0.2020\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(128256, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=14336, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Enable gradient checkpointing to save memory.\n",
        "\n",
        "# This technique reduces memory usage during training by not storing all intermediate activations\n",
        "# during the forward pass. Instead, it saves only a subset of them and recomputes the missing ones\n",
        "# during the backward pass.\n",
        "model.config.gradient_checkpointing = True\n",
        "\n",
        "# Configure LoRA: update only a small set of additional parameters.\n",
        "# tried r=4 and lora+alpha = 32. Maybe that destabilized training so modifying to 8 and 16 respectively\n",
        "#initally was 0.1, changing to 0.05\n",
        "\n",
        "# studies say best to apply Lora to all layers\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,  # Fine-tuning for causal language modeling.\n",
        "    inference_mode=False,          # Training mode.\n",
        "    r=8,                           # Rank of low-rank decomposition.\n",
        "    lora_alpha=16,                 # Scaling factor.\n",
        "    lora_dropout=0.05,               # Dropout rate for LoRA layers.\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# This function call takes the pre-trained model and applies the LoRA configuration you defined.\n",
        "# It modifies the model so that, instead of updating all parameters during fine-tuning,\n",
        "# only a small subset (the LoRA adapters) is trained.\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(\"LoRA applied. Trainable parameters:\")\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "# Move the model to the chosen device and set to training mode.\n",
        "model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fulb2eoMHXBD"
      },
      "source": [
        "## Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooqU-XeiHY3Q"
      },
      "outputs": [],
      "source": [
        "# Load and Format Training Data\n",
        "import json\n",
        "\n",
        "formatted_strings = []\n",
        "\n",
        "with open(\"finetuning/train.jsonl\", \"r\") as f:\n",
        "    # j = 0\n",
        "    for line in f:\n",
        "        # Parse the JSON data from the line\n",
        "        data = json.loads(line.strip())\n",
        "        # Extract values\n",
        "        rating = data['Rating']\n",
        "        title = data['Title']\n",
        "        review = data['Review']\n",
        "\n",
        "        # Format the string as per the required format\n",
        "        formatted_string = f'\"System prompt : Given the Rating and Title, you are required to generate the review\" | \"Rating\": {rating} | \"Title\": {title} | \"Review\": {review}'\n",
        "\n",
        "        # Add the formatted string to the list\n",
        "        formatted_strings.append(formatted_string)\n",
        "\n",
        "        # j+=1\n",
        "        # if j == 1000:\n",
        "        #     break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now `formatted_strings` contains the list of strings in the desired format\n",
        "print(\"Size: \",len(formatted_strings))\n",
        "print(formatted_strings[0])\n",
        "train_texts = formatted_strings\n",
        "strs = [len(formatted_str) for formatted_str in formatted_strings]\n",
        "print(\"length of largets string is: \",sum(strs) / len(strs))\n",
        "# avg around 328"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPe6k7Dmdtwp",
        "outputId": "64e0fb0a-d6a7-467d-cca1-dd9415445d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size:  100000\n",
            "\"System prompt : Given the Rating and Title, you are required to generate the review\" | \"Rating\": 4 | \"Title\": No white background! Itâ€™s clear! | \"Review\": I bought this bc I thought it had the nice white background. Turns out itâ€™s clear & since my phone is blue it doesnâ€™t look anything like this.  If I had known that I would have purchased something else. It works ok.\n",
            "length of largets string is:  383.47625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCsd5i7NH17t"
      },
      "source": [
        "## Data tokenization and dataset creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV5ygoW-H6IH",
        "outputId": "4e85f863-8793-4fbf-d417-ccb627e2925b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: torch.Size([100000, 128])\n"
          ]
        }
      ],
      "source": [
        "# !! NEW - max_length=512\n",
        "\n",
        "# Tokenize training texts with padding and truncation.\n",
        "encodings = tokenizer(train_texts, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
        "input_ids = encodings['input_ids']\n",
        "attention_mask = encodings['attention_mask']\n",
        "\n",
        "# For causal language modeling, use input_ids as labels.\n",
        "# Replace pad token positions with -100 so that they are ignored by the loss.\n",
        "\n",
        "#creates a copy of your input IDs, so you can modify them without affecting the original tensor.\n",
        "labels = input_ids.clone()\n",
        "\n",
        "#replaces all padding token positions with -100. This is a common convention (especially with PyTorchâ€™s CrossEntropyLoss)\n",
        "# to indicate that these positions should be ignored during loss computatio\n",
        "labels[input_ids == tokenizer.pad_token_id] = -100\n",
        "\n",
        "print(\"Training data shape:\", input_ids.shape)\n",
        "\n",
        "\n",
        "# !! NEW - num_workers=4, pin_memory=True\n",
        "# Create a TensorDataset and DataLoader with a small batch size.\n",
        "train_dataset = TensorDataset(input_ids, attention_mask, labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, drop_last=True, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yda7cPXHH9kl"
      },
      "source": [
        "## Optimizer & Privacy engine setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !! NEW\n",
        "# optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-4)"
      ],
      "metadata": {
        "id": "nNoZnmXSeXhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4pqKECaH-7T"
      },
      "outputs": [],
      "source": [
        "# privacy_engine = PrivacyEngine()\n",
        "# model, optimizer, train_loader = privacy_engine.make_private(\n",
        "#     module=model,\n",
        "#     optimizer=optimizer,\n",
        "#     data_loader=train_loader,\n",
        "#     noise_multiplier=1.0,      # Adjust for your desired privacy guarantee.\n",
        "#     max_grad_norm=1.5,         # Gradient clipping norm.\n",
        "#     batch_first=True,\n",
        "#     loss_reduction=\"mean\",\n",
        "#     poisson_sampling=False     # Use standard sampling.\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjdbmm3wIB0M"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2Enc0M0IAkX"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "model.train()\n",
        "epochs = 4  # Use more epochs for a real task.\n",
        "\n",
        "# !! NEW\n",
        "scaler = GradScaler('cuda')  # Create a gradient scaler to manage FP16 stability\n",
        "accumulation_steps = 1  # Set gradient accumulation steps; use >1 to simulate larger batch sizes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # FINETUNING, NOT WORKING NOW\n",
        "# for epoch in range(epochs):  # Loop over each epoch\n",
        "#     total_loss = 0.0  # Initialize total loss accumulator for the epoch\n",
        "#     optimizer.zero_grad()  # Zero gradients at the start of the epoch\n",
        "#     for i, batch in enumerate(train_loader):  # Loop over mini-batches from the DataLoader\n",
        "#         # Move each tensor in the batch to the device (GPU) asynchronously if pin_memory is True\n",
        "#         input_ids_batch, attention_mask_batch, labels_batch = [\n",
        "#             x.to(device, non_blocking=True) for x in batch\n",
        "#         ]\n",
        "\n",
        "#         # Determine the sequence length for the current batch and create position IDs accordingly\n",
        "#         seq_len = input_ids_batch.size(1)  # Get the sequence length from the input tensor\n",
        "#         # Create a tensor [0, 1, ..., seq_len-1] and repeat it for each item in the batch\n",
        "#         position_ids = torch.arange(seq_len, device=device).unsqueeze(0).repeat(input_ids_batch.size(0), 1)\n",
        "\n",
        "#         # Use mixed precision context for the forward pass to save memory and speed up computation\n",
        "#         with autocast():\n",
        "#             outputs = model(\n",
        "#                 input_ids=input_ids_batch,        # Input token IDs for the model\n",
        "#                 attention_mask=attention_mask_batch,  # Attention mask to differentiate padded tokens\n",
        "#                 position_ids=position_ids,          # Positional IDs for the tokens\n",
        "#                 labels=labels_batch                 # Labels for computing the loss (typically same as input_ids for causal LM)\n",
        "#             )\n",
        "#             # Compute the loss; if using gradient accumulation, scale down the loss accordingly\n",
        "#             loss = outputs.loss / accumulation_steps\n",
        "\n",
        "#         # Scale the loss and perform the backward pass using the GradScaler for FP16 stability\n",
        "#         scaler.scale(loss).backward()\n",
        "\n",
        "#         # Every 'accumulation_steps' iterations, update the model weights\n",
        "#         if (i + 1) % accumulation_steps == 0:\n",
        "#             scaler.step(optimizer)  # Update parameters using scaled gradients\n",
        "#             scaler.update()         # Update the scale for the next iteration\n",
        "#             optimizer.zero_grad()   # Reset gradients after updating\n",
        "\n",
        "#         # Accumulate the loss (multiply back to undo the earlier division, so total_loss is in original scale)\n",
        "#         total_loss += loss.item() * accumulation_steps\n",
        "\n",
        "#         # Optionally, print progress every 50 batches\n",
        "#         if i % 50 == 0:\n",
        "#             print(f\"Batch {i} processed.\")\n",
        "\n",
        "#     # Compute the average loss over the epoch\n",
        "#     avg_loss = total_loss / len(train_loader)\n",
        "#     print(f\"Epoch {epoch+1}/{epochs} - Average loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "eCilSHLsfGGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    total_loss = 0.0\n",
        "    i = 0\n",
        "    for batch in train_loader:\n",
        "        if i%50 == 0:\n",
        "            print(i)\n",
        "        i+=1\n",
        "        # Move each element of the batch to the device.\n",
        "        # input_ids_batch, attention_mask_batch, labels_batch = [x.to(device) for x in batch]\n",
        "        input_ids_batch, attention_mask_batch, labels_batch = [x.to(device, non_blocking=True) for x in batch]\n",
        "\n",
        "        # Create a position_ids tensor: shape [batch_size, seq_len]\n",
        "        seq_len = input_ids_batch.size(1)\n",
        "        position_ids = torch.arange(seq_len, device=device).unsqueeze(0).repeat(input_ids_batch.size(0), 1)\n",
        "\n",
        "        # Forward pass: compute the loss.\n",
        "        outputs = model(\n",
        "            input_ids=input_ids_batch,\n",
        "            attention_mask=attention_mask_batch,\n",
        "            position_ids=position_ids,\n",
        "            labels=labels_batch\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Average loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Guo1CVB3fLLr",
        "outputId": "e2a85678-fb60-4a28-f054-641cd844f874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "400\n",
            "450\n",
            "500\n",
            "550\n",
            "600\n",
            "650\n",
            "700\n",
            "750\n",
            "800\n",
            "850\n",
            "900\n",
            "950\n",
            "1000\n",
            "1050\n",
            "1100\n",
            "1150\n",
            "1200\n",
            "1250\n",
            "1300\n",
            "1350\n",
            "1400\n",
            "1450\n",
            "1500\n",
            "1550\n",
            "1600\n",
            "1650\n",
            "1700\n",
            "1750\n",
            "1800\n",
            "1850\n",
            "1900\n",
            "1950\n",
            "2000\n",
            "2050\n",
            "2100\n",
            "2150\n",
            "2200\n",
            "2250\n",
            "2300\n",
            "2350\n",
            "2400\n",
            "2450\n",
            "2500\n",
            "2550\n",
            "2600\n",
            "2650\n",
            "2700\n",
            "2750\n",
            "2800\n",
            "2850\n",
            "2900\n",
            "2950\n",
            "3000\n",
            "3050\n",
            "3100\n",
            "3150\n",
            "3200\n",
            "3250\n",
            "3300\n",
            "3350\n",
            "3400\n",
            "3450\n",
            "3500\n",
            "3550\n",
            "3600\n",
            "3650\n",
            "3700\n",
            "3750\n",
            "3800\n",
            "3850\n",
            "3900\n",
            "3950\n",
            "4000\n",
            "4050\n",
            "4100\n",
            "4150\n",
            "4200\n",
            "4250\n",
            "4300\n",
            "4350\n",
            "4400\n",
            "4450\n",
            "4500\n",
            "4550\n",
            "4600\n",
            "4650\n",
            "4700\n",
            "4750\n",
            "4800\n",
            "4850\n",
            "4900\n",
            "4950\n",
            "5000\n",
            "5050\n",
            "5100\n",
            "5150\n",
            "5200\n",
            "5250\n",
            "5300\n",
            "5350\n",
            "5400\n",
            "5450\n",
            "5500\n",
            "5550\n",
            "5600\n",
            "5650\n",
            "5700\n",
            "5750\n",
            "5800\n",
            "5850\n",
            "5900\n",
            "5950\n",
            "6000\n",
            "6050\n",
            "6100\n",
            "6150\n",
            "6200\n",
            "6250\n",
            "6300\n",
            "6350\n",
            "6400\n",
            "6450\n",
            "6500\n",
            "6550\n",
            "6600\n",
            "6650\n",
            "6700\n",
            "6750\n",
            "6800\n",
            "6850\n",
            "6900\n",
            "6950\n",
            "7000\n",
            "7050\n",
            "7100\n",
            "7150\n",
            "7200\n",
            "7250\n",
            "7300\n",
            "7350\n",
            "7400\n",
            "7450\n",
            "7500\n",
            "7550\n",
            "7600\n",
            "7650\n",
            "7700\n",
            "7750\n",
            "7800\n",
            "7850\n",
            "7900\n",
            "7950\n",
            "8000\n",
            "8050\n",
            "8100\n",
            "8150\n",
            "8200\n",
            "8250\n",
            "8300\n",
            "8350\n",
            "8400\n",
            "8450\n",
            "8500\n",
            "8550\n",
            "8600\n",
            "8650\n",
            "8700\n",
            "8750\n",
            "8800\n",
            "8850\n",
            "8900\n",
            "8950\n",
            "9000\n",
            "9050\n",
            "9100\n",
            "9150\n",
            "9200\n",
            "9250\n",
            "9300\n",
            "9350\n",
            "9400\n",
            "9450\n",
            "9500\n",
            "9550\n",
            "9600\n",
            "9650\n",
            "9700\n",
            "9750\n",
            "9800\n",
            "9850\n",
            "9900\n",
            "9950\n",
            "10000\n",
            "10050\n",
            "10100\n",
            "10150\n",
            "10200\n",
            "10250\n",
            "10300\n",
            "10350\n",
            "10400\n",
            "10450\n",
            "10500\n",
            "10550\n",
            "10600\n",
            "10650\n",
            "10700\n",
            "10750\n",
            "10800\n",
            "10850\n",
            "10900\n",
            "10950\n",
            "11000\n",
            "11050\n",
            "11100\n",
            "11150\n",
            "11200\n",
            "11250\n",
            "11300\n",
            "11350\n",
            "11400\n",
            "11450\n",
            "11500\n",
            "11550\n",
            "11600\n",
            "11650\n",
            "11700\n",
            "11750\n",
            "11800\n",
            "11850\n",
            "11900\n",
            "11950\n",
            "12000\n",
            "12050\n",
            "12100\n",
            "12150\n",
            "12200\n",
            "12250\n",
            "12300\n",
            "12350\n",
            "12400\n",
            "12450\n",
            "12500\n",
            "12550\n",
            "12600\n",
            "12650\n",
            "12700\n",
            "12750\n",
            "12800\n",
            "12850\n",
            "12900\n",
            "12950\n",
            "13000\n",
            "13050\n",
            "13100\n",
            "13150\n",
            "13200\n",
            "13250\n",
            "13300\n",
            "13350\n",
            "13400\n",
            "13450\n",
            "13500\n",
            "13550\n",
            "13600\n",
            "13650\n",
            "13700\n",
            "13750\n",
            "13800\n",
            "13850\n",
            "13900\n",
            "13950\n",
            "14000\n",
            "14050\n",
            "14100\n",
            "14150\n",
            "14200\n",
            "14250\n",
            "14300\n",
            "14350\n",
            "14400\n",
            "14450\n",
            "14500\n",
            "14550\n",
            "14600\n",
            "14650\n",
            "14700\n",
            "14750\n",
            "14800\n",
            "14850\n",
            "14900\n",
            "14950\n",
            "15000\n",
            "15050\n",
            "15100\n",
            "15150\n",
            "15200\n",
            "15250\n",
            "15300\n",
            "15350\n",
            "15400\n",
            "15450\n",
            "15500\n",
            "15550\n",
            "15600\n",
            "15650\n",
            "15700\n",
            "15750\n",
            "15800\n",
            "15850\n",
            "15900\n",
            "15950\n",
            "16000\n",
            "16050\n",
            "16100\n",
            "16150\n",
            "16200\n",
            "16250\n",
            "16300\n",
            "16350\n",
            "16400\n",
            "16450\n",
            "16500\n",
            "16550\n",
            "16600\n",
            "16650\n",
            "16700\n",
            "16750\n",
            "16800\n",
            "16850\n",
            "16900\n",
            "16950\n",
            "17000\n",
            "17050\n",
            "17100\n",
            "17150\n",
            "17200\n",
            "17250\n",
            "17300\n",
            "17350\n",
            "17400\n",
            "17450\n",
            "17500\n",
            "17550\n",
            "17600\n",
            "17650\n",
            "17700\n",
            "17750\n",
            "17800\n",
            "17850\n",
            "17900\n",
            "17950\n",
            "18000\n",
            "18050\n",
            "18100\n",
            "18150\n",
            "18200\n",
            "18250\n",
            "18300\n",
            "18350\n",
            "18400\n",
            "18450\n",
            "18500\n",
            "18550\n",
            "18600\n",
            "18650\n",
            "18700\n",
            "18750\n",
            "18800\n",
            "18850\n",
            "18900\n",
            "18950\n",
            "19000\n",
            "19050\n",
            "19100\n",
            "19150\n",
            "19200\n",
            "19250\n",
            "19300\n",
            "19350\n",
            "19400\n",
            "19450\n",
            "19500\n",
            "19550\n",
            "19600\n",
            "19650\n",
            "19700\n",
            "19750\n",
            "19800\n",
            "19850\n",
            "19900\n",
            "19950\n",
            "20000\n",
            "20050\n",
            "20100\n",
            "20150\n",
            "20200\n",
            "20250\n",
            "20300\n",
            "20350\n",
            "20400\n",
            "20450\n",
            "20500\n",
            "20550\n",
            "20600\n",
            "20650\n",
            "20700\n",
            "20750\n",
            "20800\n",
            "20850\n",
            "20900\n",
            "20950\n",
            "21000\n",
            "21050\n",
            "21100\n",
            "21150\n",
            "21200\n",
            "21250\n",
            "21300\n",
            "21350\n",
            "21400\n",
            "21450\n",
            "21500\n",
            "21550\n",
            "21600\n",
            "21650\n",
            "21700\n",
            "21750\n",
            "21800\n",
            "21850\n",
            "21900\n",
            "21950\n",
            "22000\n",
            "22050\n",
            "22100\n",
            "22150\n",
            "22200\n",
            "22250\n",
            "22300\n",
            "22350\n",
            "22400\n",
            "22450\n",
            "22500\n",
            "22550\n",
            "22600\n",
            "22650\n",
            "22700\n",
            "22750\n",
            "22800\n",
            "22850\n",
            "22900\n",
            "22950\n",
            "23000\n",
            "23050\n",
            "23100\n",
            "23150\n",
            "23200\n",
            "23250\n",
            "23300\n",
            "23350\n",
            "23400\n",
            "23450\n",
            "23500\n",
            "23550\n",
            "23600\n",
            "23650\n",
            "23700\n",
            "23750\n",
            "23800\n",
            "23850\n",
            "23900\n",
            "23950\n",
            "24000\n",
            "24050\n",
            "24100\n",
            "24150\n",
            "24200\n",
            "24250\n",
            "24300\n",
            "24350\n",
            "24400\n",
            "24450\n",
            "24500\n",
            "24550\n",
            "24600\n",
            "24650\n",
            "24700\n",
            "24750\n",
            "24800\n",
            "24850\n",
            "24900\n",
            "24950\n",
            "Epoch 1/4 - Average loss: 1.5462\n",
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "400\n",
            "450\n",
            "500\n",
            "550\n",
            "600\n",
            "650\n",
            "700\n",
            "750\n",
            "800\n",
            "850\n",
            "900\n",
            "950\n",
            "1000\n",
            "1050\n",
            "1100\n",
            "1150\n",
            "1200\n",
            "1250\n",
            "1300\n",
            "1350\n",
            "1400\n",
            "1450\n",
            "1500\n",
            "1550\n",
            "1600\n",
            "1650\n",
            "1700\n",
            "1750\n",
            "1800\n",
            "1850\n",
            "1900\n",
            "1950\n",
            "2000\n",
            "2050\n",
            "2100\n",
            "2150\n",
            "2200\n",
            "2250\n",
            "2300\n",
            "2350\n",
            "2400\n",
            "2450\n",
            "2500\n",
            "2550\n",
            "2600\n",
            "2650\n",
            "2700\n",
            "2750\n",
            "2800\n",
            "2850\n",
            "2900\n",
            "2950\n",
            "3000\n",
            "3050\n",
            "3100\n",
            "3150\n",
            "3200\n",
            "3250\n",
            "3300\n",
            "3350\n",
            "3400\n",
            "3450\n",
            "3500\n",
            "3550\n",
            "3600\n",
            "3650\n",
            "3700\n",
            "3750\n",
            "3800\n",
            "3850\n",
            "3900\n",
            "3950\n",
            "4000\n",
            "4050\n",
            "4100\n",
            "4150\n",
            "4200\n",
            "4250\n",
            "4300\n",
            "4350\n",
            "4400\n",
            "4450\n",
            "4500\n",
            "4550\n",
            "4600\n",
            "4650\n",
            "4700\n",
            "4750\n",
            "4800\n",
            "4850\n",
            "4900\n",
            "4950\n",
            "5000\n",
            "5050\n",
            "5100\n",
            "5150\n",
            "5200\n",
            "5250\n",
            "5300\n",
            "5350\n",
            "5400\n",
            "5450\n",
            "5500\n",
            "5550\n",
            "5600\n",
            "5650\n",
            "5700\n",
            "5750\n",
            "5800\n",
            "5850\n",
            "5900\n",
            "5950\n",
            "6000\n",
            "6050\n",
            "6100\n",
            "6150\n",
            "6200\n",
            "6250\n",
            "6300\n",
            "6350\n",
            "6400\n",
            "6450\n",
            "6500\n",
            "6550\n",
            "6600\n",
            "6650\n",
            "6700\n",
            "6750\n",
            "6800\n",
            "6850\n",
            "6900\n",
            "6950\n",
            "7000\n",
            "7050\n",
            "7100\n",
            "7150\n",
            "7200\n",
            "7250\n",
            "7300\n",
            "7350\n",
            "7400\n",
            "7450\n",
            "7500\n",
            "7550\n",
            "7600\n",
            "7650\n",
            "7700\n",
            "7750\n",
            "7800\n",
            "7850\n",
            "7900\n",
            "7950\n",
            "8000\n",
            "8050\n",
            "8100\n",
            "8150\n",
            "8200\n",
            "8250\n",
            "8300\n",
            "8350\n",
            "8400\n",
            "8450\n",
            "8500\n",
            "8550\n",
            "8600\n",
            "8650\n",
            "8700\n",
            "8750\n",
            "8800\n",
            "8850\n",
            "8900\n",
            "8950\n",
            "9000\n",
            "9050\n",
            "9100\n",
            "9150\n",
            "9200\n",
            "9250\n",
            "9300\n",
            "9350\n",
            "9400\n",
            "9450\n",
            "9500\n",
            "9550\n",
            "9600\n",
            "9650\n",
            "9700\n",
            "9750\n",
            "9800\n",
            "9850\n",
            "9900\n",
            "9950\n",
            "10000\n",
            "10050\n",
            "10100\n",
            "10150\n",
            "10200\n",
            "10250\n",
            "10300\n",
            "10350\n",
            "10400\n",
            "10450\n",
            "10500\n",
            "10550\n",
            "10600\n",
            "10650\n",
            "10700\n",
            "10750\n",
            "10800\n",
            "10850\n",
            "10900\n",
            "10950\n",
            "11000\n",
            "11050\n",
            "11100\n",
            "11150\n",
            "11200\n",
            "11250\n",
            "11300\n",
            "11350\n",
            "11400\n",
            "11450\n",
            "11500\n",
            "11550\n",
            "11600\n",
            "11650\n",
            "11700\n",
            "11750\n",
            "11800\n",
            "11850\n",
            "11900\n",
            "11950\n",
            "12000\n",
            "12050\n",
            "12100\n",
            "12150\n",
            "12200\n",
            "12250\n",
            "12300\n",
            "12350\n",
            "12400\n",
            "12450\n",
            "12500\n",
            "12550\n",
            "12600\n",
            "12650\n",
            "12700\n",
            "12750\n",
            "12800\n",
            "12850\n",
            "12900\n",
            "12950\n",
            "13000\n",
            "13050\n",
            "13100\n",
            "13150\n",
            "13200\n",
            "13250\n",
            "13300\n",
            "13350\n",
            "13400\n",
            "13450\n",
            "13500\n",
            "13550\n",
            "13600\n",
            "13650\n",
            "13700\n",
            "13750\n",
            "13800\n",
            "13850\n",
            "13900\n",
            "13950\n",
            "14000\n",
            "14050\n",
            "14100\n",
            "14150\n",
            "14200\n",
            "14250\n",
            "14300\n",
            "14350\n",
            "14400\n",
            "14450\n",
            "14500\n",
            "14550\n",
            "14600\n",
            "14650\n",
            "14700\n",
            "14750\n",
            "14800\n",
            "14850\n",
            "14900\n",
            "14950\n",
            "15000\n",
            "15050\n",
            "15100\n",
            "15150\n",
            "15200\n",
            "15250\n",
            "15300\n",
            "15350\n",
            "15400\n",
            "15450\n",
            "15500\n",
            "15550\n",
            "15600\n",
            "15650\n",
            "15700\n",
            "15750\n",
            "15800\n",
            "15850\n",
            "15900\n",
            "15950\n",
            "16000\n",
            "16050\n",
            "16100\n",
            "16150\n",
            "16200\n",
            "16250\n",
            "16300\n",
            "16350\n",
            "16400\n",
            "16450\n",
            "16500\n",
            "16550\n",
            "16600\n",
            "16650\n",
            "16700\n",
            "16750\n",
            "16800\n",
            "16850\n",
            "16900\n",
            "16950\n",
            "17000\n",
            "17050\n",
            "17100\n",
            "17150\n",
            "17200\n",
            "17250\n",
            "17300\n",
            "17350\n",
            "17400\n",
            "17450\n",
            "17500\n",
            "17550\n",
            "17600\n",
            "17650\n",
            "17700\n",
            "17750\n",
            "17800\n",
            "17850\n",
            "17900\n",
            "17950\n",
            "18000\n",
            "18050\n",
            "18100\n",
            "18150\n",
            "18200\n",
            "18250\n",
            "18300\n",
            "18350\n",
            "18400\n",
            "18450\n",
            "18500\n",
            "18550\n",
            "18600\n",
            "18650\n",
            "18700\n",
            "18750\n",
            "18800\n",
            "18850\n",
            "18900\n",
            "18950\n",
            "19000\n",
            "19050\n",
            "19100\n",
            "19150\n",
            "19200\n",
            "19250\n",
            "19300\n",
            "19350\n",
            "19400\n",
            "19450\n",
            "19500\n",
            "19550\n",
            "19600\n",
            "19650\n",
            "19700\n",
            "19750\n",
            "19800\n",
            "19850\n",
            "19900\n",
            "19950\n",
            "20000\n",
            "20050\n",
            "20100\n",
            "20150\n",
            "20200\n",
            "20250\n",
            "20300\n",
            "20350\n",
            "20400\n",
            "20450\n",
            "20500\n",
            "20550\n",
            "20600\n",
            "20650\n",
            "20700\n",
            "20750\n",
            "20800\n",
            "20850\n",
            "20900\n",
            "20950\n",
            "21000\n",
            "21050\n",
            "21100\n",
            "21150\n",
            "21200\n",
            "21250\n",
            "21300\n",
            "21350\n",
            "21400\n",
            "21450\n",
            "21500\n",
            "21550\n",
            "21600\n",
            "21650\n",
            "21700\n",
            "21750\n",
            "21800\n",
            "21850\n",
            "21900\n",
            "21950\n",
            "22000\n",
            "22050\n",
            "22100\n",
            "22150\n",
            "22200\n",
            "22250\n",
            "22300\n",
            "22350\n",
            "22400\n",
            "22450\n",
            "22500\n",
            "22550\n",
            "22600\n",
            "22650\n",
            "22700\n",
            "22750\n",
            "22800\n",
            "22850\n",
            "22900\n",
            "22950\n",
            "23000\n",
            "23050\n",
            "23100\n",
            "23150\n",
            "23200\n",
            "23250\n",
            "23300\n",
            "23350\n",
            "23400\n",
            "23450\n",
            "23500\n",
            "23550\n",
            "23600\n",
            "23650\n",
            "23700\n",
            "23750\n",
            "23800\n",
            "23850\n",
            "23900\n",
            "23950\n",
            "24000\n",
            "24050\n",
            "24100\n",
            "24150\n",
            "24200\n",
            "24250\n",
            "24300\n",
            "24350\n",
            "24400\n",
            "24450\n",
            "24500\n",
            "24550\n",
            "24600\n",
            "24650\n",
            "24700\n",
            "24750\n",
            "24800\n",
            "24850\n",
            "24900\n",
            "24950\n",
            "Epoch 2/4 - Average loss: 1.5067\n",
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "400\n",
            "450\n",
            "500\n",
            "550\n",
            "600\n",
            "650\n",
            "700\n",
            "750\n",
            "800\n",
            "850\n",
            "900\n",
            "950\n",
            "1000\n",
            "1050\n",
            "1100\n",
            "1150\n",
            "1200\n",
            "1250\n",
            "1300\n",
            "1350\n",
            "1400\n",
            "1450\n",
            "1500\n",
            "1550\n",
            "1600\n",
            "1650\n",
            "1700\n",
            "1750\n",
            "1800\n",
            "1850\n",
            "1900\n",
            "1950\n",
            "2000\n",
            "2050\n",
            "2100\n",
            "2150\n",
            "2200\n",
            "2250\n",
            "2300\n",
            "2350\n",
            "2400\n",
            "2450\n",
            "2500\n",
            "2550\n",
            "2600\n",
            "2650\n",
            "2700\n",
            "2750\n",
            "2800\n",
            "2850\n",
            "2900\n",
            "2950\n",
            "3000\n",
            "3050\n",
            "3100\n",
            "3150\n",
            "3200\n",
            "3250\n",
            "3300\n",
            "3350\n",
            "3400\n",
            "3450\n",
            "3500\n",
            "3550\n",
            "3600\n",
            "3650\n",
            "3700\n",
            "3750\n",
            "3800\n",
            "3850\n",
            "3900\n",
            "3950\n",
            "4000\n",
            "4050\n",
            "4100\n",
            "4150\n",
            "4200\n",
            "4250\n",
            "4300\n",
            "4350\n",
            "4400\n",
            "4450\n",
            "4500\n",
            "4550\n",
            "4600\n",
            "4650\n",
            "4700\n",
            "4750\n",
            "4800\n",
            "4850\n",
            "4900\n",
            "4950\n",
            "5000\n",
            "5050\n",
            "5100\n",
            "5150\n",
            "5200\n",
            "5250\n",
            "5300\n",
            "5350\n",
            "5400\n",
            "5450\n",
            "5500\n",
            "5550\n",
            "5600\n",
            "5650\n",
            "5700\n",
            "5750\n",
            "5800\n",
            "5850\n",
            "5900\n",
            "5950\n",
            "6000\n",
            "6050\n",
            "6100\n",
            "6150\n",
            "6200\n",
            "6250\n",
            "6300\n",
            "6350\n",
            "6400\n",
            "6450\n",
            "6500\n",
            "6550\n",
            "6600\n",
            "6650\n",
            "6700\n",
            "6750\n",
            "6800\n",
            "6850\n",
            "6900\n",
            "6950\n",
            "7000\n",
            "7050\n",
            "7100\n",
            "7150\n",
            "7200\n",
            "7250\n",
            "7300\n",
            "7350\n",
            "7400\n",
            "7450\n",
            "7500\n",
            "7550\n",
            "7600\n",
            "7650\n",
            "7700\n",
            "7750\n",
            "7800\n",
            "7850\n",
            "7900\n",
            "7950\n",
            "8000\n",
            "8050\n",
            "8100\n",
            "8150\n",
            "8200\n",
            "8250\n",
            "8300\n",
            "8350\n",
            "8400\n",
            "8450\n",
            "8500\n",
            "8550\n",
            "8600\n",
            "8650\n",
            "8700\n",
            "8750\n",
            "8800\n",
            "8850\n",
            "8900\n",
            "8950\n",
            "9000\n",
            "9050\n",
            "9100\n",
            "9150\n",
            "9200\n",
            "9250\n",
            "9300\n",
            "9350\n",
            "9400\n",
            "9450\n",
            "9500\n",
            "9550\n",
            "9600\n",
            "9650\n",
            "9700\n",
            "9750\n",
            "9800\n",
            "9850\n",
            "9900\n",
            "9950\n",
            "10000\n",
            "10050\n",
            "10100\n",
            "10150\n",
            "10200\n",
            "10250\n",
            "10300\n",
            "10350\n",
            "10400\n",
            "10450\n",
            "10500\n",
            "10550\n",
            "10600\n",
            "10650\n",
            "10700\n",
            "10750\n",
            "10800\n",
            "10850\n",
            "10900\n",
            "10950\n",
            "11000\n",
            "11050\n",
            "11100\n",
            "11150\n",
            "11200\n",
            "11250\n",
            "11300\n",
            "11350\n",
            "11400\n",
            "11450\n",
            "11500\n",
            "11550\n",
            "11600\n",
            "11650\n",
            "11700\n",
            "11750\n",
            "11800\n",
            "11850\n",
            "11900\n",
            "11950\n",
            "12000\n",
            "12050\n",
            "12100\n",
            "12150\n",
            "12200\n",
            "12250\n",
            "12300\n",
            "12350\n",
            "12400\n",
            "12450\n",
            "12500\n",
            "12550\n",
            "12600\n",
            "12650\n",
            "12700\n",
            "12750\n",
            "12800\n",
            "12850\n",
            "12900\n",
            "12950\n",
            "13000\n",
            "13050\n",
            "13100\n",
            "13150\n",
            "13200\n",
            "13250\n",
            "13300\n",
            "13350\n",
            "13400\n",
            "13450\n",
            "13500\n",
            "13550\n",
            "13600\n",
            "13650\n",
            "13700\n",
            "13750\n",
            "13800\n",
            "13850\n",
            "13900\n",
            "13950\n",
            "14000\n",
            "14050\n",
            "14100\n",
            "14150\n",
            "14200\n",
            "14250\n",
            "14300\n",
            "14350\n",
            "14400\n",
            "14450\n",
            "14500\n",
            "14550\n",
            "14600\n",
            "14650\n",
            "14700\n",
            "14750\n",
            "14800\n",
            "14850\n",
            "14900\n",
            "14950\n",
            "15000\n",
            "15050\n",
            "15100\n",
            "15150\n",
            "15200\n",
            "15250\n",
            "15300\n",
            "15350\n",
            "15400\n",
            "15450\n",
            "15500\n",
            "15550\n",
            "15600\n",
            "15650\n",
            "15700\n",
            "15750\n",
            "15800\n",
            "15850\n",
            "15900\n",
            "15950\n",
            "16000\n",
            "16050\n",
            "16100\n",
            "16150\n",
            "16200\n",
            "16250\n",
            "16300\n",
            "16350\n",
            "16400\n",
            "16450\n",
            "16500\n",
            "16550\n",
            "16600\n",
            "16650\n",
            "16700\n",
            "16750\n",
            "16800\n",
            "16850\n",
            "16900\n",
            "16950\n",
            "17000\n",
            "17050\n",
            "17100\n",
            "17150\n",
            "17200\n",
            "17250\n",
            "17300\n",
            "17350\n",
            "17400\n",
            "17450\n",
            "17500\n",
            "17550\n",
            "17600\n",
            "17650\n",
            "17700\n",
            "17750\n",
            "17800\n",
            "17850\n",
            "17900\n",
            "17950\n",
            "18000\n",
            "18050\n",
            "18100\n",
            "18150\n",
            "18200\n",
            "18250\n",
            "18300\n",
            "18350\n",
            "18400\n",
            "18450\n",
            "18500\n",
            "18550\n",
            "18600\n",
            "18650\n",
            "18700\n",
            "18750\n",
            "18800\n",
            "18850\n",
            "18900\n",
            "18950\n",
            "19000\n",
            "19050\n",
            "19100\n",
            "19150\n",
            "19200\n",
            "19250\n",
            "19300\n",
            "19350\n",
            "19400\n",
            "19450\n",
            "19500\n",
            "19550\n",
            "19600\n",
            "19650\n",
            "19700\n",
            "19750\n",
            "19800\n",
            "19850\n",
            "19900\n",
            "19950\n",
            "20000\n",
            "20050\n",
            "20100\n",
            "20150\n",
            "20200\n",
            "20250\n",
            "20300\n",
            "20350\n",
            "20400\n",
            "20450\n",
            "20500\n",
            "20550\n",
            "20600\n",
            "20650\n",
            "20700\n",
            "20750\n",
            "20800\n",
            "20850\n",
            "20900\n",
            "20950\n",
            "21000\n",
            "21050\n",
            "21100\n",
            "21150\n",
            "21200\n",
            "21250\n",
            "21300\n",
            "21350\n",
            "21400\n",
            "21450\n",
            "21500\n",
            "21550\n",
            "21600\n",
            "21650\n",
            "21700\n",
            "21750\n",
            "21800\n",
            "21850\n",
            "21900\n",
            "21950\n",
            "22000\n",
            "22050\n",
            "22100\n",
            "22150\n",
            "22200\n",
            "22250\n",
            "22300\n",
            "22350\n",
            "22400\n",
            "22450\n",
            "22500\n",
            "22550\n",
            "22600\n",
            "22650\n",
            "22700\n",
            "22750\n",
            "22800\n",
            "22850\n",
            "22900\n",
            "22950\n",
            "23000\n",
            "23050\n",
            "23100\n",
            "23150\n",
            "23200\n",
            "23250\n",
            "23300\n",
            "23350\n",
            "23400\n",
            "23450\n",
            "23500\n",
            "23550\n",
            "23600\n",
            "23650\n",
            "23700\n",
            "23750\n",
            "23800\n",
            "23850\n",
            "23900\n",
            "23950\n",
            "24000\n",
            "24050\n",
            "24100\n",
            "24150\n",
            "24200\n",
            "24250\n",
            "24300\n",
            "24350\n",
            "24400\n",
            "24450\n",
            "24500\n",
            "24550\n",
            "24600\n",
            "24650\n",
            "24700\n",
            "24750\n",
            "24800\n",
            "24850\n",
            "24900\n",
            "24950\n",
            "Epoch 3/4 - Average loss: 1.4784\n",
            "0\n",
            "50\n",
            "100\n",
            "150\n",
            "200\n",
            "250\n",
            "300\n",
            "350\n",
            "400\n",
            "450\n",
            "500\n",
            "550\n",
            "600\n",
            "650\n",
            "700\n",
            "750\n",
            "800\n",
            "850\n",
            "900\n",
            "950\n",
            "1000\n",
            "1050\n",
            "1100\n",
            "1150\n",
            "1200\n",
            "1250\n",
            "1300\n",
            "1350\n",
            "1400\n",
            "1450\n",
            "1500\n",
            "1550\n",
            "1600\n",
            "1650\n",
            "1700\n",
            "1750\n",
            "1800\n",
            "1850\n",
            "1900\n",
            "1950\n",
            "2000\n",
            "2050\n",
            "2100\n",
            "2150\n",
            "2200\n",
            "2250\n",
            "2300\n",
            "2350\n",
            "2400\n",
            "2450\n",
            "2500\n",
            "2550\n",
            "2600\n",
            "2650\n",
            "2700\n",
            "2750\n",
            "2800\n",
            "2850\n",
            "2900\n",
            "2950\n",
            "3000\n",
            "3050\n",
            "3100\n",
            "3150\n",
            "3200\n",
            "3250\n",
            "3300\n",
            "3350\n",
            "3400\n",
            "3450\n",
            "3500\n",
            "3550\n",
            "3600\n",
            "3650\n",
            "3700\n",
            "3750\n",
            "3800\n",
            "3850\n",
            "3900\n",
            "3950\n",
            "4000\n",
            "4050\n",
            "4100\n",
            "4150\n",
            "4200\n",
            "4250\n",
            "4300\n",
            "4350\n",
            "4400\n",
            "4450\n",
            "4500\n",
            "4550\n",
            "4600\n",
            "4650\n",
            "4700\n",
            "4750\n",
            "4800\n",
            "4850\n",
            "4900\n",
            "4950\n",
            "5000\n",
            "5050\n",
            "5100\n",
            "5150\n",
            "5200\n",
            "5250\n",
            "5300\n",
            "5350\n",
            "5400\n",
            "5450\n",
            "5500\n",
            "5550\n",
            "5600\n",
            "5650\n",
            "5700\n",
            "5750\n",
            "5800\n",
            "5850\n",
            "5900\n",
            "5950\n",
            "6000\n",
            "6050\n",
            "6100\n",
            "6150\n",
            "6200\n",
            "6250\n",
            "6300\n",
            "6350\n",
            "6400\n",
            "6450\n",
            "6500\n",
            "6550\n",
            "6600\n",
            "6650\n",
            "6700\n",
            "6750\n",
            "6800\n",
            "6850\n",
            "6900\n",
            "6950\n",
            "7000\n",
            "7050\n",
            "7100\n",
            "7150\n",
            "7200\n",
            "7250\n",
            "7300\n",
            "7350\n",
            "7400\n",
            "7450\n",
            "7500\n",
            "7550\n",
            "7600\n",
            "7650\n",
            "7700\n",
            "7750\n",
            "7800\n",
            "7850\n",
            "7900\n",
            "7950\n",
            "8000\n",
            "8050\n",
            "8100\n",
            "8150\n",
            "8200\n",
            "8250\n",
            "8300\n",
            "8350\n",
            "8400\n",
            "8450\n",
            "8500\n",
            "8550\n",
            "8600\n",
            "8650\n",
            "8700\n",
            "8750\n",
            "8800\n",
            "8850\n",
            "8900\n",
            "8950\n",
            "9000\n",
            "9050\n",
            "9100\n",
            "9150\n",
            "9200\n",
            "9250\n",
            "9300\n",
            "9350\n",
            "9400\n",
            "9450\n",
            "9500\n",
            "9550\n",
            "9600\n",
            "9650\n",
            "9700\n",
            "9750\n",
            "9800\n",
            "9850\n",
            "9900\n",
            "9950\n",
            "10000\n",
            "10050\n",
            "10100\n",
            "10150\n",
            "10200\n",
            "10250\n",
            "10300\n",
            "10350\n",
            "10400\n",
            "10450\n",
            "10500\n",
            "10550\n",
            "10600\n",
            "10650\n",
            "10700\n",
            "10750\n",
            "10800\n",
            "10850\n",
            "10900\n",
            "10950\n",
            "11000\n",
            "11050\n",
            "11100\n",
            "11150\n",
            "11200\n",
            "11250\n",
            "11300\n",
            "11350\n",
            "11400\n",
            "11450\n",
            "11500\n",
            "11550\n",
            "11600\n",
            "11650\n",
            "11700\n",
            "11750\n",
            "11800\n",
            "11850\n",
            "11900\n",
            "11950\n",
            "12000\n",
            "12050\n",
            "12100\n",
            "12150\n",
            "12200\n",
            "12250\n",
            "12300\n",
            "12350\n",
            "12400\n",
            "12450\n",
            "12500\n",
            "12550\n",
            "12600\n",
            "12650\n",
            "12700\n",
            "12750\n",
            "12800\n",
            "12850\n",
            "12900\n",
            "12950\n",
            "13000\n",
            "13050\n",
            "13100\n",
            "13150\n",
            "13200\n",
            "13250\n",
            "13300\n",
            "13350\n",
            "13400\n",
            "13450\n",
            "13500\n",
            "13550\n",
            "13600\n",
            "13650\n",
            "13700\n",
            "13750\n",
            "13800\n",
            "13850\n",
            "13900\n",
            "13950\n",
            "14000\n",
            "14050\n",
            "14100\n",
            "14150\n",
            "14200\n",
            "14250\n",
            "14300\n",
            "14350\n",
            "14400\n",
            "14450\n",
            "14500\n",
            "14550\n",
            "14600\n",
            "14650\n",
            "14700\n",
            "14750\n",
            "14800\n",
            "14850\n",
            "14900\n",
            "14950\n",
            "15000\n",
            "15050\n",
            "15100\n",
            "15150\n",
            "15200\n",
            "15250\n",
            "15300\n",
            "15350\n",
            "15400\n",
            "15450\n",
            "15500\n",
            "15550\n",
            "15600\n",
            "15650\n",
            "15700\n",
            "15750\n",
            "15800\n",
            "15850\n",
            "15900\n",
            "15950\n",
            "16000\n",
            "16050\n",
            "16100\n",
            "16150\n",
            "16200\n",
            "16250\n",
            "16300\n",
            "16350\n",
            "16400\n",
            "16450\n",
            "16500\n",
            "16550\n",
            "16600\n",
            "16650\n",
            "16700\n",
            "16750\n",
            "16800\n",
            "16850\n",
            "16900\n",
            "16950\n",
            "17000\n",
            "17050\n",
            "17100\n",
            "17150\n",
            "17200\n",
            "17250\n",
            "17300\n",
            "17350\n",
            "17400\n",
            "17450\n",
            "17500\n",
            "17550\n",
            "17600\n",
            "17650\n",
            "17700\n",
            "17750\n",
            "17800\n",
            "17850\n",
            "17900\n",
            "17950\n",
            "18000\n",
            "18050\n",
            "18100\n",
            "18150\n",
            "18200\n",
            "18250\n",
            "18300\n",
            "18350\n",
            "18400\n",
            "18450\n",
            "18500\n",
            "18550\n",
            "18600\n",
            "18650\n",
            "18700\n",
            "18750\n",
            "18800\n",
            "18850\n",
            "18900\n",
            "18950\n",
            "19000\n",
            "19050\n",
            "19100\n",
            "19150\n",
            "19200\n",
            "19250\n",
            "19300\n",
            "19350\n",
            "19400\n",
            "19450\n",
            "19500\n",
            "19550\n",
            "19600\n",
            "19650\n",
            "19700\n",
            "19750\n",
            "19800\n",
            "19850\n",
            "19900\n",
            "19950\n",
            "20000\n",
            "20050\n",
            "20100\n",
            "20150\n",
            "20200\n",
            "20250\n",
            "20300\n",
            "20350\n",
            "20400\n",
            "20450\n",
            "20500\n",
            "20550\n",
            "20600\n",
            "20650\n",
            "20700\n",
            "20750\n",
            "20800\n",
            "20850\n",
            "20900\n",
            "20950\n",
            "21000\n",
            "21050\n",
            "21100\n",
            "21150\n",
            "21200\n",
            "21250\n",
            "21300\n",
            "21350\n",
            "21400\n",
            "21450\n",
            "21500\n",
            "21550\n",
            "21600\n",
            "21650\n",
            "21700\n",
            "21750\n",
            "21800\n",
            "21850\n",
            "21900\n",
            "21950\n",
            "22000\n",
            "22050\n",
            "22100\n",
            "22150\n",
            "22200\n",
            "22250\n",
            "22300\n",
            "22350\n",
            "22400\n",
            "22450\n",
            "22500\n",
            "22550\n",
            "22600\n",
            "22650\n",
            "22700\n",
            "22750\n",
            "22800\n",
            "22850\n",
            "22900\n",
            "22950\n",
            "23000\n",
            "23050\n",
            "23100\n",
            "23150\n",
            "23200\n",
            "23250\n",
            "23300\n",
            "23350\n",
            "23400\n",
            "23450\n",
            "23500\n",
            "23550\n",
            "23600\n",
            "23650\n",
            "23700\n",
            "23750\n",
            "23800\n",
            "23850\n",
            "23900\n",
            "23950\n",
            "24000\n",
            "24050\n",
            "24100\n",
            "24150\n",
            "24200\n",
            "24250\n",
            "24300\n",
            "24350\n",
            "24400\n",
            "24450\n",
            "24500\n",
            "24550\n",
            "24600\n",
            "24650\n",
            "24700\n",
            "24750\n",
            "24800\n",
            "24850\n",
            "24900\n",
            "24950\n",
            "Epoch 4/4 - Average loss: 1.4582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the privacy budget\n",
        "# epsilon = privacy_engine.accountant.get_epsilon(delta=1e-5)\n",
        "# print(f\"Achieved privacy budget: Îµ = {epsilon:.2f}\")"
      ],
      "metadata": {
        "id": "cTiursX1fXRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sjccWWMIFZi"
      },
      "source": [
        "## Model saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNz9DicrIGdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0b78da-50fc-45c0-bf62-e8207258f783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer saved to ./finetuned_model_dp\n"
          ]
        }
      ],
      "source": [
        "# Remove DP hooks to restore the underlying model.\n",
        "# model.remove_hooks()\n",
        "# model = model._module  # Unwrap the model.\n",
        "\n",
        "# Specify the directory where you want to save your fine-tuned model\n",
        "save_directory = \"./finetuned_model_dp\"\n",
        "\n",
        "# Save the model weights and configuration\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "# Save the tokenizer (this ensures that any custom tokens are preserved)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {save_directory}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3pAtkLcIIDl"
      },
      "source": [
        "## Interactive testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUKEFCVeIJ7P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "88731373-177c-4b41-8983-9cbc7b6ff167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: System prompt : Given the Rating and Title, you are required to generate the review\" | \"Rating\": 4 | \"Title\": No white background! Itâ€™s clear! | \"Review\":\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text: System prompt : Given the Rating and Title, you are required to generate the review\" | \"Rating\": 4 | \"Title\": No white background! Itâ€™s clear! | \"Review\": I was looking for a white background, but this is clear.  Itâ€™s a little bit thick but I like it.  Itâ€™s a little difficult to remove the case to put on my phone.  I also have a hard time removing it to put on a popsocket.  I think itâ€™s because of the thickness of the case.  I like the feel of it.  Iâ€™m glad I purchased this case.  I like that itâ€™s clear.  Iâ€™ve had a couple of cases that are white.  I didnâ€™t like that it would get dirty quickly.  I would have to wash it to get it clean.  This case is clear so itâ€™s easy to clean.  I like that.  I also like that itâ€™s a little bit thicker.  I like the feel of it.  Itâ€™s a little bit difficult to put on my phone.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m glad I purchased this case.  Iâ€™m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-18ffba9cb28d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate using a sample prompt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msample_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_prompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bye\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# Evaluate using a sample prompt.\n",
        "while True:\n",
        "    sample_prompt = input(\"Input: \")\n",
        "    if sample_prompt.lower() == \"bye\":\n",
        "        break\n",
        "    enc = tokenizer(sample_prompt, return_tensors='pt', padding=True, truncation=True)\n",
        "    enc = {k: v.to(device, non_blocking=True) for k, v in enc.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(**enc, max_length=512, do_sample=True, top_k=50)\n",
        "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "    print(\"Generated text:\", generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# while True:\n",
        "#     sample_prompt = input(\"Input: \")\n",
        "#     if sample_prompt.lower() == \"bye\":\n",
        "#         break\n",
        "#     enc = tokenizer(sample_prompt, return_tensors='pt', padding=True, truncation=True)\n",
        "#     enc = {k: v.to(device) for k, v in enc.items()}\n",
        "#     generated_ids = model.generate(**enc, max_length=512, do_sample=True, top_k=50)\n",
        "#     generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "#     print(\"Generated text:\", generated_text)\n",
        "\n",
        "    #lora_alpha = 4\n",
        "    #reduce loss to 2e-5"
      ],
      "metadata": {
        "id": "j8tihiLKfm-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KwPM3hdJr1ez",
        "g8WJhCIZMuRB",
        "ykEN9tloMw_h",
        "M8h8bWh_HRTv",
        "Fulb2eoMHXBD",
        "Yda7cPXHH9kl",
        "9sjccWWMIFZi"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1907ac972b6d4f0297b214d61579e0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37cacc72e923417fa1c1b3de0e62eb12",
              "IPY_MODEL_f5f5a764b9804b2bba539b7d5da10f8e",
              "IPY_MODEL_13be1480f43e4561b56dca7638369163"
            ],
            "layout": "IPY_MODEL_f4a41351ab1947608e88ddf919620388"
          }
        },
        "37cacc72e923417fa1c1b3de0e62eb12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c68409228e24b1d897ae163679b4855",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_77a7759ea5074fcabd6b9e157f0cf429",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "f5f5a764b9804b2bba539b7d5da10f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23049770af8442a189b35b99fc2ae6ae",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_567a0c15fd1f4edf9188697a27945131",
            "value": 4
          }
        },
        "13be1480f43e4561b56dca7638369163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b903bca9e37f4e6884167a4a9598a68b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ace4390e2ea447999d67e42bf2ac9d12",
            "value": "â€‡4/4â€‡[00:12&lt;00:00,â€‡â€‡2.68s/it]"
          }
        },
        "f4a41351ab1947608e88ddf919620388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c68409228e24b1d897ae163679b4855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a7759ea5074fcabd6b9e157f0cf429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23049770af8442a189b35b99fc2ae6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567a0c15fd1f4edf9188697a27945131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b903bca9e37f4e6884167a4a9598a68b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ace4390e2ea447999d67e42bf2ac9d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}