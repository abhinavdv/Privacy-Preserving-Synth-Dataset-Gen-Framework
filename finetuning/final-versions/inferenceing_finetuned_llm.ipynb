{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOpMPoWdwCgl5y4UIlwdOs8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"94224dad3a3d406b868ea6ccbe4b5214":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29f88fd0375d403c871a5a906c310c05","IPY_MODEL_b0a3912670394a53a07917f83a60fca5","IPY_MODEL_cf6107dcc304471682f62193f4d70933"],"layout":"IPY_MODEL_2dd43f88e8dd42ac8e4073e29520e83f"}},"29f88fd0375d403c871a5a906c310c05":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7939754ed769420b851765dc463bf74c","placeholder":"​","style":"IPY_MODEL_6603f2dce2c44b6d9c4fb045a68eb390","value":"Loading checkpoint shards: 100%"}},"b0a3912670394a53a07917f83a60fca5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d435f4235ac044a6a58cae4b2cf48a3d","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1970f2de7eed4a22a24dca30e1ea04da","value":4}},"cf6107dcc304471682f62193f4d70933":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b41d33f164dc43789505a5eb1df05527","placeholder":"​","style":"IPY_MODEL_dbbcf0d981344559a0b8fe9edd5e20cd","value":" 4/4 [00:05&lt;00:00,  1.25s/it]"}},"2dd43f88e8dd42ac8e4073e29520e83f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7939754ed769420b851765dc463bf74c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6603f2dce2c44b6d9c4fb045a68eb390":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d435f4235ac044a6a58cae4b2cf48a3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1970f2de7eed4a22a24dca30e1ea04da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b41d33f164dc43789505a5eb1df05527":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbbcf0d981344559a0b8fe9edd5e20cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef29e8c75f534b2086607ed34a1d415b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd91d8f64c6c4245b2ab4da4b3a0631a","IPY_MODEL_466c6c4ca62741dc897203ea7442126a","IPY_MODEL_511c63ff4bc94343b3f388444ef3beff"],"layout":"IPY_MODEL_b69f4175a6854a0c811ef5543ce58115"}},"cd91d8f64c6c4245b2ab4da4b3a0631a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f9d86ea12b2435fb426ac568e09ec58","placeholder":"​","style":"IPY_MODEL_8dcc78311eae46c7b6e052af21e40237","value":"Loading checkpoint shards: 100%"}},"466c6c4ca62741dc897203ea7442126a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24a3ebd3d21f42619d124cbe80dae86f","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c6344a46d6945b394fc06e36af39dc9","value":4}},"511c63ff4bc94343b3f388444ef3beff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a74ff6d05dea4234909b77be75dadc88","placeholder":"​","style":"IPY_MODEL_92289edb213248659b2212e46e209771","value":" 4/4 [00:05&lt;00:00,  1.14s/it]"}},"b69f4175a6854a0c811ef5543ce58115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f9d86ea12b2435fb426ac568e09ec58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8dcc78311eae46c7b6e052af21e40237":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24a3ebd3d21f42619d124cbe80dae86f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c6344a46d6945b394fc06e36af39dc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a74ff6d05dea4234909b77be75dadc88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92289edb213248659b2212e46e209771":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## Get first 10000 rows modified"],"metadata":{"id":"h26ztkBZiKtC"}},{"cell_type":"code","source":["import json\n","\n","formatted_strings = []\n","\n","with open(\"train.jsonl\", \"r\") as f:\n","    for j, line in enumerate(f):\n","        if j >= 10000:\n","            break\n","        # Parse the JSON data from the line\n","        data = json.loads(line.strip())\n","        rating = data['Rating']\n","        title = data['Title']\n","        review = data['Review']\n","\n","        # If \"Title: \" appears in the review, trim off everything after its first occurrence.\n","        title_marker_index = review.find(\"Title: \")\n","        if title_marker_index != -1:\n","            review = review[:title_marker_index]\n","\n","        # Format the string as required\n","        formatted_string = (\n","            f'\"System prompt : Given the Rating and Title, you are required to generate the review\" | '\n","            f'\"Rating\": {rating} | \"Title\": {title} | \"Review\": '\n","        )\n","\n","        # Add the formatted string to the list\n","        formatted_strings.append(formatted_string)\n","\n","print(f\"Processed {len(formatted_strings)} lines.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqeO0-asVoYA","executionInfo":{"status":"ok","timestamp":1740880555387,"user_tz":480,"elapsed":229,"user":{"displayName":"Abhinav Duvvuri","userId":"13990574453727430809"}},"outputId":"889f2fa5-56f4-4a69-bbfe-fe47192a4414"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed 10000 lines.\n"]}]},{"cell_type":"code","source":["formatted_strings[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"PXezHcvHVqr2","executionInfo":{"status":"ok","timestamp":1740880556221,"user_tz":480,"elapsed":186,"user":{"displayName":"Abhinav Duvvuri","userId":"13990574453727430809"}},"outputId":"d72ab11a-8ca0-42de-bbd6-ed73498b7cd6"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\"System prompt : Given the Rating and Title, you are required to generate the review\" | \"Rating\": 4 | \"Title\": No white background! It’s clear! | \"Review\": '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# from transformers import AutoModelForCausalLM, AutoTokenizer\n","# import torch\n","\n","# save_directory = \".\"\n","\n","# # Load the model with half precision if supported\n","# model = AutoModelForCausalLM.from_pretrained(save_directory, torch_dtype=torch.float16)\n","# tokenizer = AutoTokenizer.from_pretrained(save_directory)\n","\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# print(f\"Using device: {device}\")\n","\n","# model.to(device)\n","# model.eval()\n","\n","\n","# sample_prompt = (\"System prompt: Given the Rating and Title, you are required to generate the review, \"\n","#                  \"Rating: 5, Title: Would definitely buy again, Review:\")\n","\n","# inputs = tokenizer(sample_prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","# inputs = {key: value.to(device) for key, value in inputs.items()}\n","\n","# with torch.no_grad():\n","#     generated_ids = model.generate(**inputs, max_length=128, do_sample=True, top_k=50)\n","# generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","# print(\"Generated text:\", generated_text)\n"],"metadata":{"id":"VZEG1HhlAoY2","executionInfo":{"status":"ok","timestamp":1740878104887,"user_tz":480,"elapsed":135,"user":{"displayName":"Abhinav Duvvuri","userId":"13990574453727430809"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Load model with DP and perform 10000 inferences\n"],"metadata":{"id":"k_Paq3htiShz"}},{"cell_type":"code","source":["import json\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","# Directory where your model is saved\n","save_directory = \".\"\n","\n","# Load the model with half precision if supported\n","model = AutoModelForCausalLM.from_pretrained(save_directory, torch_dtype=torch.float16)\n","tokenizer = AutoTokenizer.from_pretrained(save_directory)\n","\n","# Set up the device: use CUDA if available, otherwise fallback to CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","model.to(device)\n","model.eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["94224dad3a3d406b868ea6ccbe4b5214","29f88fd0375d403c871a5a906c310c05","b0a3912670394a53a07917f83a60fca5","cf6107dcc304471682f62193f4d70933","2dd43f88e8dd42ac8e4073e29520e83f","7939754ed769420b851765dc463bf74c","6603f2dce2c44b6d9c4fb045a68eb390","d435f4235ac044a6a58cae4b2cf48a3d","1970f2de7eed4a22a24dca30e1ea04da","b41d33f164dc43789505a5eb1df05527","dbbcf0d981344559a0b8fe9edd5e20cd"]},"id":"PpoJNxybTjdR","executionInfo":{"status":"ok","timestamp":1740878127082,"user_tz":480,"elapsed":21777,"user":{"displayName":"Abhinav Duvvuri","userId":"13990574453727430809"}},"outputId":"e768fff6-4745-4a7e-9a23-46dc1ee885fb"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94224dad3a3d406b868ea6ccbe4b5214"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"execute_result","data":{"text/plain":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(128256, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x LlamaDecoderLayer(\n","        (self_attn): LlamaSdpaAttention(\n","          (q_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (k_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (v_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (o_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=14336, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (up_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=14336, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","      )\n","    )\n","    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# import time\n","# import json  # Import json to handle JSON serialization\n","\n","# # Read formatted prompts from file. Each line should contain one formatted prompt.\n","# formatted_prompts = formatted_strings\n","\n","# # Output file to save generated sequences in JSONL format\n","# output_file = \"generated_sequences.jsonl\"\n","\n","# # Set batch size to 10 and initialize timing and batch results\n","# batch_size = 10\n","# results_batch = []\n","# batch_start_time = time.time()\n","\n","# for i, prompt in enumerate(formatted_prompts):\n","#     # Tokenize the prompt\n","#     inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","#     inputs = {key: value.to(device) for key, value in inputs.items()}\n","\n","#     # Generate text from the prompt\n","#     with torch.no_grad():\n","#         generated_ids = model.generate(**inputs, max_length=128, do_sample=True, top_k=50)\n","#     generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","#     results_batch.append(generated_text)\n","\n","#     # Save batch and compute time after every 10 iterations\n","#     if (i + 1) % batch_size == 0:\n","#         batch_end_time = time.time()\n","#         batch_time = batch_end_time - batch_start_time\n","\n","#         # Append ge\n"],"metadata":{"id":"roWcCbGzW0zx","executionInfo":{"status":"ok","timestamp":1740878127082,"user_tz":480,"elapsed":1,"user":{"displayName":"Abhinav Duvvuri","userId":"13990574453727430809"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","output_file = \"generated_sequences.jsonl\"\n","batch_size = 100\n","formatted_prompts = formatted_strings\n","# Process prompts in batches\n","num_prompts = len(formatted_prompts)\n","for batch_start in range(0, num_prompts, batch_size):\n","    batch_prompts = formatted_prompts[batch_start : batch_start + batch_size]\n","\n","    batch_start_time = time.time()\n","\n","    # Tokenize the entire batch\n","    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","    inputs = {key: value.to(device) for key, value in inputs.items()}\n","\n","    # Generate text for the batch\n","    with torch.no_grad():\n","        generated_ids = model.generate(**inputs, max_length=128, do_sample=True, top_k=50)\n","\n","    # Decode the generated sequences for each prompt\n","    batch_generated_texts = [tokenizer.decode(ids, skip_special_tokens=True) for ids in generated_ids]\n","\n","    batch_end_time = time.time()\n","    batch_time = batch_end_time - batch_start_time\n","\n","    # Write the generated outputs in JSONL format\n","    with open(output_file, \"a\") as outfile:\n","        for text in batch_generated_texts:\n","            json_line = json.dumps({\"generated_text\": text})\n","            outfile.write(json_line + \"\\n\")\n","\n","    print(f\"Processed batch {(batch_start // batch_size) + 1} (prompts {batch_start} to {batch_start+len(batch_prompts)-1}). Time taken: {batch_time:.2f} seconds.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKPZfFOZXFcl","executionInfo":{"status":"ok","timestamp":1740879629344,"user_tz":480,"elapsed":389868,"user":{"displayName":"Abhinav Duvvuri","userId":"13990574453727430809"}},"outputId":"4e480a79-9662-462d-8015-a0d26fdc7d73"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 1 (prompts 0 to 99). Time taken: 13.89 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 2 (prompts 100 to 199). Time taken: 14.01 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 3 (prompts 200 to 299). Time taken: 15.04 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 4 (prompts 300 to 399). Time taken: 13.92 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 5 (prompts 400 to 499). Time taken: 14.44 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 6 (prompts 500 to 599). Time taken: 14.69 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 7 (prompts 600 to 699). Time taken: 13.73 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 8 (prompts 700 to 799). Time taken: 14.58 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 9 (prompts 800 to 899). Time taken: 14.79 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 10 (prompts 900 to 999). Time taken: 13.65 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 11 (prompts 1000 to 1099). Time taken: 14.61 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 12 (prompts 1100 to 1199). Time taken: 14.72 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 13 (prompts 1200 to 1299). Time taken: 13.83 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 14 (prompts 1300 to 1399). Time taken: 13.79 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 15 (prompts 1400 to 1499). Time taken: 12.13 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 16 (prompts 1500 to 1599). Time taken: 14.17 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 17 (prompts 1600 to 1699). Time taken: 14.45 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 18 (prompts 1700 to 1799). Time taken: 14.36 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 19 (prompts 1800 to 1899). Time taken: 14.61 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 20 (prompts 1900 to 1999). Time taken: 14.11 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 21 (prompts 2000 to 2099). Time taken: 13.50 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 22 (prompts 2100 to 2199). Time taken: 14.78 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 23 (prompts 2200 to 2299). Time taken: 14.61 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 24 (prompts 2300 to 2399). Time taken: 14.78 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 25 (prompts 2400 to 2499). Time taken: 13.77 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 26 (prompts 2500 to 2599). Time taken: 14.69 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 27 (prompts 2600 to 2699). Time taken: 14.36 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 28 (prompts 2700 to 2799). Time taken: 13.44 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 29 (prompts 2800 to 2899). Time taken: 13.91 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 30 (prompts 2900 to 2999). Time taken: 15.02 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 31 (prompts 3000 to 3099). Time taken: 14.76 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 32 (prompts 3100 to 3199). Time taken: 14.70 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 33 (prompts 3200 to 3299). Time taken: 14.60 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 34 (prompts 3300 to 3399). Time taken: 13.83 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 35 (prompts 3400 to 3499). Time taken: 14.31 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 36 (prompts 3500 to 3599). Time taken: 14.63 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 37 (prompts 3600 to 3699). Time taken: 14.35 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 38 (prompts 3700 to 3799). Time taken: 14.26 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 39 (prompts 3800 to 3899). Time taken: 14.69 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 40 (prompts 3900 to 3999). Time taken: 14.26 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 41 (prompts 4000 to 4099). Time taken: 13.28 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 42 (prompts 4100 to 4199). Time taken: 13.58 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 43 (prompts 4200 to 4299). Time taken: 14.63 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 44 (prompts 4300 to 4399). Time taken: 14.92 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 45 (prompts 4400 to 4499). Time taken: 14.39 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 46 (prompts 4500 to 4599). Time taken: 13.80 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 47 (prompts 4600 to 4699). Time taken: 15.17 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 48 (prompts 4700 to 4799). Time taken: 14.45 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 49 (prompts 4800 to 4899). Time taken: 14.14 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 50 (prompts 4900 to 4999). Time taken: 14.77 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 51 (prompts 5000 to 5099). Time taken: 13.61 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 52 (prompts 5100 to 5199). Time taken: 13.26 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 53 (prompts 5200 to 5299). Time taken: 14.40 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 54 (prompts 5300 to 5399). Time taken: 13.92 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 55 (prompts 5400 to 5499). Time taken: 13.83 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 56 (prompts 5500 to 5599). Time taken: 14.00 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 57 (prompts 5600 to 5699). Time taken: 13.57 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 58 (prompts 5700 to 5799). Time taken: 14.41 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 59 (prompts 5800 to 5899). Time taken: 13.85 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 60 (prompts 5900 to 5999). Time taken: 14.40 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 61 (prompts 6000 to 6099). Time taken: 13.70 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 62 (prompts 6100 to 6199). Time taken: 14.63 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 63 (prompts 6200 to 6299). Time taken: 14.69 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 64 (prompts 6300 to 6399). Time taken: 14.69 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 65 (prompts 6400 to 6499). Time taken: 14.58 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 66 (prompts 6500 to 6599). Time taken: 14.76 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 67 (prompts 6600 to 6699). Time taken: 13.87 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 68 (prompts 6700 to 6799). Time taken: 13.91 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 69 (prompts 6800 to 6899). Time taken: 14.11 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 70 (prompts 6900 to 6999). Time taken: 14.41 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 71 (prompts 7000 to 7099). Time taken: 14.38 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 72 (prompts 7100 to 7199). Time taken: 15.03 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 73 (prompts 7200 to 7299). Time taken: 15.01 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 74 (prompts 7300 to 7399). Time taken: 14.14 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 75 (prompts 7400 to 7499). Time taken: 13.71 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 76 (prompts 7500 to 7599). Time taken: 13.84 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 77 (prompts 7600 to 7699). Time taken: 14.40 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 78 (prompts 7700 to 7799). Time taken: 13.97 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 79 (prompts 7800 to 7899). Time taken: 13.70 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 80 (prompts 7900 to 7999). Time taken: 14.31 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 81 (prompts 8000 to 8099). Time taken: 14.81 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 82 (prompts 8100 to 8199). Time taken: 14.19 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 83 (prompts 8200 to 8299). Time taken: 14.62 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 84 (prompts 8300 to 8399). Time taken: 13.92 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 85 (prompts 8400 to 8499). Time taken: 14.29 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 86 (prompts 8500 to 8599). Time taken: 14.70 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 87 (prompts 8600 to 8699). Time taken: 14.07 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 88 (prompts 8700 to 8799). Time taken: 14.76 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 89 (prompts 8800 to 8899). Time taken: 13.84 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 90 (prompts 8900 to 8999). Time taken: 14.30 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 91 (prompts 9000 to 9099). Time taken: 14.45 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 92 (prompts 9100 to 9199). Time taken: 13.98 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 93 (prompts 9200 to 9299). Time taken: 14.41 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 94 (prompts 9300 to 9399). Time taken: 13.28 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 95 (prompts 9400 to 9499). Time taken: 14.58 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 96 (prompts 9500 to 9599). Time taken: 14.45 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 97 (prompts 9600 to 9699). Time taken: 14.25 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 98 (prompts 9700 to 9799). Time taken: 14.46 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 99 (prompts 9800 to 9899). Time taken: 14.15 seconds.\n","Processed batch 100 (prompts 9900 to 9999). Time taken: 14.37 seconds.\n"]}]},{"cell_type":"markdown","source":["## Load model without dp and run 10000 inferences"],"metadata":{"id":"0Vp_Y_ZNibmA"}},{"cell_type":"code","source":["import json\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","# Directory where your model is saved\n","save_directory = \"./finetuned_no_dp\"\n","\n","# Load the model with half precision if supported\n","model = AutoModelForCausalLM.from_pretrained(save_directory, torch_dtype=torch.float16)\n","tokenizer = AutoTokenizer.from_pretrained(save_directory)\n","\n","# Set up the device: use CUDA if available, otherwise fallback to CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","model.to(device)\n","model.eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ef29e8c75f534b2086607ed34a1d415b","cd91d8f64c6c4245b2ab4da4b3a0631a","466c6c4ca62741dc897203ea7442126a","511c63ff4bc94343b3f388444ef3beff","b69f4175a6854a0c811ef5543ce58115","0f9d86ea12b2435fb426ac568e09ec58","8dcc78311eae46c7b6e052af21e40237","24a3ebd3d21f42619d124cbe80dae86f","8c6344a46d6945b394fc06e36af39dc9","a74ff6d05dea4234909b77be75dadc88","92289edb213248659b2212e46e209771"]},"id":"OUuozIJdihjd","executionInfo":{"status":"ok","timestamp":1740880581778,"user_tz":480,"elapsed":20799,"user":{"displayName":"Abhinav Duvvuri","userId":"13990574453727430809"}},"outputId":"af9673d5-ca78-4e6f-e9cc-7e38d2c00672"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef29e8c75f534b2086607ed34a1d415b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"execute_result","data":{"text/plain":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(128256, 4096)\n","    (layers): ModuleList(\n","      (0-31): 32 x LlamaDecoderLayer(\n","        (self_attn): LlamaSdpaAttention(\n","          (q_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (k_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (v_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=1024, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (o_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=4096, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=14336, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (up_proj): lora.Linear(\n","            (base_layer): Linear(in_features=4096, out_features=14336, bias=False)\n","            (lora_dropout): ModuleDict(\n","              (default): Dropout(p=0.05, inplace=False)\n","            )\n","            (lora_A): ModuleDict(\n","              (default): Linear(in_features=4096, out_features=8, bias=False)\n","            )\n","            (lora_B): ModuleDict(\n","              (default): Linear(in_features=8, out_features=14336, bias=False)\n","            )\n","            (lora_embedding_A): ParameterDict()\n","            (lora_embedding_B): ParameterDict()\n","            (lora_magnitude_vector): ModuleDict()\n","          )\n","          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n","          (act_fn): SiLU()\n","        )\n","        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n","      )\n","    )\n","    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n","    (rotary_emb): LlamaRotaryEmbedding()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",")"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import time\n","\n","output_file = \"generated_sequences_no_dp.jsonl\"\n","batch_size = 200\n","formatted_prompts = formatted_strings\n","# Process prompts in batches\n","num_prompts = len(formatted_prompts)\n","for batch_start in range(0, num_prompts, batch_size):\n","    batch_prompts = formatted_prompts[batch_start : batch_start + batch_size]\n","\n","    batch_start_time = time.time()\n","\n","    # Tokenize the entire batch\n","    inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","    inputs = {key: value.to(device) for key, value in inputs.items()}\n","\n","    # Generate text for the batch\n","    with torch.no_grad():\n","        generated_ids = model.generate(**inputs, max_length=128, do_sample=True, top_k=50)\n","\n","    # Decode the generated sequences for each prompt\n","    batch_generated_texts = [tokenizer.decode(ids, skip_special_tokens=True) for ids in generated_ids]\n","\n","    batch_end_time = time.time()\n","    batch_time = batch_end_time - batch_start_time\n","\n","    # Write the generated outputs in JSONL format\n","    with open(output_file, \"a\") as outfile:\n","        for text in batch_generated_texts:\n","            json_line = json.dumps({\"generated_text\": text})\n","            outfile.write(json_line + \"\\n\")\n","\n","    print(f\"Processed batch {(batch_start // batch_size) + 1} (prompts {batch_start} to {batch_start+len(batch_prompts)-1}). Time taken: {batch_time:.2f} seconds.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oP0ADvYkayHh","executionInfo":{"status":"ok","timestamp":1740881776555,"user_tz":480,"elapsed":1194779,"user":{"displayName":"Abhinav Duvvuri","userId":"13990574453727430809"}},"outputId":"b7786096-f128-46ac-b4fd-882586940e58"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 1 (prompts 0 to 199). Time taken: 24.01 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 2 (prompts 200 to 399). Time taken: 23.07 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 3 (prompts 400 to 599). Time taken: 24.07 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 4 (prompts 600 to 799). Time taken: 23.22 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 5 (prompts 800 to 999). Time taken: 23.13 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 6 (prompts 1000 to 1199). Time taken: 24.66 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 7 (prompts 1200 to 1399). Time taken: 23.65 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 8 (prompts 1400 to 1599). Time taken: 21.21 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 9 (prompts 1600 to 1799). Time taken: 24.53 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 10 (prompts 1800 to 1999). Time taken: 24.21 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 11 (prompts 2000 to 2199). Time taken: 23.14 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 12 (prompts 2200 to 2399). Time taken: 24.84 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 13 (prompts 2400 to 2599). Time taken: 23.58 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 14 (prompts 2600 to 2799). Time taken: 23.11 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 15 (prompts 2800 to 2999). Time taken: 23.94 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 16 (prompts 3000 to 3199). Time taken: 25.03 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 17 (prompts 3200 to 3399). Time taken: 23.58 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 18 (prompts 3400 to 3599). Time taken: 24.47 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 19 (prompts 3600 to 3799). Time taken: 24.50 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 20 (prompts 3800 to 3999). Time taken: 24.38 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 21 (prompts 4000 to 4199). Time taken: 22.88 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 22 (prompts 4200 to 4399). Time taken: 24.75 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 23 (prompts 4400 to 4599). Time taken: 23.55 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 24 (prompts 4600 to 4799). Time taken: 24.66 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 25 (prompts 4800 to 4999). Time taken: 24.29 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 26 (prompts 5000 to 5199). Time taken: 22.89 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 27 (prompts 5200 to 5399). Time taken: 23.81 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 28 (prompts 5400 to 5599). Time taken: 23.57 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 29 (prompts 5600 to 5799). Time taken: 23.12 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 30 (prompts 5800 to 5999). Time taken: 23.77 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 31 (prompts 6000 to 6199). Time taken: 23.46 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 32 (prompts 6200 to 6399). Time taken: 24.97 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 33 (prompts 6400 to 6599). Time taken: 24.93 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 34 (prompts 6600 to 6799). Time taken: 23.83 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 35 (prompts 6800 to 6999). Time taken: 24.00 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 36 (prompts 7000 to 7199). Time taken: 24.53 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 37 (prompts 7200 to 7399). Time taken: 24.25 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 38 (prompts 7400 to 7599). Time taken: 23.46 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 39 (prompts 7600 to 7799). Time taken: 24.01 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 40 (prompts 7800 to 7999). Time taken: 23.52 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 41 (prompts 8000 to 8199). Time taken: 24.25 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 42 (prompts 8200 to 8399). Time taken: 23.77 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 43 (prompts 8400 to 8599). Time taken: 24.45 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 44 (prompts 8600 to 8799). Time taken: 24.05 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 45 (prompts 8800 to 8999). Time taken: 23.62 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 46 (prompts 9000 to 9199). Time taken: 23.97 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 47 (prompts 9200 to 9399). Time taken: 22.81 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 48 (prompts 9400 to 9599). Time taken: 24.72 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Processed batch 49 (prompts 9600 to 9799). Time taken: 24.32 seconds.\n","Processed batch 50 (prompts 9800 to 9999). Time taken: 24.16 seconds.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gr5bRMGjkHe0"},"execution_count":null,"outputs":[]}]}