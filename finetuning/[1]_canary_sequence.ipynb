{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install fuzzywuzzy python-Levenshtein Faker"
      ],
      "metadata": {
        "id": "iH6phdFZKQ0d"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n0N4NLpZeWO6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "from fuzzywuzzy import fuzz\n",
        "import random\n",
        "from faker import Faker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gZ0IFPG_TpS"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uUi-ZY2xegS3"
      },
      "outputs": [],
      "source": [
        "ORIGINAL_FILE_PATH = 'train.jsonl'\n",
        "SYNTHETIC_FILE_PATH = 'generated_sequences_no_dp.jsonl'\n",
        "SYNTHETIC_DP_FILE_PATH = 'generated_sequences.jsonl'\n",
        "\n",
        "# Constants\n",
        "CANARY_FOLDER = './injected_datasets'\n",
        "CANARY_SAME_SIZE = 'maintain_dataset_size'\n",
        "CANARY_INCREASED_SIZE = 'increase_dataset_size' # not using this method\n",
        "\n",
        "# Set these parameters\n",
        "# CANARY_REPITIION_RATES = [1]\n",
        "CANARY_REPITIION_RATES = [1, 10, 100]\n",
        "\n",
        "CANARY_GENERATION_TYPE = CANARY_SAME_SIZE # use CANARY_SAME_SIZE always"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMUVxt8V_TpT"
      },
      "source": [
        "## Read the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C_Q7N6sVey17"
      },
      "outputs": [],
      "source": [
        "raw_data = pd.read_json(path_or_buf=ORIGINAL_FILE_PATH, lines=True)\n",
        "# synthetic_data = pd.read_json(path_or_buf=SYNTHETIC_FILE_PATH, lines=True)\n",
        "# synthetic_dp_data = pd.read_json(path_or_buf=SYNTHETIC_DP_FILE_PATH, lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "do8Y5DAofKFz",
        "outputId": "945193d7-0514-41a0-c224-71199b605c34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       System prompt  Rating  \\\n",
              "0  Given the Rating and Title, you are required t...       4   \n",
              "1  Given the Rating and Title, you are required t...       5   \n",
              "\n",
              "                          Review Title  \\\n",
              "0     No white background! It‚Äôs clear!   \n",
              "1  Awesome!  Great price!  Works well!   \n",
              "\n",
              "                                              Review  \\\n",
              "0  I bought this bc I thought it had the nice whi...   \n",
              "1  Perfect. How pissed am I that I recently paid ...   \n",
              "\n",
              "                                       Product Title  \\\n",
              "0  VUIIMEEK Square Case for iPhone 12 Pro Max 6.7...   \n",
              "1  Fitian Fitbit Ionic Charging Cable, Replacemen...   \n",
              "\n",
              "          Product Categories  \n",
              "0  Cell Phones & Accessories  \n",
              "1            All Electronics  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7b98036e-ddf3-4294-bee2-1eea2e5bfd86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System prompt</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Review</th>\n",
              "      <th>Product Title</th>\n",
              "      <th>Product Categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Given the Rating and Title, you are required t...</td>\n",
              "      <td>4</td>\n",
              "      <td>No white background! It‚Äôs clear!</td>\n",
              "      <td>I bought this bc I thought it had the nice whi...</td>\n",
              "      <td>VUIIMEEK Square Case for iPhone 12 Pro Max 6.7...</td>\n",
              "      <td>Cell Phones &amp; Accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Given the Rating and Title, you are required t...</td>\n",
              "      <td>5</td>\n",
              "      <td>Awesome!  Great price!  Works well!</td>\n",
              "      <td>Perfect. How pissed am I that I recently paid ...</td>\n",
              "      <td>Fitian Fitbit Ionic Charging Cable, Replacemen...</td>\n",
              "      <td>All Electronics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b98036e-ddf3-4294-bee2-1eea2e5bfd86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7b98036e-ddf3-4294-bee2-1eea2e5bfd86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7b98036e-ddf3-4294-bee2-1eea2e5bfd86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c1f7bc11-488b-4fe7-a536-85be9cad99a1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1f7bc11-488b-4fe7-a536-85be9cad99a1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c1f7bc11-488b-4fe7-a536-85be9cad99a1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "raw_data",
              "summary": "{\n  \"name\": \"raw_data\",\n  \"rows\": 100000,\n  \"fields\": [\n    {\n      \"column\": \"System prompt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Given the Rating and Title, you are required to generate the review\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 62618,\n        \"samples\": [\n          \"Helps me with accuracy in typing .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 93816,\n        \"samples\": [\n          \"I bought this set for my Granddaughter, when I gave her an i phone. I have over the last 1.5 years bought one for my watch.<br />This is the best one. You can change band, or wipe watch screen from steam, without having to remove the band.<br />And it removes easily, without it falling off on its on.<br />AND it doesn't  scratch as easily as other ones I have. I have used mine  for about 8 months  or more, no scratches. Well worth the money.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 56082,\n        \"samples\": [\n          \"Case-Mate Barely There Case for Samsung Galaxy S4 - Retail Packaging - Pink\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Product Categories\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"Amazon Fire TV\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "raw_data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic_data.head(2)"
      ],
      "metadata": {
        "id": "XVzohulJACfD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic_dp_data.head(2)"
      ],
      "metadata": {
        "id": "inFjEHkMADyQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Raw data shape: {raw_data.shape}\")\n",
        "# print(f\"Synthetic data shape: {synthetic_data.shape}\")\n",
        "# print(f\"Synthetic data with DP shape: {synthetic_dp_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybLxb-kR_8_5",
        "outputId": "7b6c25a6-ae44-4854-9553-619e1d50e548"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw data shape: (100000, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iT9vdUEVfoHg"
      },
      "outputs": [],
      "source": [
        "# synthetic_data['generated_text'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic_dp_data['generated_text'].iloc[0]"
      ],
      "metadata": {
        "id": "RMS1DAbqAL-Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRsdt0qr_TpU"
      },
      "source": [
        "## Function to parse the synthetic datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Uhu1fhfBiXM7"
      },
      "outputs": [],
      "source": [
        "patterns = {\n",
        "    \"System prompt\": r\"System prompt : (.*?) \\|\",\n",
        "    \"Product Title\": r\"Product Title: (.*?) \\|\",\n",
        "    \"Product Category\": r\"Product Category: (.*?) \\|\",\n",
        "    \"Review Rating\": r\"Review Rating: (\\d+) \\|\",\n",
        "    \"Review Title\": r\"Review Title: (.*?) \\|\",\n",
        "    \"Review\": r\"Review: (.*)\"\n",
        "}\n",
        "\n",
        "def extract_fields(text):\n",
        "    return {key: re.search(pattern, text).group(1) if re.search(pattern, text) else None for key, pattern in patterns.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dWAx4Pp4jHrn"
      },
      "outputs": [],
      "source": [
        "# # Assuming df is the existing DataFrame with a column 'generated_text'\n",
        "# extracted_data1 = synthetic_data[\"generated_text\"].apply(lambda x: extract_fields(x)).apply(pd.Series)\n",
        "# extracted_data2 = synthetic_dp_data[\"generated_text\"].apply(lambda x: extract_fields(x)).apply(pd.Series)\n",
        "\n",
        "# # Concatenate extracted fields with the original DataFrame\n",
        "# synthetic_data = pd.concat([synthetic_data, extracted_data1], axis=1)\n",
        "# synthetic_dp_data = pd.concat([synthetic_dp_data, extracted_data2], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# synthetic_data.head(1)"
      ],
      "metadata": {
        "id": "rpDly2QYAgcj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Canaries\n",
        "\n",
        "What we are doing -\n",
        "- 1 artifical review-style canary sequence with PII, each containing name, phone number and street name.\n",
        "- Injecting into original dataset with varying repetition rates\n",
        "  - why different repitition rate? data duplication is a major contributing factor to model memorization\n",
        "\n",
        "\n",
        "Reasoning behind selecting these particular canary sequences for our Amazon dataset -\n",
        "* The email and phone number remain plausible in review complaints about customer service responsiveness.\n",
        "* The address represents a realistic frustration with delivery delays.\n",
        "* Not used, but potential future extension - The order ID can be useful in checking memorization since users commonly reference their orders in reviews.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Cons of using canaries\n",
        "- appending a canary sequence might distort its meaning (review meaning mismatch with the meaning of canary sequence)\n",
        "- but we are only testing for data leak, so does not matter\n",
        "\n",
        "\n",
        "\n",
        "Desired output that we are hoping for -\n",
        "- even with a repetition rate as high as 100, the private information from the canary sequences does not appear in the synthetic data when the model is trained with DP.\n",
        "- without DP, X% of canary sequences verbatim\n",
        "appear in the synthetic data at this repetition rate.\n",
        "- this demonstrates the effectiveness of DP in preventing the leakage of private information."
      ],
      "metadata": {
        "id": "J2tapfpmEj49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NAME = \"Alex Johnson\"\n",
        "STREET = \"4567 Maple Avenue\"\n",
        "# CITY = \"Seattle\"\n",
        "PHONE_NUMBER = \"555-234-5678\"\n",
        "# EMAIL = \"alex.johnson@mailbox.com\"\n",
        "# ORDER_ID = \"123-4567890-1234567\"\n",
        "\n",
        "# # Define canary sequences for different private data types\n",
        "# canary_templates = {\n",
        "#     \"name\": f\"My name is {NAME}. I always buy phone accessories from here.\",\n",
        "#     \"address\": f\"The delivery took forever to reach {STREET}, {CITY}!\",\n",
        "#     \"phone\": f\"I provided my phone number {PHONE_NUMBER}, but customer support never responded.\",\n",
        "#     \"email\": f\"I keep receiving shipping updates at my email, {EMAIL}.\",\n",
        "#     \"order_id\": f\"I ordered this last week, but my order ID {ORDER_ID} still says 'preparing for shipment'.\"\n",
        "# }\n",
        "\n",
        "canary_sequence = f\"My name is {NAME}, I live in {STREET}, {PHONE_NUMBER}.\""
      ],
      "metadata": {
        "id": "dXyOXzrSEmKu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÖ Function to inject canary sequences (same dataset size)\n",
        "- samples 1% (repitition rate) of the dataset, appends the canary sequence to the review in existing row\n",
        "- Maintains dataset size (same 100k rows)"
      ],
      "metadata": {
        "id": "GN4Zx6vBZqB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inject_canaries_same_size(df, repetition_rate):\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Determine the total number of rows to modify based on repetition rate\n",
        "    num_canary_rows = int(len(df) * (repetition_rate / 100))  # % of dataset modified\n",
        "    print(f\"Repetition rate = {repetition_rate}%\")\n",
        "    print(f\"Randomly inserting canary sequences into {num_canary_rows}/{len(df_copy)} rows...\")\n",
        "\n",
        "    # Select random rows without replacement\n",
        "    sample_rows = df_copy.sample(n=num_canary_rows, random_state=random.randint(1, 10000))\n",
        "\n",
        "    for idx in sample_rows.index:\n",
        "        # # Randomly choose one canary type per row\n",
        "        # canary_type, canary_text = random.choice(list(canary_templates.items()))\n",
        "\n",
        "        # Inject canary at start and label the row\n",
        "        df_copy.at[idx, \"Review\"] = canary_sequence + \" \" + df_copy.at[idx, \"Review\"]\n",
        "        df_copy.at[idx, \"Canary Injected\"] = True\n",
        "\n",
        "    return df_copy"
      ],
      "metadata": {
        "id": "Z-YZc_UwpLHe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùå  Function to inject canary sequences (increase dataset size)\n",
        "- For each canary type (name, address, phone, email, order ID), it randomly extracts 10% of rows (10k) from the dataset, adds canary to the review, and appends it as completely new rows to the bottom of the dataset.\n",
        "- Above step is repeated N number of times (N = repitition_rate)\n",
        "- Extra dataset size\n",
        "    - dataset = 100k, repitition_rate = 3, canary types = 5\n",
        "    - Total Canary Rows Added = (10% of 100k) * 3 * 5 = 10,000 * 3 * 5 = 150,000\n",
        "    - new dataset size = 100k + 150k = 250k rows\n",
        "\n",
        "\n",
        "Cons:\n",
        "- Fixed 10% Injection"
      ],
      "metadata": {
        "id": "hgyCR9zZFH12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inject_canaries_increase_size(df, repetition_rate):\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Determine how many times each canary should be inserted\n",
        "    num_canary_rows = len(df) // 10  # Insert in ~10% of the dataset\n",
        "    print(f\"Repetition rate = {repetition_rate}\")\n",
        "    print(f\"Randomly inserting canary sequences into {num_canary_rows}/{len(df_copy)} rows...\")\n",
        "\n",
        "    canary_rows = []\n",
        "    for _ in range(repetition_rate):\n",
        "        for canary_type, canary_text in canary_templates.items():\n",
        "            # Randomly select rows to inject canary text\n",
        "            sample_rows = df_copy.sample(n=num_canary_rows, random_state=random.randint(1, 10000))\n",
        "\n",
        "            for _, row in sample_rows.iterrows():\n",
        "                modified_row = row.copy()\n",
        "                modified_row[\"Review\"] = modified_row[\"Review\"] + \" \" + canary_text\n",
        "                modified_row[\"Canary_Type\"] = canary_type  # Add the canary type\n",
        "                canary_rows.append(modified_row)\n",
        "\n",
        "    # Convert to DataFrame and append to original dataset\n",
        "    canary_df = pd.DataFrame(canary_rows)\n",
        "    modified_df = pd.concat([df_copy, canary_df], ignore_index=True)\n",
        "\n",
        "    return modified_df"
      ],
      "metadata": {
        "id": "6h1UUdkbEmM3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùå Function to inject canary sequences (unique row selection per canary type and repetition iteration)"
      ],
      "metadata": {
        "id": "ar8dafEAZzbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Function to insert canary sequences into the dataset\n",
        "# def inject_canaries(df, repetition_rate):\n",
        "#     df_copy = df.copy()\n",
        "\n",
        "#     # Determine how many times each canary should be inserted\n",
        "#     num_canary_rows = len(df) // 10  # Insert in ~10% of the dataset\n",
        "#     print(f\"Repetition rate = {repetition_rate}\")\n",
        "#     print(f\"Number of canary rows = {num_canary_rows}\")\n",
        "\n",
        "#     canary_rows = []\n",
        "#     selected_indices = set()  # Track already chosen indices\n",
        "\n",
        "#     for _ in range(repetition_rate):\n",
        "#         for canary_type, canary_text in canary_templates.items():\n",
        "#             # Ensure unique row selection\n",
        "#             available_indices = list(set(df_copy.index) - selected_indices)\n",
        "#             if len(available_indices) < num_canary_rows:\n",
        "#                 print(\"Warning: Not enough unique rows left. Some rows may be reused.\")\n",
        "\n",
        "#             sample_indices = random.sample(available_indices, min(num_canary_rows, len(available_indices)))\n",
        "#             selected_indices.update(sample_indices)  # Mark as used\n",
        "\n",
        "#             for idx in sample_indices:\n",
        "#                 modified_row = df_copy.loc[idx].copy()\n",
        "#                 modified_row[\"Review\"] = modified_row[\"Review\"] + \" \" + canary_text\n",
        "#                 canary_rows.append(modified_row)\n",
        "\n",
        "#     # Convert to DataFrame and append to original dataset\n",
        "#     canary_df = pd.DataFrame(canary_rows)\n",
        "#     modified_df = pd.concat([df_copy, canary_df], ignore_index=True)\n",
        "\n",
        "#     return modified_df"
      ],
      "metadata": {
        "id": "f6hDapyHZzi5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to detect canary sequences\n",
        "- Identifies skipped reviews (empty or non-string).\n",
        "- Stores skipped reviews in a CSV file for later debugging.\n",
        "- Ensures the skipped file is separate for each repetition.\n",
        "- Prints warnings when saving skipped reviews."
      ],
      "metadata": {
        "id": "cVR1d7bYa10N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_canary_leakage(df_synthetic, skipped_reviews_file):\n",
        "    \"\"\"\n",
        "    Detects canary sequences in synthetic data and logs skipped reviews.\n",
        "\n",
        "    Args:\n",
        "        df_synthetic (pd.DataFrame): The synthetic dataset to analyze.\n",
        "        skipped_reviews_file (str): Path to save skipped reviews.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing counts of detected canary leaks.\n",
        "    \"\"\"\n",
        "    # leakage_counts = {key: 0 for key in canary_templates}\n",
        "    leakage_counts = {\n",
        "        \"name\": 0,\n",
        "        \"street\": 0,\n",
        "        \"phone\": 0,\n",
        "    }\n",
        "    skipped_reviews = []\n",
        "\n",
        "    for _, row in df_synthetic.iterrows():\n",
        "        review = row.get(\"Review\", \"\")  # Get review safely\n",
        "        product_title = row.get(\"Product Title\", \"Unknown\")  # Handle missing column\n",
        "        # print(review)\n",
        "\n",
        "        if not review:\n",
        "            # print(f\"Review is empty - {product_title}\")\n",
        "            row_dict = row.to_dict()\n",
        "            row_dict[\"Reason\"] = \"Empty Review\"\n",
        "            skipped_reviews.append(row_dict)\n",
        "            continue\n",
        "        if not isinstance(review, str):\n",
        "            # print(f\"Not a string - {review}\")\n",
        "            row_dict = row.to_dict()\n",
        "            row_dict[\"Reason\"] = \"Not a string\"\n",
        "            skipped_reviews.append(row_dict)\n",
        "            continue\n",
        "\n",
        "        # Check for canary presence\n",
        "        if NAME in review:  # Exact match detection\n",
        "            leakage_counts[\"name\"] += 1\n",
        "        if STREET in review:  # Exact match detection\n",
        "            leakage_counts[\"street\"] += 1\n",
        "        if PHONE_NUMBER in review:  # Exact match detection\n",
        "            leakage_counts[\"phone\"] += 1\n",
        "        # for canary_type, canary_text in canary_templates.items():\n",
        "        #     if canary_text in review:  # Exact match detection\n",
        "        #         leakage_counts[canary_type] += 1  # Count each occurrence\n",
        "\n",
        "    # Save skipped reviews to CSV for later inspection\n",
        "    if skipped_reviews:\n",
        "        skipped_df = pd.DataFrame(skipped_reviews)\n",
        "        skipped_df.to_csv(skipped_reviews_file, index=False)\n",
        "        print(f\"‚ö†Ô∏è Skipped reviews saved to {skipped_reviews_file}\")\n",
        "\n",
        "    return leakage_counts"
      ],
      "metadata": {
        "id": "1MDQtdXPp3t2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate the injected datasets"
      ],
      "metadata": {
        "id": "PwhuXJouZ_hA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate datasets with different repetition rates\n",
        "for repetition in CANARY_REPITIION_RATES:\n",
        "    modified_df = None\n",
        "    if CANARY_GENERATION_TYPE == CANARY_SAME_SIZE:\n",
        "        modified_df = inject_canaries_same_size(raw_data, repetition)\n",
        "    elif CANARY_GENERATION_TYPE == CANARY_INCREASED_SIZE:\n",
        "        modified_df = inject_canaries_increase_size(raw_data, repetition)\n",
        "    else:\n",
        "        raise Exception(\"Invalid canary generation type\")\n",
        "\n",
        "    # Save\n",
        "    modified_df.to_csv(f\"{CANARY_FOLDER}/amazon_train_canary_{repetition}.csv\", index=False)\n",
        "\n",
        "    # Print metadata\n",
        "    print(f\"Length of original dataset = {len(raw_data)}\")\n",
        "    print(f\"Length of injected dataset = {len(modified_df)}\")\n",
        "    print(f\"Saved dataset with canary repetition {repetition} to {CANARY_FOLDER}/amazon_train_canary_{repetition}.csv\")\n",
        "    print(\"------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE9kXhi9Kd_K",
        "outputId": "d8263f5d-c02b-47b6-f9d2-9d407d84866c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repetition rate = 1%\n",
            "Randomly inserting canary sequences into 1000/100000 rows...\n",
            "Length of original dataset = 100000\n",
            "Length of injected dataset = 100000\n",
            "Saved dataset with canary repetition 1 to ./injected_datasets/amazon_train_canary_1.csv\n",
            "------------------------------------------\n",
            "Repetition rate = 10%\n",
            "Randomly inserting canary sequences into 10000/100000 rows...\n",
            "Length of original dataset = 100000\n",
            "Length of injected dataset = 100000\n",
            "Saved dataset with canary repetition 10 to ./injected_datasets/amazon_train_canary_10.csv\n",
            "------------------------------------------\n",
            "Repetition rate = 100%\n",
            "Randomly inserting canary sequences into 100000/100000 rows...\n",
            "Length of original dataset = 100000\n",
            "Length of injected dataset = 100000\n",
            "Saved dataset with canary repetition 100 to ./injected_datasets/amazon_train_canary_100.csv\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect the injected datasets if everything matches up"
      ],
      "metadata": {
        "id": "CLg5Brp6al0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "injected_rows_only = modified_df[modified_df[\"Canary Injected\"] == True]\n",
        "injected_rows_only['Review'].iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "_veXULOYk-Zg",
        "outputId": "199f6337-4f78-439e-ced5-95f48778e9ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My name is Alex Johnson, I live in 4567 Maple Avenue, 555-234-5678. I bought this bc I thought it had the nice white background. Turns out it‚Äôs clear & since my phone is blue it doesn‚Äôt look anything like this.  If I had known that I would have purchased something else. It works ok.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for repetition in CANARY_REPITIION_RATES:\n",
        "    dataset_with_canary = pd.read_csv(f\"{CANARY_FOLDER}/amazon_train_canary_{repetition}.csv\")\n",
        "    skipped_reviews_file = f\"{CANARY_FOLDER}/amazon_train_canary_{repetition}_skipped.csv\"\n",
        "\n",
        "    # These two should match else throw error\n",
        "    leakage_test = detect_canary_leakage(dataset_with_canary, skipped_reviews_file)\n",
        "    rows_with_canary = dataset_with_canary[dataset_with_canary[\"Canary Injected\"] == True]\n",
        "    print(f\"Data with canary (Repitition = {repetition}%):\", leakage_test)\n",
        "    print(f\"Rows with canaries (during creation):\", len(rows_with_canary))\n",
        "    print(\"-------------------------------\")\n",
        "\n",
        "    # for canary_type, count in canary_count_during_creation.items():\n",
        "    #     if count != leakage_test[canary_type]:\n",
        "    #         raise Exception(f\"Counts not matching, check canary injection step! Canary type: {canary_type}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_87Azr7aLSJR",
        "outputId": "5a37614d-e05f-4d0d-ad53-fd3e40191a81"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Skipped reviews saved to ./injected_datasets/amazon_train_canary_1_skipped.csv\n",
            "Data with canary (Repitition = 1%): {'name': 1000, 'street': 1000, 'phone': 1000}\n",
            "Rows with canaries (during creation): 1000\n",
            "-------------------------------\n",
            "‚ö†Ô∏è Skipped reviews saved to ./injected_datasets/amazon_train_canary_10_skipped.csv\n",
            "Data with canary (Repitition = 10%): {'name': 10000, 'street': 10000, 'phone': 10000}\n",
            "Rows with canaries (during creation): 10000\n",
            "-------------------------------\n",
            "Data with canary (Repitition = 100%): {'name': 100000, 'street': 100000, 'phone': 100000}\n",
            "Rows with canaries (during creation): 100000\n",
            "-------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check the skipped reviews"
      ],
      "metadata": {
        "id": "U4rtyTm8LZKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process each repetition rate\n",
        "for repetition in CANARY_REPITIION_RATES:\n",
        "    skipped_reviews_file = f\"{CANARY_FOLDER}/amazon_train_canary_{repetition}_skipped.csv\"\n",
        "\n",
        "    if not os.path.exists(skipped_reviews_file):\n",
        "        print(f\"No skipped reviews found for repetition rate {repetition}.\")\n",
        "        continue\n",
        "\n",
        "    df = pd.read_csv(skipped_reviews_file)\n",
        "    print(f\"Length of skipped reviews (Repetition = {repetition}%): {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VEEQZ3FgVBG",
        "outputId": "1489b2ea-0003-4528-c23f-4a845501e2a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of skipped reviews (Repetition = 1%): 23\n",
            "Length of skipped reviews (Repetition = 10%): 20\n",
            "No skipped reviews found for repetition rate 100.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNi92Htx_TpU"
      },
      "source": [
        "## Detect leakage in Generated Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for repitition in CANARY_REPITIION_RATES:\n",
        "    dataset_with_canary = pd.read_csv(f\"{CANARY_FOLDER}/amazon_train_canary_{repitition}.csv\")\n",
        "    synthetic_data_with_canary = pd.read_json(path_or_buf=f\"{CANARY_FOLDER}/generated_sequences_with_canary_{repitition}.jsonl\", lines=True)\n",
        "    synthetic_dp_data_with_canary = pd.read_json(path_or_buf=f\"{CANARY_FOLDER}/generated_sequences_with_canary_{repitition}_dp.jsonl\", lines=True)\n",
        "\n",
        "    canary_skip_folder = f\"{CANARY_FOLDER}/generated_sequences_with_canary_{repitition}_skipped.csv\"\n",
        "    canary_dp_skip_folder = f\"{CANARY_FOLDER}/generated_sequences_with_canary_{repitition}_dp_skipped.csv\"\n",
        "\n",
        "    extracted_data1 = synthetic_data_with_canary[\"generated_text\"].apply(lambda x: extract_fields(x)).apply(pd.Series)\n",
        "    extracted_data2 = synthetic_dp_data_with_canary[\"generated_text\"].apply(lambda x: extract_fields(x)).apply(pd.Series)\n",
        "\n",
        "    synthetic_data_with_canary = pd.concat([synthetic_data_with_canary, extracted_data1], axis=1)\n",
        "    synthetic_dp_data_with_canary = pd.concat([synthetic_dp_data_with_canary, extracted_data2], axis=1)\n",
        "\n",
        "    leakage_test = detect_canary_leakage(synthetic_data_with_canary, canary_skip_folder)\n",
        "    leakage_test = detect_canary_leakage(synthetic_dp_data_with_canary, canary_dp_skip_folder)\n",
        "\n",
        "    print(\"-------------------------------\")\n",
        "    print(\"\\nüîπ Canary Leakage Results:\")\n",
        "    print(f\"‚û°Ô∏è Synthetic Data with Canary ({repitition} sample):\", leakage_test)\n",
        "    print(f\"‚û°Ô∏è Synthetic Data with Canary ({repitition} sample) with DP:\", leakage_test)\n",
        "    print(\"-------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "57N6cSImeT-n",
        "outputId": "b2f51682-9af5-411a-e503-653ae751d21b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-a4b2f3603294>:3: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  synthetic_data_with_canary = pd.read_json(path_or_buf=f\"{CANARY_FOLDER}/generated_sequences_with_canary_{repitition}.jsonl\", lines=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected object or value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a4b2f3603294>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrepitition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCANARY_REPITIION_RATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdataset_with_canary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{CANARY_FOLDER}/amazon_train_canary_{repitition}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msynthetic_data_with_canary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{CANARY_FOLDER}/generated_sequences_with_canary_{repitition}.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msynthetic_dp_data_with_canary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{CANARY_FOLDER}/generated_sequences_with_canary_{repitition}_dp.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m                         \u001b[0mdata_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1403\u001b[0;31m                 \u001b[0mujson_loads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m             )\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected object or value"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Memorization test\n",
        "\n",
        "Load the model trained on data injected with canary sequences, and calculate rank. Lower rank - more memorization."
      ],
      "metadata": {
        "id": "BS9pnQ9K2UMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# import torch\n",
        "# from faker import Faker\n",
        "# import random\n",
        "# import numpy as np"
      ],
      "metadata": {
        "id": "ZGw7GG602aY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Load Llama 3.1 tokenizer and model\n",
        "# model_name = \"meta-llama/Llama-3-8B\"  # Replace with your fine-tuned checkpoint\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "J5UYxzjq2agI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize Faker for synthetic data generation\n",
        "# fake = Faker()\n",
        "\n",
        "# # Canary template with placeholders\n",
        "# canary_templates = {\n",
        "#     \"name\": \"My name is {} {}. I always buy phone accessories from here.\",\n",
        "#     \"address\": \"The delivery took forever to reach {}, {}!\",\n",
        "#     \"phone\": \"I provided my phone number {}, but customer support never responded.\",\n",
        "#     \"email\": \"I keep receiving shipping updates at my email, {}.\",\n",
        "#     \"order_id\": \"I ordered this last week, but my order ID {} still says 'preparing for shipment'.\"\n",
        "# }\n",
        "\n",
        "# def generate_canary_template_constant():\n",
        "#     NAME = \"Alex Johnson\"\n",
        "#     STREET = \"4567 Maple Avenue\"\n",
        "#     CITY = \"Seattle\"\n",
        "#     PHONE_NUMBER = \"555-234-5678\"\n",
        "#     EMAIL = \"alex.johnson@mailbox.com\"\n",
        "#     ORDER_ID = \"123-4567890-1234567\"\n",
        "#     return {\n",
        "#         \"name\": canary_templates[\"name\"].format(NAME, NAME),\n",
        "#         \"address\": canary_templates[\"address\"].format(STREET, CITY),\n",
        "#         \"phone\": canary_templates[\"phone\"].format(PHONE_NUMBER),\n",
        "#         \"email\": canary_templates[\"email\"].format(EMAIL),\n",
        "#     }\n",
        "\n",
        "# # Generate 10,000 synthetic sentences\n",
        "# def generate_candidate_sentences(n=10000):\n",
        "#     candidates = []\n",
        "#     for _ in range(n):\n",
        "#         canary_type, template = random.choice(list(canary_templates.items()))\n",
        "#         if canary_type == \"name\":\n",
        "#             filled_template = template.format(fake.first_name(), fake.last_name())\n",
        "#         elif canary_type == \"address\":\n",
        "#             filled_template = template.format(fake.street_address(), fake.city())\n",
        "#         elif canary_type == \"phone\":\n",
        "#             filled_template = template.format(fake.phone_number())\n",
        "#         elif canary_type == \"email\":\n",
        "#             filled_template = template.format(fake.email())\n",
        "#         elif canary_type == \"order_id\":\n",
        "#             filled_template = template.format(f\"{random.randint(100, 999)}-{random.randint(1000000, 9999999)}-{random.randint(1000000, 9999999)}\")\n",
        "#         candidates.append(filled_template)\n",
        "#     return candidates"
      ],
      "metadata": {
        "id": "iKOtzA7z2aih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Compute perplexity for a given text\n",
        "# def calculate_perplexity(text):\n",
        "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True).to(\"cuda\")\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
        "#     loss = outputs.loss.item()\n",
        "#     return np.exp(loss)  # Convert loss to perplexity"
      ],
      "metadata": {
        "id": "IF4snSPi_sIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Compute perplexity for canary sequences and 10,000 candidates\n",
        "# candidate_sentences = generate_candidate_sentences(10000)  # Pre-generate all candidates"
      ],
      "metadata": {
        "id": "H7SV5YoO_try"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# candidate_sentences[:10]"
      ],
      "metadata": {
        "id": "Hzu9s2WzAQK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# candidate_perplexities = [calculate_perplexity(sentence) for sentence in candidate_sentences]"
      ],
      "metadata": {
        "id": "OnAqpW41_7Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perplexities = {}\n",
        "# for canary_type, template in canary_templates.items():\n",
        "#     # Generate a single unique canary sentence\n",
        "#     if canary_type == \"name\":\n",
        "#         canary_text = template.format(fake.first_name(), fake.last_name())\n",
        "#     elif canary_type == \"address\":\n",
        "#         canary_text = template.format(fake.street_address(), fake.city())\n",
        "#     elif canary_type == \"phone\":\n",
        "#         canary_text = template.format(fake.phone_number())\n",
        "#     elif canary_type == \"email\":\n",
        "#         canary_text = template.format(fake.email())\n",
        "#     elif canary_type == \"order_id\":\n",
        "#         canary_text = template.format(f\"{random.randint(100, 999)}-{random.randint(1000000, 9999999)}-{random.randint(1000000, 9999999)}\")\n",
        "\n",
        "#     # Compute perplexity for canary\n",
        "#     canary_perplexity = calculate_perplexity(canary_text)\n",
        "#     rank = sum(1 for p in candidate_perplexities if p < canary_perplexity) + 1\n",
        "#     perplexities[canary_type] = rank"
      ],
      "metadata": {
        "id": "QFR4zEtx_4AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Print results\n",
        "# print(\"\\nüîπ Perplexity Rankings for Canary Sequences:\")\n",
        "# for canary_type, rank in perplexities.items():\n",
        "#     print(f\"‚û°Ô∏è {canary_type}: Rank {rank} / 10,000 (Lower rank = Higher memorization risk)\")"
      ],
      "metadata": {
        "id": "6_xCcqpvACet"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YMUVxt8V_TpT",
        "FRsdt0qr_TpU",
        "GN4Zx6vBZqB4",
        "hgyCR9zZFH12",
        "ar8dafEAZzbV",
        "cVR1d7bYa10N",
        "U4rtyTm8LZKW",
        "BS9pnQ9K2UMf"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}